2019-05-14 03:11:42,236: INFO: [driver.py:123]: Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt
2019-05-14 03:11:42,258: INFO: [driver.py:123]: Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt
2019-05-14 03:11:50,114: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-14 03:11:55,906: INFO: [train_wsdan.py:143]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-14 03:11:55,906: INFO: [train_wsdan.py:203]: Epoch 001, Learning Rate 0.001
2019-05-14 03:19:35,914: INFO: [train_wsdan.py:313]: 
	Batch 100: (Raw) Loss 6.9147, Accuracy: (0.19, 0.81, 1.31), (Crop) Loss 6.9141, Accuracy: (0.22, 0.69, 1.16), (Drop) Loss 6.9144, Accuracy: (0.28, 0.81, 1.34), Time 4.32
2019-05-14 03:26:39,389: INFO: [train_wsdan.py:313]: 
	Batch 200: (Raw) Loss 6.9082, Accuracy: (0.28, 0.92, 1.31), (Crop) Loss 6.9071, Accuracy: (0.33, 0.86, 1.28), (Drop) Loss 6.9084, Accuracy: (0.30, 0.84, 1.34), Time 4.19
2019-05-14 03:33:42,609: INFO: [train_wsdan.py:313]: 
	Batch 300: (Raw) Loss 6.8868, Accuracy: (0.32, 0.96, 1.34), (Crop) Loss 6.8836, Accuracy: (0.39, 0.92, 1.31), (Drop) Loss 6.8903, Accuracy: (0.32, 0.85, 1.31), Time 4.16
2019-05-14 03:40:45,895: INFO: [train_wsdan.py:313]: 
	Batch 400: (Raw) Loss 6.8549, Accuracy: (0.30, 0.89, 1.35), (Crop) Loss 6.8485, Accuracy: (0.36, 0.88, 1.34), (Drop) Loss 6.8611, Accuracy: (0.30, 0.78, 1.27), Time 4.30
2019-05-14 03:47:48,569: INFO: [train_wsdan.py:313]: 
	Batch 500: (Raw) Loss 6.8196, Accuracy: (0.33, 0.91, 1.44), (Crop) Loss 6.8098, Accuracy: (0.38, 0.94, 1.45), (Drop) Loss 6.8280, Accuracy: (0.32, 0.82, 1.32), Time 4.24
2019-05-14 03:54:52,694: INFO: [train_wsdan.py:313]: 
	Batch 600: (Raw) Loss 6.7856, Accuracy: (0.38, 0.99, 1.56), (Crop) Loss 6.7726, Accuracy: (0.42, 1.06, 1.61), (Drop) Loss 6.7958, Accuracy: (0.35, 0.89, 1.46), Time 4.33
2019-05-14 04:01:56,652: INFO: [train_wsdan.py:313]: 
	Batch 700: (Raw) Loss 6.7544, Accuracy: (0.42, 1.11, 1.75), (Crop) Loss 6.7377, Accuracy: (0.47, 1.20, 1.82), (Drop) Loss 6.7665, Accuracy: (0.38, 0.98, 1.58), Time 4.15
2019-05-14 04:09:01,253: INFO: [train_wsdan.py:313]: 
	Batch 800: (Raw) Loss 6.7167, Accuracy: (0.45, 1.25, 1.97), (Crop) Loss 6.6971, Accuracy: (0.52, 1.34, 2.04), (Drop) Loss 6.7313, Accuracy: (0.44, 1.07, 1.78), Time 4.27
2019-05-14 04:16:05,522: INFO: [train_wsdan.py:313]: 
	Batch 900: (Raw) Loss 6.6733, Accuracy: (0.54, 1.52, 2.34), (Crop) Loss 6.6539, Accuracy: (0.62, 1.57, 2.36), (Drop) Loss 6.6904, Accuracy: (0.53, 1.28, 2.06), Time 4.32
2019-05-14 04:23:09,382: INFO: [train_wsdan.py:313]: 
	Batch 1000: (Raw) Loss 6.6175, Accuracy: (0.71, 1.83, 2.83), (Crop) Loss 6.5995, Accuracy: (0.76, 1.91, 2.90), (Drop) Loss 6.6396, Accuracy: (0.65, 1.61, 2.53), Time 4.25
2019-05-14 04:23:09,382: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 04:30:12,995: INFO: [train_wsdan.py:313]: 
	Batch 1100: (Raw) Loss 6.5500, Accuracy: (0.93, 2.34, 3.55), (Crop) Loss 6.5339, Accuracy: (0.98, 2.39, 3.59), (Drop) Loss 6.5774, Accuracy: (0.80, 2.07, 3.16), Time 4.16
2019-05-14 04:37:15,836: INFO: [train_wsdan.py:313]: 
	Batch 1200: (Raw) Loss 6.4742, Accuracy: (1.26, 3.04, 4.49), (Crop) Loss 6.4602, Accuracy: (1.32, 3.06, 4.52), (Drop) Loss 6.5103, Accuracy: (1.05, 2.64, 3.94), Time 4.20
2019-05-14 04:44:19,308: INFO: [train_wsdan.py:313]: 
	Batch 1300: (Raw) Loss 6.3939, Accuracy: (1.68, 3.88, 5.61), (Crop) Loss 6.3833, Accuracy: (1.70, 3.90, 5.59), (Drop) Loss 6.4381, Accuracy: (1.38, 3.29, 4.85), Time 4.24
2019-05-14 04:51:22,449: INFO: [train_wsdan.py:313]: 
	Batch 1400: (Raw) Loss 6.3090, Accuracy: (2.12, 4.75, 6.81), (Crop) Loss 6.3024, Accuracy: (2.06, 4.73, 6.69), (Drop) Loss 6.3645, Accuracy: (1.75, 3.98, 5.76), Time 4.29
2019-05-14 04:58:26,138: INFO: [train_wsdan.py:313]: 
	Batch 1500: (Raw) Loss 6.2259, Accuracy: (2.60, 5.77, 8.12), (Crop) Loss 6.2233, Accuracy: (2.51, 5.66, 7.93), (Drop) Loss 6.2927, Accuracy: (2.12, 4.73, 6.79), Time 4.24
2019-05-14 05:05:30,359: INFO: [train_wsdan.py:313]: 
	Batch 1600: (Raw) Loss 6.1420, Accuracy: (3.11, 6.75, 9.43), (Crop) Loss 6.1451, Accuracy: (2.95, 6.55, 9.16), (Drop) Loss 6.2208, Accuracy: (2.52, 5.49, 7.85), Time 4.35
2019-05-14 05:12:34,677: INFO: [train_wsdan.py:313]: 
	Batch 1700: (Raw) Loss 6.0563, Accuracy: (3.69, 7.92, 10.94), (Crop) Loss 6.0642, Accuracy: (3.44, 7.60, 10.49), (Drop) Loss 6.1442, Accuracy: (2.93, 6.40, 9.01), Time 4.23
2019-05-14 05:19:38,576: INFO: [train_wsdan.py:313]: 
	Batch 1800: (Raw) Loss 5.9666, Accuracy: (4.31, 9.09, 12.41), (Crop) Loss 5.9796, Accuracy: (3.97, 8.65, 11.84), (Drop) Loss 6.0661, Accuracy: (3.38, 7.32, 10.15), Time 4.17
2019-05-14 05:26:43,245: INFO: [train_wsdan.py:313]: 
	Batch 1900: (Raw) Loss 5.8774, Accuracy: (4.98, 10.28, 13.91), (Crop) Loss 5.8955, Accuracy: (4.56, 9.77, 13.18), (Drop) Loss 5.9875, Accuracy: (3.88, 8.26, 11.34), Time 4.25
2019-05-14 05:33:47,735: INFO: [train_wsdan.py:313]: 
	Batch 2000: (Raw) Loss 5.7875, Accuracy: (5.68, 11.52, 15.43), (Crop) Loss 5.8116, Accuracy: (5.17, 10.84, 14.54), (Drop) Loss 5.9074, Accuracy: (4.41, 9.27, 12.58), Time 4.20
2019-05-14 05:33:47,735: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 05:40:52,106: INFO: [train_wsdan.py:313]: 
	Batch 2100: (Raw) Loss 5.6986, Accuracy: (6.39, 12.77, 16.98), (Crop) Loss 5.7278, Accuracy: (5.80, 11.96, 15.92), (Drop) Loss 5.8298, Accuracy: (4.94, 10.23, 13.82), Time 4.28
2019-05-14 05:47:55,565: INFO: [train_wsdan.py:313]: 
	Batch 2200: (Raw) Loss 5.6137, Accuracy: (7.08, 13.97, 18.44), (Crop) Loss 5.6484, Accuracy: (6.37, 13.03, 17.18), (Drop) Loss 5.7574, Accuracy: (5.43, 11.12, 14.94), Time 4.35
2019-05-14 05:54:58,644: INFO: [train_wsdan.py:313]: 
	Batch 2300: (Raw) Loss 5.5292, Accuracy: (7.75, 15.16, 19.85), (Crop) Loss 5.5695, Accuracy: (7.00, 14.09, 18.44), (Drop) Loss 5.6843, Accuracy: (5.96, 12.07, 16.10), Time 4.27
2019-05-14 06:02:02,713: INFO: [train_wsdan.py:313]: 
	Batch 2400: (Raw) Loss 5.4483, Accuracy: (8.41, 16.31, 21.23), (Crop) Loss 5.4937, Accuracy: (7.59, 15.14, 19.67), (Drop) Loss 5.6165, Accuracy: (6.43, 12.93, 17.16), Time 4.16
2019-05-14 06:09:06,753: INFO: [train_wsdan.py:313]: 
	Batch 2500: (Raw) Loss 5.3695, Accuracy: (9.09, 17.42, 22.52), (Crop) Loss 5.4206, Accuracy: (8.18, 16.11, 20.84), (Drop) Loss 5.5505, Accuracy: (6.91, 13.72, 18.18), Time 4.22
2019-05-14 06:16:10,465: INFO: [train_wsdan.py:313]: 
	Batch 2600: (Raw) Loss 5.2920, Accuracy: (9.77, 18.55, 23.86), (Crop) Loss 5.3483, Accuracy: (8.81, 17.08, 22.02), (Drop) Loss 5.4835, Accuracy: (7.46, 14.65, 19.26), Time 4.28
2019-05-14 06:23:13,883: INFO: [train_wsdan.py:313]: 
	Batch 2700: (Raw) Loss 5.2173, Accuracy: (10.46, 19.65, 25.12), (Crop) Loss 5.2800, Accuracy: (9.39, 18.03, 23.17), (Drop) Loss 5.4206, Accuracy: (7.99, 15.48, 20.25), Time 4.18
2019-05-14 06:30:16,320: INFO: [train_wsdan.py:313]: 
	Batch 2800: (Raw) Loss 5.1451, Accuracy: (11.14, 20.73, 26.35), (Crop) Loss 5.2141, Accuracy: (9.96, 19.00, 24.27), (Drop) Loss 5.3590, Accuracy: (8.50, 16.32, 21.24), Time 4.22
2019-05-14 06:37:19,190: INFO: [train_wsdan.py:313]: 
	Batch 2900: (Raw) Loss 5.0756, Accuracy: (11.79, 21.79, 27.58), (Crop) Loss 5.1502, Accuracy: (10.55, 19.91, 25.31), (Drop) Loss 5.2995, Accuracy: (8.99, 17.15, 22.21), Time 4.27
2019-05-14 06:44:22,394: INFO: [train_wsdan.py:313]: 
	Batch 3000: (Raw) Loss 5.0107, Accuracy: (12.45, 22.77, 28.70), (Crop) Loss 5.0900, Accuracy: (11.11, 20.75, 26.30), (Drop) Loss 5.2447, Accuracy: (9.46, 17.92, 23.11), Time 4.27
2019-05-14 06:44:22,394: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 06:51:28,266: INFO: [train_wsdan.py:313]: 
	Batch 3100: (Raw) Loss 4.9457, Accuracy: (13.07, 23.77, 29.82), (Crop) Loss 5.0304, Accuracy: (11.66, 21.60, 27.29), (Drop) Loss 5.1905, Accuracy: (9.89, 18.68, 24.01), Time 4.22
2019-05-14 06:58:33,809: INFO: [train_wsdan.py:313]: 
	Batch 3200: (Raw) Loss 4.8844, Accuracy: (13.71, 24.72, 30.89), (Crop) Loss 4.9739, Accuracy: (12.20, 22.43, 28.27), (Drop) Loss 5.1391, Accuracy: (10.35, 19.44, 24.90), Time 4.28
2019-05-14 07:05:38,669: INFO: [train_wsdan.py:313]: 
	Batch 3300: (Raw) Loss 4.8253, Accuracy: (14.33, 25.62, 31.89), (Crop) Loss 4.9191, Accuracy: (12.75, 23.26, 29.19), (Drop) Loss 5.0895, Accuracy: (10.79, 20.15, 25.72), Time 4.27
2019-05-14 07:12:43,890: INFO: [train_wsdan.py:313]: 
	Batch 3400: (Raw) Loss 4.7658, Accuracy: (14.98, 26.54, 32.92), (Crop) Loss 4.8635, Accuracy: (13.33, 24.08, 30.10), (Drop) Loss 5.0396, Accuracy: (11.26, 20.88, 26.54), Time 4.34
2019-05-14 07:19:47,903: INFO: [train_wsdan.py:313]: 
	Batch 3500: (Raw) Loss 4.7118, Accuracy: (15.55, 27.40, 33.87), (Crop) Loss 4.8144, Accuracy: (13.82, 24.83, 30.95), (Drop) Loss 4.9950, Accuracy: (11.67, 21.52, 27.28), Time 4.16
2019-05-14 07:26:51,305: INFO: [train_wsdan.py:313]: 
	Batch 3600: (Raw) Loss 4.6581, Accuracy: (16.14, 28.25, 34.82), (Crop) Loss 4.7656, Accuracy: (14.33, 25.57, 31.78), (Drop) Loss 4.9507, Accuracy: (12.10, 22.18, 28.03), Time 4.24
2019-05-14 07:33:55,981: INFO: [train_wsdan.py:313]: 
	Batch 3700: (Raw) Loss 4.6070, Accuracy: (16.69, 29.04, 35.70), (Crop) Loss 4.7184, Accuracy: (14.75, 26.24, 32.54), (Drop) Loss 4.9087, Accuracy: (12.48, 22.76, 28.72), Time 4.24
2019-05-14 07:41:00,580: INFO: [train_wsdan.py:313]: 
	Batch 3800: (Raw) Loss 4.5569, Accuracy: (17.28, 29.85, 36.57), (Crop) Loss 4.6713, Accuracy: (15.24, 26.94, 33.33), (Drop) Loss 4.8675, Accuracy: (12.86, 23.34, 29.40), Time 4.22
2019-05-14 07:48:05,538: INFO: [train_wsdan.py:313]: 
	Batch 3900: (Raw) Loss 4.5083, Accuracy: (17.83, 30.63, 37.43), (Crop) Loss 4.6266, Accuracy: (15.69, 27.63, 34.12), (Drop) Loss 4.8266, Accuracy: (13.25, 23.95, 30.10), Time 4.29
2019-05-14 07:55:10,806: INFO: [train_wsdan.py:313]: 
	Batch 4000: (Raw) Loss 4.4616, Accuracy: (18.36, 31.39, 38.25), (Crop) Loss 4.5838, Accuracy: (16.15, 28.30, 34.84), (Drop) Loss 4.7881, Accuracy: (13.63, 24.50, 30.74), Time 4.29
2019-05-14 07:55:10,807: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 08:02:15,633: INFO: [train_wsdan.py:313]: 
	Batch 4100: (Raw) Loss 4.4160, Accuracy: (18.91, 32.12, 39.02), (Crop) Loss 4.5421, Accuracy: (16.61, 28.94, 35.53), (Drop) Loss 4.7488, Accuracy: (14.05, 25.11, 31.41), Time 4.27
2019-05-14 08:09:19,029: INFO: [train_wsdan.py:313]: 
	Batch 4200: (Raw) Loss 4.3700, Accuracy: (19.45, 32.87, 39.83), (Crop) Loss 4.5008, Accuracy: (17.06, 29.58, 36.23), (Drop) Loss 4.7105, Accuracy: (14.43, 25.70, 32.07), Time 4.21
2019-05-14 08:16:22,276: INFO: [train_wsdan.py:313]: 
	Batch 4300: (Raw) Loss 4.3265, Accuracy: (19.96, 33.58, 40.59), (Crop) Loss 4.4603, Accuracy: (17.50, 30.21, 36.94), (Drop) Loss 4.6748, Accuracy: (14.75, 26.23, 32.68), Time 4.22
2019-05-14 08:23:27,535: INFO: [train_wsdan.py:313]: 
	Batch 4400: (Raw) Loss 4.2846, Accuracy: (20.48, 34.27, 41.32), (Crop) Loss 4.4224, Accuracy: (17.92, 30.79, 37.58), (Drop) Loss 4.6409, Accuracy: (15.09, 26.72, 33.24), Time 4.32
2019-05-14 08:30:32,811: INFO: [train_wsdan.py:313]: 
	Batch 4500: (Raw) Loss 4.2435, Accuracy: (20.96, 34.96, 42.05), (Crop) Loss 4.3847, Accuracy: (18.33, 31.39, 38.22), (Drop) Loss 4.6070, Accuracy: (15.43, 27.23, 33.84), Time 4.27
2019-05-14 08:37:38,790: INFO: [train_wsdan.py:313]: 
	Batch 4600: (Raw) Loss 4.2026, Accuracy: (21.47, 35.62, 42.76), (Crop) Loss 4.3461, Accuracy: (18.78, 32.00, 38.86), (Drop) Loss 4.5733, Accuracy: (15.80, 27.75, 34.40), Time 4.23
2019-05-14 08:44:44,043: INFO: [train_wsdan.py:313]: 
	Batch 4700: (Raw) Loss 4.1630, Accuracy: (21.95, 36.26, 43.44), (Crop) Loss 4.3106, Accuracy: (19.18, 32.53, 39.45), (Drop) Loss 4.5403, Accuracy: (16.13, 28.25, 34.97), Time 4.19
2019-05-14 08:51:48,680: INFO: [train_wsdan.py:313]: 
	Batch 4800: (Raw) Loss 4.1260, Accuracy: (22.37, 36.86, 44.09), (Crop) Loss 4.2764, Accuracy: (19.55, 33.07, 40.04), (Drop) Loss 4.5099, Accuracy: (16.44, 28.70, 35.47), Time 4.19
2019-05-14 08:58:53,075: INFO: [train_wsdan.py:313]: 
	Batch 4900: (Raw) Loss 4.0895, Accuracy: (22.80, 37.48, 44.74), (Crop) Loss 4.2427, Accuracy: (19.90, 33.61, 40.61), (Drop) Loss 4.4801, Accuracy: (16.75, 29.17, 35.97), Time 4.26
2019-05-14 09:05:56,358: INFO: [train_wsdan.py:313]: 
	Batch 5000: (Raw) Loss 4.0544, Accuracy: (23.24, 38.05, 45.35), (Crop) Loss 4.2099, Accuracy: (20.28, 34.13, 41.17), (Drop) Loss 4.4519, Accuracy: (17.06, 29.60, 36.46), Time 4.36
2019-05-14 09:05:56,358: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 09:13:01,740: INFO: [train_wsdan.py:313]: 
	Batch 5100: (Raw) Loss 4.0199, Accuracy: (23.68, 38.62, 45.94), (Crop) Loss 4.1780, Accuracy: (20.67, 34.66, 41.71), (Drop) Loss 4.4233, Accuracy: (17.37, 30.05, 36.95), Time 4.31
2019-05-14 09:20:07,272: INFO: [train_wsdan.py:313]: 
	Batch 5200: (Raw) Loss 3.9870, Accuracy: (24.10, 39.16, 46.51), (Crop) Loss 4.1478, Accuracy: (21.03, 35.14, 42.22), (Drop) Loss 4.3954, Accuracy: (17.68, 30.49, 37.43), Time 4.29
2019-05-14 09:27:13,010: INFO: [train_wsdan.py:313]: 
	Batch 5300: (Raw) Loss 3.9541, Accuracy: (24.51, 39.72, 47.09), (Crop) Loss 4.1170, Accuracy: (21.39, 35.63, 42.76), (Drop) Loss 4.3680, Accuracy: (18.00, 30.93, 37.90), Time 4.23
2019-05-14 09:34:17,245: INFO: [train_wsdan.py:313]: 
	Batch 5400: (Raw) Loss 3.9225, Accuracy: (24.92, 40.23, 47.63), (Crop) Loss 4.0873, Accuracy: (21.75, 36.09, 43.25), (Drop) Loss 4.3416, Accuracy: (18.29, 31.34, 38.35), Time 4.19
2019-05-14 09:41:21,288: INFO: [train_wsdan.py:313]: 
	Batch 5500: (Raw) Loss 3.8917, Accuracy: (25.33, 40.74, 48.16), (Crop) Loss 4.0597, Accuracy: (22.08, 36.52, 43.72), (Drop) Loss 4.3162, Accuracy: (18.57, 31.74, 38.79), Time 4.26
2019-05-14 09:48:24,785: INFO: [train_wsdan.py:313]: 
	Batch 5600: (Raw) Loss 3.8622, Accuracy: (25.69, 41.23, 48.68), (Crop) Loss 4.0322, Accuracy: (22.41, 36.95, 44.21), (Drop) Loss 4.2914, Accuracy: (18.84, 32.12, 39.21), Time 4.38
2019-05-14 09:55:29,521: INFO: [train_wsdan.py:313]: 
	Batch 5700: (Raw) Loss 3.8337, Accuracy: (26.06, 41.69, 49.16), (Crop) Loss 4.0062, Accuracy: (22.71, 37.36, 44.64), (Drop) Loss 4.2679, Accuracy: (19.08, 32.49, 39.61), Time 4.25
2019-05-14 10:02:34,673: INFO: [train_wsdan.py:313]: 
	Batch 5800: (Raw) Loss 3.8056, Accuracy: (26.40, 42.16, 49.64), (Crop) Loss 3.9796, Accuracy: (23.03, 37.78, 45.09), (Drop) Loss 4.2445, Accuracy: (19.32, 32.86, 40.02), Time 4.21
2019-05-14 10:09:39,628: INFO: [train_wsdan.py:313]: 
	Batch 5900: (Raw) Loss 3.7776, Accuracy: (26.76, 42.63, 50.13), (Crop) Loss 3.9536, Accuracy: (23.33, 38.19, 45.53), (Drop) Loss 4.2215, Accuracy: (19.57, 33.21, 40.42), Time 4.30
2019-05-14 10:16:43,873: INFO: [train_wsdan.py:313]: 
	Batch 6000: (Raw) Loss 3.7500, Accuracy: (27.13, 43.08, 50.58), (Crop) Loss 3.9286, Accuracy: (23.64, 38.59, 45.95), (Drop) Loss 4.1989, Accuracy: (19.84, 33.56, 40.81), Time 4.20
2019-05-14 10:16:43,873: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 10:23:50,550: INFO: [train_wsdan.py:313]: 
	Batch 6100: (Raw) Loss 3.7231, Accuracy: (27.49, 43.52, 51.04), (Crop) Loss 3.9037, Accuracy: (23.96, 38.98, 46.37), (Drop) Loss 4.1764, Accuracy: (20.11, 33.91, 41.19), Time 4.25
2019-05-14 10:30:54,368: INFO: [train_wsdan.py:313]: 
	Batch 6200: (Raw) Loss 3.6969, Accuracy: (27.85, 43.96, 51.50), (Crop) Loss 3.8797, Accuracy: (24.27, 39.39, 46.78), (Drop) Loss 4.1551, Accuracy: (20.36, 34.26, 41.55), Time 4.18
2019-05-14 10:37:59,014: INFO: [train_wsdan.py:313]: 
	Batch 6300: (Raw) Loss 3.6721, Accuracy: (28.17, 44.37, 51.93), (Crop) Loss 3.8576, Accuracy: (24.54, 39.75, 47.16), (Drop) Loss 4.1342, Accuracy: (20.62, 34.60, 41.91), Time 4.26
2019-05-14 10:45:03,712: INFO: [train_wsdan.py:313]: 
	Batch 6400: (Raw) Loss 3.6468, Accuracy: (28.51, 44.79, 52.36), (Crop) Loss 3.8341, Accuracy: (24.84, 40.13, 47.57), (Drop) Loss 4.1135, Accuracy: (20.86, 34.93, 42.26), Time 4.38
2019-05-14 10:52:09,053: INFO: [train_wsdan.py:313]: 
	Batch 6500: (Raw) Loss 3.6224, Accuracy: (28.84, 45.21, 52.79), (Crop) Loss 3.8114, Accuracy: (25.12, 40.50, 47.96), (Drop) Loss 4.0937, Accuracy: (21.10, 35.25, 42.60), Time 4.22
2019-05-14 10:59:14,565: INFO: [train_wsdan.py:313]: 
	Batch 6600: (Raw) Loss 3.5985, Accuracy: (29.16, 45.60, 53.21), (Crop) Loss 3.7897, Accuracy: (25.39, 40.86, 48.33), (Drop) Loss 4.0742, Accuracy: (21.33, 35.54, 42.90), Time 4.23
2019-05-14 11:06:19,065: INFO: [train_wsdan.py:313]: 
	Batch 6700: (Raw) Loss 3.5752, Accuracy: (29.47, 45.99, 53.60), (Crop) Loss 3.7682, Accuracy: (25.66, 41.22, 48.71), (Drop) Loss 4.0560, Accuracy: (21.52, 35.84, 43.23), Time 4.24
2019-05-14 11:13:22,503: INFO: [train_wsdan.py:313]: 
	Batch 6800: (Raw) Loss 3.5533, Accuracy: (29.76, 46.37, 53.98), (Crop) Loss 3.7482, Accuracy: (25.91, 41.55, 49.05), (Drop) Loss 4.0371, Accuracy: (21.75, 36.16, 43.56), Time 4.23
2019-05-14 11:20:27,126: INFO: [train_wsdan.py:313]: 
	Batch 6900: (Raw) Loss 3.5301, Accuracy: (30.07, 46.75, 54.37), (Crop) Loss 3.7274, Accuracy: (26.17, 41.90, 49.41), (Drop) Loss 4.0185, Accuracy: (21.97, 36.46, 43.89), Time 4.39
2019-05-14 11:27:32,856: INFO: [train_wsdan.py:313]: 
	Batch 7000: (Raw) Loss 3.5074, Accuracy: (30.39, 47.14, 54.76), (Crop) Loss 3.7064, Accuracy: (26.44, 42.25, 49.77), (Drop) Loss 3.9990, Accuracy: (22.20, 36.77, 44.22), Time 4.22
2019-05-14 11:27:32,857: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 11:34:38,130: INFO: [train_wsdan.py:313]: 
	Batch 7100: (Raw) Loss 3.4859, Accuracy: (30.70, 47.50, 55.14), (Crop) Loss 3.6863, Accuracy: (26.71, 42.58, 50.12), (Drop) Loss 3.9810, Accuracy: (22.42, 37.07, 44.55), Time 4.30
2019-05-14 11:41:44,203: INFO: [train_wsdan.py:313]: 
	Batch 7200: (Raw) Loss 3.4652, Accuracy: (30.98, 47.85, 55.49), (Crop) Loss 3.6673, Accuracy: (26.95, 42.88, 50.44), (Drop) Loss 3.9640, Accuracy: (22.62, 37.34, 44.84), Time 4.30
2019-05-14 11:48:49,673: INFO: [train_wsdan.py:313]: 
	Batch 7300: (Raw) Loss 3.4445, Accuracy: (31.27, 48.20, 55.84), (Crop) Loss 3.6481, Accuracy: (27.19, 43.19, 50.78), (Drop) Loss 3.9470, Accuracy: (22.81, 37.60, 45.12), Time 4.28
2019-05-14 11:55:54,881: INFO: [train_wsdan.py:313]: 
	Batch 7400: (Raw) Loss 3.4241, Accuracy: (31.55, 48.55, 56.18), (Crop) Loss 3.6296, Accuracy: (27.42, 43.50, 51.09), (Drop) Loss 3.9304, Accuracy: (23.01, 37.87, 45.40), Time 4.29
2019-05-14 12:02:59,721: INFO: [train_wsdan.py:313]: 
	Batch 7500: (Raw) Loss 3.4044, Accuracy: (31.83, 48.89, 56.54), (Crop) Loss 3.6110, Accuracy: (27.66, 43.81, 51.41), (Drop) Loss 3.9149, Accuracy: (23.19, 38.11, 45.67), Time 4.22
2019-05-14 12:10:04,622: INFO: [train_wsdan.py:313]: 
	Batch 7600: (Raw) Loss 3.3846, Accuracy: (32.12, 49.24, 56.88), (Crop) Loss 3.5930, Accuracy: (27.91, 44.11, 51.72), (Drop) Loss 3.8997, Accuracy: (23.37, 38.37, 45.93), Time 4.22
2019-05-14 12:17:10,745: INFO: [train_wsdan.py:313]: 
	Batch 7700: (Raw) Loss 3.3654, Accuracy: (32.39, 49.55, 57.20), (Crop) Loss 3.5753, Accuracy: (28.13, 44.41, 52.02), (Drop) Loss 3.8843, Accuracy: (23.57, 38.61, 46.18), Time 4.33
2019-05-14 12:24:17,367: INFO: [train_wsdan.py:313]: 
	Batch 7800: (Raw) Loss 3.3469, Accuracy: (32.64, 49.86, 57.51), (Crop) Loss 3.5578, Accuracy: (28.36, 44.71, 52.32), (Drop) Loss 3.8690, Accuracy: (23.76, 38.85, 46.45), Time 4.24
2019-05-14 12:31:24,345: INFO: [train_wsdan.py:313]: 
	Batch 7900: (Raw) Loss 3.3285, Accuracy: (32.90, 50.16, 57.82), (Crop) Loss 3.5406, Accuracy: (28.58, 44.99, 52.61), (Drop) Loss 3.8539, Accuracy: (23.94, 39.10, 46.71), Time 4.32
2019-05-14 12:38:30,578: INFO: [train_wsdan.py:313]: 
	Batch 8000: (Raw) Loss 3.3096, Accuracy: (33.17, 50.49, 58.13), (Crop) Loss 3.5230, Accuracy: (28.82, 45.28, 52.91), (Drop) Loss 3.8385, Accuracy: (24.12, 39.35, 46.96), Time 4.26
2019-05-14 12:38:30,581: INFO: [train_wsdan.py:317]: saving the latest model from epoch 0
2019-05-14 12:45:36,553: INFO: [train_wsdan.py:313]: 
	Batch 8100: (Raw) Loss 3.2919, Accuracy: (33.41, 50.79, 58.43), (Crop) Loss 3.5064, Accuracy: (29.04, 45.56, 53.20), (Drop) Loss 3.8242, Accuracy: (24.29, 39.58, 47.20), Time 4.41
2019-05-14 12:52:41,930: INFO: [train_wsdan.py:313]: 
	Batch 8200: (Raw) Loss 3.2749, Accuracy: (33.65, 51.07, 58.72), (Crop) Loss 3.4908, Accuracy: (29.24, 45.80, 53.46), (Drop) Loss 3.8101, Accuracy: (24.47, 39.81, 47.45), Time 4.20
2019-05-14 12:59:19,678: INFO: [train_wsdan.py:345]: Train: (Raw) Loss 3.2597, Accuracy: (33.86, 51.33, 58.97), (Crop) Loss 3.4768, Accuracy: (29.42, 46.03, 53.70), (Drop) Loss 3.7979, Accuracy: (24.63, 40.01, 47.66), Time 35243.77
2019-05-14 13:01:12,236: INFO: [train_wsdan.py:438]: saving the best model from epoch 1
2019-05-14 13:01:12,526: INFO: [train_wsdan.py:449]: Valid: Loss 2.51821,  Accuracy: Top-1 44.02, Top-3 66.76, Top-5 75.70, Time 112.34
2019-05-14 13:01:12,536: INFO: [train_wsdan.py:203]: Epoch 002, Learning Rate 0.001
2019-05-14 13:08:25,589: INFO: [train_wsdan.py:313]: 
	Batch 100: (Raw) Loss 1.7044, Accuracy: (57.25, 78.09, 84.97), (Crop) Loss 2.0543, Accuracy: (48.50, 70.00, 77.47), (Drop) Loss 2.5246, Accuracy: (40.56, 60.91, 69.91), Time 4.20
2019-05-14 13:15:30,041: INFO: [train_wsdan.py:313]: 
	Batch 200: (Raw) Loss 1.7013, Accuracy: (57.33, 78.31, 85.14), (Crop) Loss 2.0406, Accuracy: (49.16, 70.34, 77.81), (Drop) Loss 2.5302, Accuracy: (40.72, 61.34, 69.78), Time 4.20
2019-05-14 13:22:35,761: INFO: [train_wsdan.py:313]: 
	Batch 300: (Raw) Loss 1.6933, Accuracy: (57.43, 78.38, 85.34), (Crop) Loss 2.0205, Accuracy: (49.43, 70.55, 78.14), (Drop) Loss 2.5106, Accuracy: (40.96, 61.65, 70.17), Time 4.35
2019-05-14 13:29:40,530: INFO: [train_wsdan.py:313]: 
	Batch 400: (Raw) Loss 1.6881, Accuracy: (57.50, 78.45, 85.35), (Crop) Loss 2.0168, Accuracy: (49.69, 70.55, 78.31), (Drop) Loss 2.5192, Accuracy: (40.91, 61.23, 69.94), Time 4.19
2019-05-14 13:36:45,903: INFO: [train_wsdan.py:313]: 
	Batch 500: (Raw) Loss 1.6889, Accuracy: (57.41, 78.38, 85.38), (Crop) Loss 2.0102, Accuracy: (49.77, 70.62, 78.43), (Drop) Loss 2.5280, Accuracy: (40.61, 61.24, 69.79), Time 4.32
2019-05-14 13:43:51,948: INFO: [train_wsdan.py:313]: 
	Batch 600: (Raw) Loss 1.6879, Accuracy: (57.28, 78.29, 85.31), (Crop) Loss 2.0115, Accuracy: (49.79, 70.44, 78.20), (Drop) Loss 2.5231, Accuracy: (40.68, 61.20, 69.54), Time 4.20
2019-05-14 13:50:57,045: INFO: [train_wsdan.py:313]: 
	Batch 700: (Raw) Loss 1.6854, Accuracy: (57.32, 78.21, 85.20), (Crop) Loss 2.0068, Accuracy: (49.81, 70.41, 78.15), (Drop) Loss 2.5250, Accuracy: (40.65, 61.14, 69.43), Time 4.24
2019-05-14 13:58:02,267: INFO: [train_wsdan.py:313]: 
	Batch 800: (Raw) Loss 1.6916, Accuracy: (57.27, 78.27, 85.15), (Crop) Loss 2.0166, Accuracy: (49.59, 70.21, 77.98), (Drop) Loss 2.5294, Accuracy: (40.66, 61.08, 69.36), Time 4.27
2019-05-14 14:05:07,041: INFO: [train_wsdan.py:313]: 
	Batch 900: (Raw) Loss 1.6912, Accuracy: (57.29, 78.33, 85.25), (Crop) Loss 2.0126, Accuracy: (49.60, 70.24, 78.09), (Drop) Loss 2.5273, Accuracy: (40.58, 61.00, 69.32), Time 4.23
2019-05-14 14:12:11,258: INFO: [train_wsdan.py:313]: 
	Batch 1000: (Raw) Loss 1.6881, Accuracy: (57.44, 78.38, 85.24), (Crop) Loss 2.0110, Accuracy: (49.71, 70.28, 78.06), (Drop) Loss 2.5157, Accuracy: (40.77, 61.11, 69.47), Time 4.25
2019-05-14 14:12:11,258: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 14:19:15,858: INFO: [train_wsdan.py:313]: 
	Batch 1100: (Raw) Loss 1.6833, Accuracy: (57.50, 78.40, 85.28), (Crop) Loss 2.0047, Accuracy: (49.81, 70.39, 78.13), (Drop) Loss 2.5209, Accuracy: (40.65, 60.99, 69.41), Time 4.18
2019-05-14 14:26:20,708: INFO: [train_wsdan.py:313]: 
	Batch 1200: (Raw) Loss 1.6848, Accuracy: (57.54, 78.33, 85.20), (Crop) Loss 2.0093, Accuracy: (49.72, 70.29, 78.09), (Drop) Loss 2.5272, Accuracy: (40.62, 60.86, 69.23), Time 4.22
2019-05-14 14:33:25,631: INFO: [train_wsdan.py:313]: 
	Batch 1300: (Raw) Loss 1.6798, Accuracy: (57.62, 78.48, 85.33), (Crop) Loss 2.0042, Accuracy: (49.81, 70.38, 78.13), (Drop) Loss 2.5234, Accuracy: (40.75, 60.98, 69.27), Time 4.23
2019-05-14 14:40:29,496: INFO: [train_wsdan.py:313]: 
	Batch 1400: (Raw) Loss 1.6787, Accuracy: (57.61, 78.46, 85.33), (Crop) Loss 2.0011, Accuracy: (49.90, 70.48, 78.22), (Drop) Loss 2.5223, Accuracy: (40.84, 61.04, 69.32), Time 4.21
2019-05-14 14:47:35,608: INFO: [train_wsdan.py:313]: 
	Batch 1500: (Raw) Loss 1.6794, Accuracy: (57.65, 78.42, 85.29), (Crop) Loss 2.0007, Accuracy: (49.96, 70.53, 78.21), (Drop) Loss 2.5236, Accuracy: (40.86, 61.05, 69.33), Time 4.36
2019-05-14 14:54:42,176: INFO: [train_wsdan.py:313]: 
	Batch 1600: (Raw) Loss 1.6764, Accuracy: (57.75, 78.46, 85.29), (Crop) Loss 1.9994, Accuracy: (50.02, 70.55, 78.26), (Drop) Loss 2.5199, Accuracy: (40.96, 61.06, 69.38), Time 4.26
2019-05-14 15:01:48,073: INFO: [train_wsdan.py:313]: 
	Batch 1700: (Raw) Loss 1.6756, Accuracy: (57.71, 78.48, 85.31), (Crop) Loss 1.9964, Accuracy: (50.07, 70.63, 78.35), (Drop) Loss 2.5200, Accuracy: (40.95, 61.06, 69.36), Time 4.30
2019-05-14 15:08:53,273: INFO: [train_wsdan.py:313]: 
	Batch 1800: (Raw) Loss 1.6735, Accuracy: (57.84, 78.49, 85.32), (Crop) Loss 1.9952, Accuracy: (50.15, 70.68, 78.40), (Drop) Loss 2.5216, Accuracy: (40.96, 61.02, 69.34), Time 4.28
2019-05-14 15:15:58,430: INFO: [train_wsdan.py:313]: 
	Batch 1900: (Raw) Loss 1.6740, Accuracy: (57.78, 78.45, 85.30), (Crop) Loss 1.9939, Accuracy: (50.11, 70.69, 78.43), (Drop) Loss 2.5243, Accuracy: (40.94, 60.97, 69.27), Time 4.25
2019-05-14 15:23:02,754: INFO: [train_wsdan.py:313]: 
	Batch 2000: (Raw) Loss 1.6707, Accuracy: (57.85, 78.52, 85.35), (Crop) Loss 1.9914, Accuracy: (50.17, 70.75, 78.48), (Drop) Loss 2.5206, Accuracy: (40.99, 61.01, 69.32), Time 4.22
2019-05-14 15:23:02,754: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 15:30:09,553: INFO: [train_wsdan.py:313]: 
	Batch 2100: (Raw) Loss 1.6693, Accuracy: (57.86, 78.56, 85.38), (Crop) Loss 1.9918, Accuracy: (50.16, 70.73, 78.47), (Drop) Loss 2.5179, Accuracy: (41.06, 61.11, 69.40), Time 4.23
2019-05-14 15:37:14,465: INFO: [train_wsdan.py:313]: 
	Batch 2200: (Raw) Loss 1.6665, Accuracy: (57.96, 78.62, 85.42), (Crop) Loss 1.9883, Accuracy: (50.26, 70.79, 78.53), (Drop) Loss 2.5159, Accuracy: (41.09, 61.14, 69.46), Time 4.34
2019-05-14 15:44:20,346: INFO: [train_wsdan.py:313]: 
	Batch 2300: (Raw) Loss 1.6613, Accuracy: (58.06, 78.72, 85.52), (Crop) Loss 1.9827, Accuracy: (50.34, 70.93, 78.67), (Drop) Loss 2.5123, Accuracy: (41.17, 61.23, 69.54), Time 4.25
2019-05-14 15:51:26,354: INFO: [train_wsdan.py:313]: 
	Batch 2400: (Raw) Loss 1.6606, Accuracy: (58.06, 78.75, 85.55), (Crop) Loss 1.9817, Accuracy: (50.41, 70.98, 78.70), (Drop) Loss 2.5105, Accuracy: (41.19, 61.26, 69.55), Time 4.28
2019-05-14 15:58:32,776: INFO: [train_wsdan.py:313]: 
	Batch 2500: (Raw) Loss 1.6574, Accuracy: (58.15, 78.83, 85.58), (Crop) Loss 1.9793, Accuracy: (50.46, 71.06, 78.75), (Drop) Loss 2.5098, Accuracy: (41.24, 61.31, 69.56), Time 4.28
2019-05-14 16:05:39,311: INFO: [train_wsdan.py:313]: 
	Batch 2600: (Raw) Loss 1.6564, Accuracy: (58.18, 78.85, 85.59), (Crop) Loss 1.9784, Accuracy: (50.49, 71.08, 78.73), (Drop) Loss 2.5118, Accuracy: (41.26, 61.28, 69.52), Time 4.25
2019-05-14 16:12:45,100: INFO: [train_wsdan.py:313]: 
	Batch 2700: (Raw) Loss 1.6532, Accuracy: (58.25, 78.89, 85.62), (Crop) Loss 1.9755, Accuracy: (50.56, 71.11, 78.77), (Drop) Loss 2.5123, Accuracy: (41.31, 61.29, 69.48), Time 4.32
2019-05-14 16:19:50,505: INFO: [train_wsdan.py:313]: 
	Batch 2800: (Raw) Loss 1.6498, Accuracy: (58.34, 78.94, 85.67), (Crop) Loss 1.9727, Accuracy: (50.62, 71.17, 78.82), (Drop) Loss 2.5095, Accuracy: (41.39, 61.39, 69.56), Time 4.21
2019-05-14 16:26:55,102: INFO: [train_wsdan.py:313]: 
	Batch 2900: (Raw) Loss 1.6474, Accuracy: (58.40, 78.99, 85.70), (Crop) Loss 1.9700, Accuracy: (50.65, 71.25, 78.86), (Drop) Loss 2.5081, Accuracy: (41.43, 61.40, 69.57), Time 4.27
2019-05-14 16:33:58,706: INFO: [train_wsdan.py:313]: 
	Batch 3000: (Raw) Loss 1.6455, Accuracy: (58.42, 79.03, 85.72), (Crop) Loss 1.9683, Accuracy: (50.66, 71.27, 78.87), (Drop) Loss 2.5071, Accuracy: (41.43, 61.40, 69.58), Time 4.21
2019-05-14 16:33:58,707: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 16:41:03,863: INFO: [train_wsdan.py:313]: 
	Batch 3100: (Raw) Loss 1.6425, Accuracy: (58.48, 79.08, 85.78), (Crop) Loss 1.9660, Accuracy: (50.72, 71.32, 78.95), (Drop) Loss 2.5057, Accuracy: (41.46, 61.40, 69.59), Time 4.20
2019-05-14 16:48:06,164: INFO: [train_wsdan.py:313]: 
	Batch 3200: (Raw) Loss 1.6412, Accuracy: (58.50, 79.12, 85.79), (Crop) Loss 1.9651, Accuracy: (50.74, 71.34, 78.95), (Drop) Loss 2.5056, Accuracy: (41.47, 61.40, 69.59), Time 4.27
2019-05-14 16:55:09,630: INFO: [train_wsdan.py:313]: 
	Batch 3300: (Raw) Loss 1.6377, Accuracy: (58.61, 79.18, 85.85), (Crop) Loss 1.9614, Accuracy: (50.85, 71.39, 78.98), (Drop) Loss 2.5032, Accuracy: (41.52, 61.42, 69.62), Time 4.19
2019-05-14 17:02:12,618: INFO: [train_wsdan.py:313]: 
	Batch 3400: (Raw) Loss 1.6351, Accuracy: (58.65, 79.21, 85.86), (Crop) Loss 1.9584, Accuracy: (50.91, 71.47, 79.02), (Drop) Loss 2.5032, Accuracy: (41.52, 61.39, 69.60), Time 4.29
2019-05-14 17:09:16,940: INFO: [train_wsdan.py:313]: 
	Batch 3500: (Raw) Loss 1.6319, Accuracy: (58.72, 79.26, 85.90), (Crop) Loss 1.9542, Accuracy: (50.97, 71.53, 79.08), (Drop) Loss 2.5016, Accuracy: (41.59, 61.41, 69.61), Time 4.28
2019-05-14 17:16:22,515: INFO: [train_wsdan.py:313]: 
	Batch 3600: (Raw) Loss 1.6296, Accuracy: (58.76, 79.31, 85.94), (Crop) Loss 1.9512, Accuracy: (51.03, 71.58, 79.14), (Drop) Loss 2.5031, Accuracy: (41.55, 61.39, 69.60), Time 4.22
2019-05-14 17:23:26,371: INFO: [train_wsdan.py:313]: 
	Batch 3700: (Raw) Loss 1.6263, Accuracy: (58.84, 79.37, 85.99), (Crop) Loss 1.9483, Accuracy: (51.07, 71.65, 79.17), (Drop) Loss 2.5014, Accuracy: (41.59, 61.39, 69.62), Time 4.31
2019-05-14 17:30:30,376: INFO: [train_wsdan.py:313]: 
	Batch 3800: (Raw) Loss 1.6241, Accuracy: (58.89, 79.39, 86.00), (Crop) Loss 1.9455, Accuracy: (51.13, 71.69, 79.19), (Drop) Loss 2.5001, Accuracy: (41.62, 61.42, 69.62), Time 4.25
2019-05-14 17:37:34,665: INFO: [train_wsdan.py:313]: 
	Batch 3900: (Raw) Loss 1.6233, Accuracy: (58.90, 79.39, 86.00), (Crop) Loss 1.9451, Accuracy: (51.16, 71.70, 79.19), (Drop) Loss 2.4998, Accuracy: (41.66, 61.43, 69.61), Time 4.34
2019-05-14 17:44:39,489: INFO: [train_wsdan.py:313]: 
	Batch 4000: (Raw) Loss 1.6216, Accuracy: (58.95, 79.42, 86.01), (Crop) Loss 1.9428, Accuracy: (51.22, 71.75, 79.22), (Drop) Loss 2.5004, Accuracy: (41.68, 61.42, 69.60), Time 4.21
2019-05-14 17:44:39,490: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 17:51:44,756: INFO: [train_wsdan.py:313]: 
	Batch 4100: (Raw) Loss 1.6202, Accuracy: (58.99, 79.45, 86.04), (Crop) Loss 1.9405, Accuracy: (51.27, 71.81, 79.27), (Drop) Loss 2.5008, Accuracy: (41.68, 61.40, 69.55), Time 4.24
2019-05-14 17:58:48,530: INFO: [train_wsdan.py:313]: 
	Batch 4200: (Raw) Loss 1.6174, Accuracy: (59.06, 79.50, 86.06), (Crop) Loss 1.9377, Accuracy: (51.33, 71.84, 79.29), (Drop) Loss 2.5006, Accuracy: (41.70, 61.41, 69.56), Time 4.21
2019-05-14 18:05:53,057: INFO: [train_wsdan.py:313]: 
	Batch 4300: (Raw) Loss 1.6159, Accuracy: (59.09, 79.51, 86.09), (Crop) Loss 1.9363, Accuracy: (51.35, 71.86, 79.31), (Drop) Loss 2.5015, Accuracy: (41.71, 61.39, 69.53), Time 4.25
2019-05-14 18:12:56,976: INFO: [train_wsdan.py:313]: 
	Batch 4400: (Raw) Loss 1.6135, Accuracy: (59.15, 79.54, 86.11), (Crop) Loss 1.9340, Accuracy: (51.43, 71.90, 79.34), (Drop) Loss 2.5001, Accuracy: (41.77, 61.42, 69.55), Time 4.35
2019-05-14 18:20:00,445: INFO: [train_wsdan.py:313]: 
	Batch 4500: (Raw) Loss 1.6111, Accuracy: (59.20, 79.57, 86.13), (Crop) Loss 1.9314, Accuracy: (51.45, 71.94, 79.37), (Drop) Loss 2.4993, Accuracy: (41.78, 61.43, 69.55), Time 4.19
2019-05-14 18:27:04,193: INFO: [train_wsdan.py:313]: 
	Batch 4600: (Raw) Loss 1.6090, Accuracy: (59.24, 79.61, 86.16), (Crop) Loss 1.9291, Accuracy: (51.49, 71.99, 79.42), (Drop) Loss 2.4975, Accuracy: (41.82, 61.48, 69.59), Time 4.27
2019-05-14 18:34:08,089: INFO: [train_wsdan.py:313]: 
	Batch 4700: (Raw) Loss 1.6073, Accuracy: (59.28, 79.66, 86.19), (Crop) Loss 1.9276, Accuracy: (51.51, 72.00, 79.44), (Drop) Loss 2.4959, Accuracy: (41.84, 61.51, 69.63), Time 4.32
2019-05-14 18:41:12,515: INFO: [train_wsdan.py:313]: 
	Batch 4800: (Raw) Loss 1.6040, Accuracy: (59.35, 79.71, 86.22), (Crop) Loss 1.9243, Accuracy: (51.57, 72.05, 79.51), (Drop) Loss 2.4933, Accuracy: (41.87, 61.56, 69.66), Time 4.25
2019-05-14 18:48:16,190: INFO: [train_wsdan.py:313]: 
	Batch 4900: (Raw) Loss 1.6012, Accuracy: (59.40, 79.74, 86.25), (Crop) Loss 1.9207, Accuracy: (51.62, 72.11, 79.57), (Drop) Loss 2.4909, Accuracy: (41.90, 61.60, 69.69), Time 4.24
2019-05-14 18:55:20,594: INFO: [train_wsdan.py:313]: 
	Batch 5000: (Raw) Loss 1.5985, Accuracy: (59.48, 79.77, 86.29), (Crop) Loss 1.9174, Accuracy: (51.71, 72.17, 79.61), (Drop) Loss 2.4893, Accuracy: (41.94, 61.63, 69.72), Time 4.22
2019-05-14 18:55:20,594: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 19:02:26,115: INFO: [train_wsdan.py:313]: 
	Batch 5100: (Raw) Loss 1.5962, Accuracy: (59.55, 79.81, 86.31), (Crop) Loss 1.9147, Accuracy: (51.75, 72.22, 79.66), (Drop) Loss 2.4874, Accuracy: (42.01, 61.67, 69.74), Time 4.35
2019-05-14 19:09:31,159: INFO: [train_wsdan.py:313]: 
	Batch 5200: (Raw) Loss 1.5932, Accuracy: (59.61, 79.85, 86.35), (Crop) Loss 1.9114, Accuracy: (51.81, 72.27, 79.68), (Drop) Loss 2.4866, Accuracy: (42.04, 61.66, 69.74), Time 4.18
2019-05-14 19:16:35,319: INFO: [train_wsdan.py:313]: 
	Batch 5300: (Raw) Loss 1.5916, Accuracy: (59.65, 79.88, 86.37), (Crop) Loss 1.9091, Accuracy: (51.85, 72.32, 79.73), (Drop) Loss 2.4865, Accuracy: (42.05, 61.69, 69.76), Time 4.15
2019-05-14 19:23:38,608: INFO: [train_wsdan.py:313]: 
	Batch 5400: (Raw) Loss 1.5896, Accuracy: (59.71, 79.91, 86.40), (Crop) Loss 1.9064, Accuracy: (51.92, 72.37, 79.76), (Drop) Loss 2.4844, Accuracy: (42.10, 61.73, 69.80), Time 4.16
2019-05-14 19:30:41,614: INFO: [train_wsdan.py:313]: 
	Batch 5500: (Raw) Loss 1.5869, Accuracy: (59.78, 79.94, 86.44), (Crop) Loss 1.9040, Accuracy: (51.97, 72.43, 79.82), (Drop) Loss 2.4822, Accuracy: (42.14, 61.76, 69.82), Time 4.13
2019-05-14 19:37:43,931: INFO: [train_wsdan.py:313]: 
	Batch 5600: (Raw) Loss 1.5848, Accuracy: (59.83, 79.98, 86.47), (Crop) Loss 1.9017, Accuracy: (52.01, 72.48, 79.86), (Drop) Loss 2.4800, Accuracy: (42.19, 61.79, 69.85), Time 4.30
2019-05-14 19:44:45,898: INFO: [train_wsdan.py:313]: 
	Batch 5700: (Raw) Loss 1.5826, Accuracy: (59.86, 80.02, 86.50), (Crop) Loss 1.8998, Accuracy: (52.06, 72.51, 79.89), (Drop) Loss 2.4788, Accuracy: (42.22, 61.80, 69.86), Time 4.17
2019-05-14 19:51:49,034: INFO: [train_wsdan.py:313]: 
	Batch 5800: (Raw) Loss 1.5812, Accuracy: (59.88, 80.03, 86.51), (Crop) Loss 1.8984, Accuracy: (52.09, 72.55, 79.92), (Drop) Loss 2.4792, Accuracy: (42.24, 61.80, 69.85), Time 4.27
2019-05-14 19:58:51,251: INFO: [train_wsdan.py:313]: 
	Batch 5900: (Raw) Loss 1.5790, Accuracy: (59.93, 80.07, 86.54), (Crop) Loss 1.8959, Accuracy: (52.15, 72.60, 79.95), (Drop) Loss 2.4784, Accuracy: (42.27, 61.80, 69.86), Time 4.18
2019-05-14 20:05:55,102: INFO: [train_wsdan.py:313]: 
	Batch 6000: (Raw) Loss 1.5766, Accuracy: (59.98, 80.12, 86.57), (Crop) Loss 1.8931, Accuracy: (52.21, 72.66, 80.01), (Drop) Loss 2.4774, Accuracy: (42.32, 61.84, 69.89), Time 4.33
2019-05-14 20:05:55,103: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 20:12:58,322: INFO: [train_wsdan.py:313]: 
	Batch 6100: (Raw) Loss 1.5743, Accuracy: (60.02, 80.15, 86.60), (Crop) Loss 1.8913, Accuracy: (52.24, 72.67, 80.03), (Drop) Loss 2.4760, Accuracy: (42.35, 61.86, 69.90), Time 4.19
2019-05-14 20:20:01,983: INFO: [train_wsdan.py:313]: 
	Batch 6200: (Raw) Loss 1.5716, Accuracy: (60.07, 80.18, 86.63), (Crop) Loss 1.8883, Accuracy: (52.30, 72.73, 80.08), (Drop) Loss 2.4734, Accuracy: (42.40, 61.90, 69.95), Time 4.25
2019-05-14 20:27:07,620: INFO: [train_wsdan.py:313]: 
	Batch 6300: (Raw) Loss 1.5693, Accuracy: (60.14, 80.21, 86.66), (Crop) Loss 1.8861, Accuracy: (52.35, 72.77, 80.11), (Drop) Loss 2.4729, Accuracy: (42.44, 61.92, 69.95), Time 4.30
2019-05-14 20:34:12,668: INFO: [train_wsdan.py:313]: 
	Batch 6400: (Raw) Loss 1.5673, Accuracy: (60.18, 80.25, 86.68), (Crop) Loss 1.8840, Accuracy: (52.39, 72.81, 80.14), (Drop) Loss 2.4713, Accuracy: (42.49, 61.96, 69.98), Time 4.21
2019-05-14 20:41:15,734: INFO: [train_wsdan.py:313]: 
	Batch 6500: (Raw) Loss 1.5649, Accuracy: (60.24, 80.29, 86.71), (Crop) Loss 1.8815, Accuracy: (52.46, 72.86, 80.17), (Drop) Loss 2.4695, Accuracy: (42.53, 62.00, 70.00), Time 4.24
2019-05-14 20:48:19,616: INFO: [train_wsdan.py:313]: 
	Batch 6600: (Raw) Loss 1.5629, Accuracy: (60.28, 80.32, 86.74), (Crop) Loss 1.8794, Accuracy: (52.49, 72.90, 80.21), (Drop) Loss 2.4688, Accuracy: (42.54, 62.01, 70.00), Time 4.18
2019-05-14 20:55:23,105: INFO: [train_wsdan.py:313]: 
	Batch 6700: (Raw) Loss 1.5612, Accuracy: (60.32, 80.35, 86.77), (Crop) Loss 1.8778, Accuracy: (52.53, 72.92, 80.24), (Drop) Loss 2.4696, Accuracy: (42.55, 62.00, 70.00), Time 4.14
2019-05-14 21:02:26,566: INFO: [train_wsdan.py:313]: 
	Batch 6800: (Raw) Loss 1.5596, Accuracy: (60.35, 80.37, 86.79), (Crop) Loss 1.8762, Accuracy: (52.57, 72.94, 80.25), (Drop) Loss 2.4709, Accuracy: (42.54, 61.98, 69.97), Time 4.24
2019-05-14 21:09:31,148: INFO: [train_wsdan.py:313]: 
	Batch 6900: (Raw) Loss 1.5570, Accuracy: (60.41, 80.41, 86.81), (Crop) Loss 1.8738, Accuracy: (52.64, 72.99, 80.28), (Drop) Loss 2.4703, Accuracy: (42.57, 62.00, 69.97), Time 4.32
2019-05-14 21:16:35,972: INFO: [train_wsdan.py:313]: 
	Batch 7000: (Raw) Loss 1.5553, Accuracy: (60.45, 80.43, 86.83), (Crop) Loss 1.8722, Accuracy: (52.69, 73.02, 80.30), (Drop) Loss 2.4702, Accuracy: (42.58, 62.02, 69.97), Time 4.41
2019-05-14 21:16:35,973: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 21:23:40,851: INFO: [train_wsdan.py:313]: 
	Batch 7100: (Raw) Loss 1.5540, Accuracy: (60.48, 80.46, 86.85), (Crop) Loss 1.8711, Accuracy: (52.73, 73.03, 80.31), (Drop) Loss 2.4700, Accuracy: (42.60, 62.03, 69.98), Time 4.25
2019-05-14 21:30:45,482: INFO: [train_wsdan.py:313]: 
	Batch 7200: (Raw) Loss 1.5515, Accuracy: (60.55, 80.51, 86.88), (Crop) Loss 1.8694, Accuracy: (52.76, 73.07, 80.33), (Drop) Loss 2.4691, Accuracy: (42.64, 62.05, 69.99), Time 4.23
2019-05-14 21:37:48,710: INFO: [train_wsdan.py:313]: 
	Batch 7300: (Raw) Loss 1.5491, Accuracy: (60.59, 80.55, 86.91), (Crop) Loss 1.8670, Accuracy: (52.81, 73.12, 80.37), (Drop) Loss 2.4689, Accuracy: (42.65, 62.07, 69.99), Time 4.33
2019-05-14 21:44:51,929: INFO: [train_wsdan.py:313]: 
	Batch 7400: (Raw) Loss 1.5473, Accuracy: (60.64, 80.59, 86.93), (Crop) Loss 1.8653, Accuracy: (52.86, 73.16, 80.40), (Drop) Loss 2.4690, Accuracy: (42.66, 62.06, 69.98), Time 4.27
2019-05-14 21:51:55,983: INFO: [train_wsdan.py:313]: 
	Batch 7500: (Raw) Loss 1.5449, Accuracy: (60.69, 80.62, 86.96), (Crop) Loss 1.8624, Accuracy: (52.91, 73.21, 80.45), (Drop) Loss 2.4696, Accuracy: (42.66, 62.06, 69.97), Time 4.22
2019-05-14 21:59:00,178: INFO: [train_wsdan.py:313]: 
	Batch 7600: (Raw) Loss 1.5427, Accuracy: (60.74, 80.66, 86.99), (Crop) Loss 1.8601, Accuracy: (52.96, 73.25, 80.49), (Drop) Loss 2.4701, Accuracy: (42.66, 62.05, 69.96), Time 4.17
2019-05-14 22:06:04,514: INFO: [train_wsdan.py:313]: 
	Batch 7700: (Raw) Loss 1.5405, Accuracy: (60.79, 80.69, 87.01), (Crop) Loss 1.8579, Accuracy: (53.01, 73.29, 80.51), (Drop) Loss 2.4700, Accuracy: (42.67, 62.04, 69.96), Time 4.25
2019-05-14 22:13:09,109: INFO: [train_wsdan.py:313]: 
	Batch 7800: (Raw) Loss 1.5386, Accuracy: (60.84, 80.72, 87.04), (Crop) Loss 1.8556, Accuracy: (53.06, 73.33, 80.54), (Drop) Loss 2.4705, Accuracy: (42.68, 62.04, 69.94), Time 4.19
2019-05-14 22:20:13,974: INFO: [train_wsdan.py:313]: 
	Batch 7900: (Raw) Loss 1.5360, Accuracy: (60.91, 80.76, 87.07), (Crop) Loss 1.8528, Accuracy: (53.12, 73.37, 80.58), (Drop) Loss 2.4700, Accuracy: (42.72, 62.04, 69.94), Time 4.23
2019-05-14 22:27:17,769: INFO: [train_wsdan.py:313]: 
	Batch 8000: (Raw) Loss 1.5345, Accuracy: (60.96, 80.79, 87.08), (Crop) Loss 1.8509, Accuracy: (53.16, 73.41, 80.62), (Drop) Loss 2.4706, Accuracy: (42.73, 62.02, 69.92), Time 4.21
2019-05-14 22:27:17,770: INFO: [train_wsdan.py:317]: saving the latest model from epoch 1
2019-05-14 22:34:24,766: INFO: [train_wsdan.py:313]: 
	Batch 8100: (Raw) Loss 1.5327, Accuracy: (60.99, 80.82, 87.11), (Crop) Loss 1.8491, Accuracy: (53.20, 73.45, 80.65), (Drop) Loss 2.4717, Accuracy: (42.73, 62.01, 69.90), Time 4.24
2019-05-14 22:41:29,106: INFO: [train_wsdan.py:313]: 
	Batch 8200: (Raw) Loss 1.5309, Accuracy: (61.03, 80.85, 87.13), (Crop) Loss 1.8472, Accuracy: (53.24, 73.48, 80.68), (Drop) Loss 2.4728, Accuracy: (42.73, 62.00, 69.88), Time 4.29
2019-05-14 22:47:42,327: INFO: [train_wsdan.py:345]: Train: (Raw) Loss 1.5297, Accuracy: (61.06, 80.87, 87.15), (Crop) Loss 1.8460, Accuracy: (53.27, 73.51, 80.70), (Drop) Loss 2.4730, Accuracy: (42.74, 61.99, 69.88), Time 35189.79
2019-05-14 22:49:22,652: INFO: [train_wsdan.py:438]: saving the best model from epoch 2
2019-05-14 22:49:24,410: INFO: [train_wsdan.py:449]: Valid: Loss 1.91150,  Accuracy: Top-1 54.85, Top-3 76.35, Top-5 83.62, Time 100.21
2019-05-14 22:49:24,419: INFO: [train_wsdan.py:203]: Epoch 003, Learning Rate 0.001
2019-05-17 08:11:10,823: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:19:17,727: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:19:25,831: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:19:25,904: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:19:25,929: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:19:28,236: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:22:50,359: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:22:52,568: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:22:52,620: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:22:52,636: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:22:53,702: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:24:58,484: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:25:00,683: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:25:00,734: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:25:00,750: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:25:01,822: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:25:01,822: INFO: [train_wsdan.py:215]: Epoch 002, Learning Rate 0.001
2019-05-17 08:31:30,002: INFO: [train_wsdan.py:325]: 
	Batch 100: (Raw) Loss 6.7806, Accuracy: (1.66, 2.56, 3.41), (Crop) Loss 6.5194, Accuracy: (2.56, 4.16, 5.50), (Drop) Loss 6.4716, Accuracy: (2.69, 4.72, 6.19), Time 3.40
2019-05-17 08:37:54,934: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:37:59,202: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:37:59,255: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:37:59,271: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:38:01,111: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:39:15,524: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:39:17,752: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:39:17,803: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:39:17,819: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:39:18,883: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:40:02,101: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:40:04,325: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:40:04,379: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:40:04,394: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:40:05,498: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:41:50,276: INFO: [train_wsdan.py:466]: saving the best model from epoch 2
2019-05-17 08:41:51,260: INFO: [train_wsdan.py:478]: Valid: Loss 1.84986,  Accuracy: Top-1 55.48, Top-3 76.13, Top-5 83.76, Time 104.67
2019-05-17 08:43:17,111: INFO: [train_wsdan.py:466]: saving the best model from epoch 3
2019-05-17 08:43:18,338: INFO: [train_wsdan.py:478]: Valid: Loss 1.84986,  Accuracy: Top-1 55.48, Top-3 76.13, Top-5 83.76, Time 85.75
2019-05-17 08:44:43,455: INFO: [train_wsdan.py:466]: saving the best model from epoch 4
2019-05-17 08:44:43,761: INFO: [train_wsdan.py:478]: Valid: Loss 1.84986,  Accuracy: Top-1 55.48, Top-3 76.13, Top-5 83.76, Time 85.02
2019-05-17 08:46:08,881: INFO: [train_wsdan.py:466]: saving the best model from epoch 5
2019-05-17 08:46:09,185: INFO: [train_wsdan.py:478]: Valid: Loss 1.84986,  Accuracy: Top-1 55.48, Top-3 76.13, Top-5 83.76, Time 85.02
2019-05-17 08:47:34,293: INFO: [train_wsdan.py:466]: saving the best model from epoch 6
2019-05-17 08:47:34,597: INFO: [train_wsdan.py:478]: Valid: Loss 1.84986,  Accuracy: Top-1 55.48, Top-3 76.13, Top-5 83.76, Time 85.01
2019-05-17 08:50:36,872: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 08:50:41,272: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 08:50:41,324: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 08:50:41,338: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 08:50:43,050: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 08:50:43,050: INFO: [train_wsdan.py:217]: Epoch 002, Learning Rate 0.001
2019-05-17 08:57:05,782: INFO: [train_wsdan.py:327]: 
	Batch 100: (Raw) Loss 1.1793, Accuracy: (70.12, 86.25, 91.84), (Crop) Loss 1.5188, Accuracy: (60.25, 78.53, 85.22), (Drop) Loss 2.3771, Accuracy: (47.50, 64.25, 70.94), Time 3.37
2019-05-17 09:22:39,829: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 09:22:42,608: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 09:22:42,670: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 09:22:42,692: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 09:22:43,783: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 09:22:43,783: INFO: [train_wsdan.py:219]: Epoch 002, Learning Rate 0.001
2019-05-17 09:29:06,786: INFO: [train_wsdan.py:329]: 
	Batch 100: (Raw) Loss 1.2193, Accuracy: (68.38, 86.44, 91.84), (Crop) Loss 1.5063, Accuracy: (59.56, 79.31, 86.12), (Drop) Loss 2.4416, Accuracy: (44.62, 63.31, 70.41), Time 3.40
2019-05-17 09:34:44,168: INFO: [train_wsdan.py:329]: 
	Batch 200: (Raw) Loss 1.2099, Accuracy: (68.86, 86.69, 91.56), (Crop) Loss 1.5134, Accuracy: (60.19, 79.45, 85.86), (Drop) Loss 2.3919, Accuracy: (45.14, 64.36, 71.22), Time 3.38
2019-05-17 10:33:09,173: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 10:33:16,887: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 10:33:16,941: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 10:33:16,957: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 10:33:18,776: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 10:33:18,776: INFO: [train_wsdan.py:219]: Epoch 002, Learning Rate 0.001
2019-05-17 10:35:44,688: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 10:35:47,053: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 10:35:47,105: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 10:35:47,121: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 10:35:48,225: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 10:35:48,225: INFO: [train_wsdan.py:219]: Epoch 002, Learning Rate 0.001
2019-05-17 10:37:55,382: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 10:37:58,092: INFO: [train_wsdan.py:482]: Valid: Loss 1.84057,  Accuracy: Top-1 55.48, Top-3 76.26, Top-5 84.10, Time 88.97
2019-05-17 10:39:28,193: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 10:39:30,811: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 10:39:30,864: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 10:39:30,880: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 10:39:32,009: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 10:39:32,009: INFO: [train_wsdan.py:219]: Epoch 002, Learning Rate 0.001
2019-05-17 10:45:44,937: INFO: [train_wsdan.py:329]: 
	Batch 100: (Raw) Loss 1.2349, Accuracy: (68.16, 86.28, 91.00), (Crop) Loss 1.5442, Accuracy: (59.25, 78.41, 85.12), (Drop) Loss 2.3708, Accuracy: (46.25, 64.12, 71.53), Time 3.41
2019-05-17 10:51:23,411: INFO: [train_wsdan.py:329]: 
	Batch 200: (Raw) Loss 1.2223, Accuracy: (68.59, 86.06, 91.19), (Crop) Loss 1.5158, Accuracy: (59.81, 78.97, 85.55), (Drop) Loss 2.3875, Accuracy: (46.09, 63.27, 70.75), Time 3.38
2019-05-17 10:52:53,339: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 10:52:54,547: INFO: [train_wsdan.py:482]: Valid: Loss 1.98820,  Accuracy: Top-1 54.68, Top-3 76.18, Top-5 83.59, Time 89.82
2019-05-17 10:58:24,624: INFO: [train_wsdan.py:329]: 
	Batch 300: (Raw) Loss 1.5425, Accuracy: (62.11, 80.67, 86.53), (Crop) Loss 1.8520, Accuracy: (54.62, 74.12, 81.16), (Drop) Loss 2.9126, Accuracy: (38.24, 54.41, 61.85), Time 3.31
2019-05-17 11:03:55,159: INFO: [train_wsdan.py:329]: 
	Batch 400: (Raw) Loss 1.6414, Accuracy: (59.82, 79.05, 85.20), (Crop) Loss 1.9401, Accuracy: (52.91, 72.70, 79.95), (Drop) Loss 3.1094, Accuracy: (34.80, 50.84, 58.41), Time 3.31
2019-05-17 11:05:16,117: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 11:05:17,512: INFO: [train_wsdan.py:482]: Valid: Loss 2.28066,  Accuracy: Top-1 43.46, Top-3 66.59, Top-5 74.81, Time 80.86
2019-05-17 11:10:47,415: INFO: [train_wsdan.py:329]: 
	Batch 500: (Raw) Loss 1.6833, Accuracy: (59.06, 78.44, 84.82), (Crop) Loss 1.9818, Accuracy: (52.11, 72.00, 79.35), (Drop) Loss 3.2726, Accuracy: (32.49, 47.99, 55.49), Time 3.28
2019-05-17 11:16:17,718: INFO: [train_wsdan.py:329]: 
	Batch 600: (Raw) Loss 1.6987, Accuracy: (58.54, 78.20, 84.67), (Crop) Loss 1.9940, Accuracy: (51.80, 71.77, 79.20), (Drop) Loss 3.3592, Accuracy: (31.25, 46.60, 54.18), Time 3.30
2019-05-17 11:17:38,715: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 11:17:40,042: INFO: [train_wsdan.py:482]: Valid: Loss 2.27017,  Accuracy: Top-1 44.23, Top-3 67.10, Top-5 75.70, Time 80.90
2019-05-17 11:23:09,943: INFO: [train_wsdan.py:329]: 
	Batch 700: (Raw) Loss 1.7103, Accuracy: (58.09, 77.92, 84.50), (Crop) Loss 1.9918, Accuracy: (51.54, 71.81, 79.20), (Drop) Loss 3.4682, Accuracy: (29.59, 44.67, 52.29), Time 3.29
2019-05-17 11:28:42,779: INFO: [train_wsdan.py:329]: 
	Batch 800: (Raw) Loss 1.7147, Accuracy: (57.93, 77.86, 84.43), (Crop) Loss 1.9906, Accuracy: (51.53, 71.76, 79.21), (Drop) Loss 3.5265, Accuracy: (28.68, 43.76, 51.26), Time 3.34
2019-05-17 11:30:02,550: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 11:30:03,668: INFO: [train_wsdan.py:482]: Valid: Loss 2.46717,  Accuracy: Top-1 42.31, Top-3 65.69, Top-5 73.35, Time 79.67
2019-05-17 11:35:37,364: INFO: [train_wsdan.py:329]: 
	Batch 900: (Raw) Loss 1.7201, Accuracy: (57.80, 77.72, 84.32), (Crop) Loss 1.9948, Accuracy: (51.48, 71.72, 79.10), (Drop) Loss 3.5404, Accuracy: (28.36, 43.52, 51.02), Time 3.31
2019-05-17 11:41:10,676: INFO: [train_wsdan.py:329]: 
	Batch 1000: (Raw) Loss 1.7301, Accuracy: (57.47, 77.53, 84.24), (Crop) Loss 2.0013, Accuracy: (51.21, 71.58, 79.05), (Drop) Loss 3.5470, Accuracy: (28.12, 43.38, 50.96), Time 3.33
2019-05-17 11:41:10,676: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 11:42:34,036: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 11:42:35,271: INFO: [train_wsdan.py:482]: Valid: Loss 2.09323,  Accuracy: Top-1 47.95, Top-3 69.65, Top-5 77.43, Time 81.95
2019-05-17 11:48:08,029: INFO: [train_wsdan.py:329]: 
	Batch 1100: (Raw) Loss 1.7212, Accuracy: (57.59, 77.66, 84.36), (Crop) Loss 1.9920, Accuracy: (51.40, 71.72, 79.17), (Drop) Loss 3.5695, Accuracy: (27.93, 42.99, 50.51), Time 3.30
2019-05-17 11:53:40,637: INFO: [train_wsdan.py:329]: 
	Batch 1200: (Raw) Loss 1.7171, Accuracy: (57.59, 77.79, 84.42), (Crop) Loss 1.9861, Accuracy: (51.45, 71.80, 79.21), (Drop) Loss 3.6104, Accuracy: (27.37, 42.27, 49.79), Time 3.32
2019-05-17 11:55:02,613: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 11:55:03,820: INFO: [train_wsdan.py:482]: Valid: Loss 2.11948,  Accuracy: Top-1 48.05, Top-3 68.80, Top-5 77.67, Time 81.88
2019-05-17 12:00:36,852: INFO: [train_wsdan.py:329]: 
	Batch 1300: (Raw) Loss 1.7122, Accuracy: (57.73, 77.83, 84.43), (Crop) Loss 1.9786, Accuracy: (51.63, 71.91, 79.29), (Drop) Loss 3.6409, Accuracy: (26.96, 41.74, 49.21), Time 3.30
2019-05-17 12:06:09,858: INFO: [train_wsdan.py:329]: 
	Batch 1400: (Raw) Loss 1.7086, Accuracy: (57.80, 77.93, 84.52), (Crop) Loss 1.9735, Accuracy: (51.67, 72.02, 79.41), (Drop) Loss 3.6657, Accuracy: (26.53, 41.31, 48.79), Time 3.33
2019-05-17 12:07:30,909: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 12:07:32,108: INFO: [train_wsdan.py:482]: Valid: Loss 2.05626,  Accuracy: Top-1 49.04, Top-3 70.38, Top-5 78.37, Time 80.95
2019-05-17 12:13:05,336: INFO: [train_wsdan.py:329]: 
	Batch 1500: (Raw) Loss 1.7064, Accuracy: (57.84, 77.93, 84.59), (Crop) Loss 1.9688, Accuracy: (51.73, 72.06, 79.47), (Drop) Loss 3.6774, Accuracy: (26.36, 41.17, 48.60), Time 3.28
2019-05-17 12:18:38,730: INFO: [train_wsdan.py:329]: 
	Batch 1600: (Raw) Loss 1.7024, Accuracy: (57.86, 78.01, 84.66), (Crop) Loss 1.9660, Accuracy: (51.74, 72.07, 79.48), (Drop) Loss 3.6992, Accuracy: (26.10, 40.79, 48.18), Time 3.32
2019-05-17 12:19:59,268: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 12:20:00,513: INFO: [train_wsdan.py:482]: Valid: Loss 2.12909,  Accuracy: Top-1 47.95, Top-3 70.28, Top-5 78.41, Time 80.44
2019-05-17 12:25:33,847: INFO: [train_wsdan.py:329]: 
	Batch 1700: (Raw) Loss 1.6965, Accuracy: (58.00, 78.11, 84.74), (Crop) Loss 1.9603, Accuracy: (51.83, 72.18, 79.54), (Drop) Loss 3.7027, Accuracy: (26.03, 40.70, 48.07), Time 3.34
2019-05-17 12:31:07,339: INFO: [train_wsdan.py:329]: 
	Batch 1800: (Raw) Loss 1.6952, Accuracy: (58.00, 78.15, 84.78), (Crop) Loss 1.9572, Accuracy: (51.89, 72.23, 79.60), (Drop) Loss 3.7130, Accuracy: (25.84, 40.47, 47.86), Time 3.34
2019-05-17 12:32:27,842: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 12:32:29,090: INFO: [train_wsdan.py:482]: Valid: Loss 2.16108,  Accuracy: Top-1 47.42, Top-3 70.05, Top-5 77.57, Time 80.40
2019-05-17 12:38:02,332: INFO: [train_wsdan.py:329]: 
	Batch 1900: (Raw) Loss 1.6897, Accuracy: (58.07, 78.26, 84.88), (Crop) Loss 1.9481, Accuracy: (51.99, 72.38, 79.76), (Drop) Loss 3.7174, Accuracy: (25.72, 40.39, 47.75), Time 3.36
2019-05-17 12:43:35,713: INFO: [train_wsdan.py:329]: 
	Batch 2000: (Raw) Loss 1.6847, Accuracy: (58.15, 78.37, 84.98), (Crop) Loss 1.9423, Accuracy: (52.06, 72.45, 79.85), (Drop) Loss 3.7183, Accuracy: (25.63, 40.35, 47.72), Time 3.33
2019-05-17 12:43:35,713: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 12:44:59,416: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 12:45:00,651: INFO: [train_wsdan.py:482]: Valid: Loss 1.99179,  Accuracy: Top-1 49.12, Top-3 72.22, Top-5 80.31, Time 82.28
2019-05-17 12:50:34,331: INFO: [train_wsdan.py:329]: 
	Batch 2100: (Raw) Loss 1.6776, Accuracy: (58.24, 78.50, 85.10), (Crop) Loss 1.9352, Accuracy: (52.20, 72.57, 79.92), (Drop) Loss 3.7084, Accuracy: (25.70, 40.53, 47.90), Time 3.33
2019-05-17 12:56:07,553: INFO: [train_wsdan.py:329]: 
	Batch 2200: (Raw) Loss 1.6709, Accuracy: (58.35, 78.61, 85.18), (Crop) Loss 1.9276, Accuracy: (52.36, 72.68, 80.01), (Drop) Loss 3.6978, Accuracy: (25.79, 40.67, 48.05), Time 3.34
2019-05-17 12:57:27,767: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 12:57:28,976: INFO: [train_wsdan.py:482]: Valid: Loss 1.97067,  Accuracy: Top-1 51.09, Top-3 72.58, Top-5 80.02, Time 80.12
2019-05-17 13:03:02,638: INFO: [train_wsdan.py:329]: 
	Batch 2300: (Raw) Loss 1.6662, Accuracy: (58.43, 78.67, 85.24), (Crop) Loss 1.9228, Accuracy: (52.45, 72.76, 80.07), (Drop) Loss 3.6815, Accuracy: (25.93, 40.90, 48.33), Time 3.34
2019-05-17 13:08:35,415: INFO: [train_wsdan.py:329]: 
	Batch 2400: (Raw) Loss 1.6605, Accuracy: (58.52, 78.79, 85.33), (Crop) Loss 1.9177, Accuracy: (52.51, 72.85, 80.14), (Drop) Loss 3.6804, Accuracy: (25.92, 40.91, 48.36), Time 3.33
2019-05-17 13:09:57,468: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 13:09:58,640: INFO: [train_wsdan.py:482]: Valid: Loss 1.89835,  Accuracy: Top-1 50.91, Top-3 73.69, Top-5 80.86, Time 81.95
2019-05-17 13:15:31,462: INFO: [train_wsdan.py:329]: 
	Batch 2500: (Raw) Loss 1.6519, Accuracy: (58.74, 78.93, 85.45), (Crop) Loss 1.9086, Accuracy: (52.70, 73.00, 80.25), (Drop) Loss 3.6779, Accuracy: (25.95, 40.95, 48.41), Time 3.32
2019-05-17 13:21:04,509: INFO: [train_wsdan.py:329]: 
	Batch 2600: (Raw) Loss 1.6472, Accuracy: (58.84, 79.01, 85.51), (Crop) Loss 1.9042, Accuracy: (52.78, 73.07, 80.27), (Drop) Loss 3.6723, Accuracy: (25.96, 41.01, 48.52), Time 3.33
2019-05-17 13:22:26,115: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 13:22:27,335: INFO: [train_wsdan.py:482]: Valid: Loss 1.92484,  Accuracy: Top-1 50.92, Top-3 72.40, Top-5 80.67, Time 81.51
2019-05-17 13:27:59,722: INFO: [train_wsdan.py:329]: 
	Batch 2700: (Raw) Loss 1.6419, Accuracy: (58.97, 79.09, 85.58), (Crop) Loss 1.8980, Accuracy: (52.90, 73.18, 80.36), (Drop) Loss 3.6615, Accuracy: (26.09, 41.19, 48.68), Time 3.30
2019-05-17 13:33:32,249: INFO: [train_wsdan.py:329]: 
	Batch 2800: (Raw) Loss 1.6359, Accuracy: (59.09, 79.20, 85.66), (Crop) Loss 1.8929, Accuracy: (53.01, 73.28, 80.45), (Drop) Loss 3.6497, Accuracy: (26.22, 41.40, 48.89), Time 3.32
2019-05-17 13:34:53,221: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 13:34:54,431: INFO: [train_wsdan.py:482]: Valid: Loss 1.84888,  Accuracy: Top-1 52.26, Top-3 73.86, Top-5 81.98, Time 80.87
2019-05-17 13:40:27,943: INFO: [train_wsdan.py:329]: 
	Batch 2900: (Raw) Loss 1.6312, Accuracy: (59.18, 79.27, 85.72), (Crop) Loss 1.8880, Accuracy: (53.11, 73.37, 80.52), (Drop) Loss 3.6406, Accuracy: (26.30, 41.58, 49.05), Time 3.34
2019-05-17 13:46:00,830: INFO: [train_wsdan.py:329]: 
	Batch 3000: (Raw) Loss 1.6259, Accuracy: (59.26, 79.38, 85.80), (Crop) Loss 1.8836, Accuracy: (53.17, 73.44, 80.58), (Drop) Loss 3.6315, Accuracy: (26.38, 41.72, 49.20), Time 3.30
2019-05-17 13:46:00,831: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 13:47:23,971: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 13:47:25,196: INFO: [train_wsdan.py:482]: Valid: Loss 1.84603,  Accuracy: Top-1 52.90, Top-3 74.40, Top-5 81.42, Time 81.72
2019-05-17 13:52:57,858: INFO: [train_wsdan.py:329]: 
	Batch 3100: (Raw) Loss 1.6212, Accuracy: (59.34, 79.42, 85.85), (Crop) Loss 1.8774, Accuracy: (53.28, 73.55, 80.64), (Drop) Loss 3.6231, Accuracy: (26.47, 41.81, 49.32), Time 3.31
2019-05-17 13:58:30,548: INFO: [train_wsdan.py:329]: 
	Batch 3200: (Raw) Loss 1.6168, Accuracy: (59.43, 79.49, 85.92), (Crop) Loss 1.8724, Accuracy: (53.37, 73.64, 80.73), (Drop) Loss 3.6141, Accuracy: (26.58, 41.95, 49.49), Time 3.35
2019-05-17 13:59:49,860: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 13:59:51,076: INFO: [train_wsdan.py:482]: Valid: Loss 1.82125,  Accuracy: Top-1 53.92, Top-3 74.88, Top-5 82.23, Time 79.21
2019-05-17 14:05:23,883: INFO: [train_wsdan.py:329]: 
	Batch 3300: (Raw) Loss 1.6133, Accuracy: (59.52, 79.55, 85.98), (Crop) Loss 1.8682, Accuracy: (53.44, 73.71, 80.81), (Drop) Loss 3.6030, Accuracy: (26.70, 42.13, 49.67), Time 3.31
2019-05-17 14:10:56,177: INFO: [train_wsdan.py:329]: 
	Batch 3400: (Raw) Loss 1.6090, Accuracy: (59.58, 79.61, 86.06), (Crop) Loss 1.8642, Accuracy: (53.51, 73.79, 80.86), (Drop) Loss 3.5818, Accuracy: (26.96, 42.47, 50.04), Time 3.33
2019-05-17 14:12:16,193: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 14:12:17,387: INFO: [train_wsdan.py:482]: Valid: Loss 1.87486,  Accuracy: Top-1 52.21, Top-3 74.30, Top-5 81.17, Time 79.92
2019-05-17 14:17:50,223: INFO: [train_wsdan.py:329]: 
	Batch 3500: (Raw) Loss 1.6052, Accuracy: (59.68, 79.69, 86.13), (Crop) Loss 1.8600, Accuracy: (53.59, 73.86, 80.95), (Drop) Loss 3.5825, Accuracy: (26.94, 42.48, 50.03), Time 3.33
2019-05-17 14:23:23,137: INFO: [train_wsdan.py:329]: 
	Batch 3600: (Raw) Loss 1.6012, Accuracy: (59.77, 79.77, 86.20), (Crop) Loss 1.8551, Accuracy: (53.69, 73.96, 81.03), (Drop) Loss 3.5790, Accuracy: (26.96, 42.53, 50.10), Time 3.31
2019-05-17 14:24:42,885: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 14:24:44,095: INFO: [train_wsdan.py:482]: Valid: Loss 1.83844,  Accuracy: Top-1 53.40, Top-3 74.57, Top-5 81.76, Time 79.63
2019-05-17 14:30:16,756: INFO: [train_wsdan.py:329]: 
	Batch 3700: (Raw) Loss 1.5967, Accuracy: (59.85, 79.83, 86.27), (Crop) Loss 1.8499, Accuracy: (53.77, 74.06, 81.11), (Drop) Loss 3.5880, Accuracy: (26.86, 42.37, 49.94), Time 3.32
2019-05-17 14:35:49,472: INFO: [train_wsdan.py:329]: 
	Batch 3800: (Raw) Loss 1.5923, Accuracy: (59.96, 79.91, 86.32), (Crop) Loss 1.8461, Accuracy: (53.85, 74.11, 81.17), (Drop) Loss 3.5931, Accuracy: (26.83, 42.32, 49.85), Time 3.34
2019-05-17 14:37:08,486: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 14:37:09,508: INFO: [train_wsdan.py:482]: Valid: Loss 1.92473,  Accuracy: Top-1 50.94, Top-3 73.55, Top-5 80.78, Time 78.90
2019-05-17 14:42:42,482: INFO: [train_wsdan.py:329]: 
	Batch 3900: (Raw) Loss 1.5900, Accuracy: (60.00, 79.96, 86.36), (Crop) Loss 1.8433, Accuracy: (53.87, 74.15, 81.19), (Drop) Loss 3.5898, Accuracy: (26.85, 42.36, 49.90), Time 3.32
2019-05-17 14:48:14,999: INFO: [train_wsdan.py:329]: 
	Batch 4000: (Raw) Loss 1.5870, Accuracy: (60.08, 80.01, 86.41), (Crop) Loss 1.8406, Accuracy: (53.92, 74.21, 81.22), (Drop) Loss 3.5803, Accuracy: (26.96, 42.53, 50.08), Time 3.32
2019-05-17 14:48:15,014: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 14:49:37,683: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 14:49:38,903: INFO: [train_wsdan.py:482]: Valid: Loss 1.83222,  Accuracy: Top-1 53.27, Top-3 74.27, Top-5 81.47, Time 81.25
2019-05-17 14:55:11,625: INFO: [train_wsdan.py:329]: 
	Batch 4100: (Raw) Loss 1.5830, Accuracy: (60.17, 80.06, 86.46), (Crop) Loss 1.8366, Accuracy: (54.01, 74.27, 81.28), (Drop) Loss 3.5737, Accuracy: (27.06, 42.65, 50.18), Time 3.33
2019-05-17 15:00:44,730: INFO: [train_wsdan.py:329]: 
	Batch 4200: (Raw) Loss 1.5781, Accuracy: (60.28, 80.14, 86.52), (Crop) Loss 1.8326, Accuracy: (54.10, 74.32, 81.33), (Drop) Loss 3.5683, Accuracy: (27.13, 42.75, 50.27), Time 3.32
2019-05-17 15:02:03,012: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 15:02:04,209: INFO: [train_wsdan.py:482]: Valid: Loss 1.83998,  Accuracy: Top-1 52.20, Top-3 73.75, Top-5 81.79, Time 78.17
2019-05-17 15:07:37,190: INFO: [train_wsdan.py:329]: 
	Batch 4300: (Raw) Loss 1.5739, Accuracy: (60.40, 80.21, 86.58), (Crop) Loss 1.8285, Accuracy: (54.18, 74.38, 81.40), (Drop) Loss 3.5574, Accuracy: (27.27, 42.91, 50.42), Time 3.33
2019-05-17 15:13:10,575: INFO: [train_wsdan.py:329]: 
	Batch 4400: (Raw) Loss 1.5700, Accuracy: (60.49, 80.26, 86.62), (Crop) Loss 1.8242, Accuracy: (54.26, 74.45, 81.47), (Drop) Loss 3.5466, Accuracy: (27.42, 43.08, 50.60), Time 3.34
2019-05-17 15:14:29,353: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 15:14:30,542: INFO: [train_wsdan.py:482]: Valid: Loss 1.77192,  Accuracy: Top-1 55.02, Top-3 74.93, Top-5 82.08, Time 78.67
2019-05-17 15:20:03,884: INFO: [train_wsdan.py:329]: 
	Batch 4500: (Raw) Loss 1.5649, Accuracy: (60.60, 80.34, 86.67), (Crop) Loss 1.8188, Accuracy: (54.39, 74.54, 81.54), (Drop) Loss 3.5310, Accuracy: (27.64, 43.36, 50.88), Time 3.30
2019-05-17 15:25:36,607: INFO: [train_wsdan.py:329]: 
	Batch 4600: (Raw) Loss 1.5605, Accuracy: (60.71, 80.41, 86.71), (Crop) Loss 1.8138, Accuracy: (54.49, 74.61, 81.60), (Drop) Loss 3.5230, Accuracy: (27.76, 43.49, 50.99), Time 3.37
2019-05-17 15:26:55,734: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 15:26:56,925: INFO: [train_wsdan.py:482]: Valid: Loss 1.74864,  Accuracy: Top-1 56.17, Top-3 75.82, Top-5 83.28, Time 79.03
2019-05-17 15:32:29,671: INFO: [train_wsdan.py:329]: 
	Batch 4700: (Raw) Loss 1.5567, Accuracy: (60.81, 80.46, 86.75), (Crop) Loss 1.8091, Accuracy: (54.61, 74.68, 81.64), (Drop) Loss 3.5129, Accuracy: (27.91, 43.66, 51.16), Time 3.31
2019-05-17 15:38:02,459: INFO: [train_wsdan.py:329]: 
	Batch 4800: (Raw) Loss 1.5522, Accuracy: (60.89, 80.55, 86.81), (Crop) Loss 1.8045, Accuracy: (54.71, 74.76, 81.70), (Drop) Loss 3.5094, Accuracy: (27.95, 43.72, 51.22), Time 3.33
2019-05-17 15:39:21,302: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 15:39:22,491: INFO: [train_wsdan.py:482]: Valid: Loss 1.79622,  Accuracy: Top-1 55.04, Top-3 76.89, Top-5 83.52, Time 78.75
2019-05-17 15:44:55,432: INFO: [train_wsdan.py:329]: 
	Batch 4900: (Raw) Loss 1.5496, Accuracy: (60.96, 80.58, 86.83), (Crop) Loss 1.8022, Accuracy: (54.74, 74.81, 81.74), (Drop) Loss 3.5056, Accuracy: (28.00, 43.78, 51.27), Time 3.31
2019-05-17 15:50:28,566: INFO: [train_wsdan.py:329]: 
	Batch 5000: (Raw) Loss 1.5459, Accuracy: (61.03, 80.63, 86.87), (Crop) Loss 1.7984, Accuracy: (54.81, 74.86, 81.78), (Drop) Loss 3.4973, Accuracy: (28.09, 43.91, 51.42), Time 3.31
2019-05-17 15:50:28,608: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 15:51:50,333: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 15:51:51,535: INFO: [train_wsdan.py:482]: Valid: Loss 1.69486,  Accuracy: Top-1 55.88, Top-3 77.36, Top-5 84.10, Time 80.31
2019-05-17 15:57:24,275: INFO: [train_wsdan.py:329]: 
	Batch 5100: (Raw) Loss 1.5426, Accuracy: (61.10, 80.69, 86.91), (Crop) Loss 1.7950, Accuracy: (54.87, 74.94, 81.85), (Drop) Loss 3.4931, Accuracy: (28.13, 43.98, 51.49), Time 3.33
2019-05-17 16:02:57,254: INFO: [train_wsdan.py:329]: 
	Batch 5200: (Raw) Loss 1.5387, Accuracy: (61.19, 80.76, 86.97), (Crop) Loss 1.7917, Accuracy: (54.93, 75.00, 81.89), (Drop) Loss 3.4844, Accuracy: (28.25, 44.13, 51.64), Time 3.32
2019-05-17 16:04:15,736: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 16:04:16,909: INFO: [train_wsdan.py:482]: Valid: Loss 1.73456,  Accuracy: Top-1 56.06, Top-3 76.69, Top-5 83.64, Time 78.35
2019-05-17 16:09:49,490: INFO: [train_wsdan.py:329]: 
	Batch 5300: (Raw) Loss 1.5360, Accuracy: (61.24, 80.82, 87.01), (Crop) Loss 1.7887, Accuracy: (55.00, 75.04, 81.94), (Drop) Loss 3.4777, Accuracy: (28.35, 44.23, 51.75), Time 3.32
2019-05-17 16:15:22,470: INFO: [train_wsdan.py:329]: 
	Batch 5400: (Raw) Loss 1.5321, Accuracy: (61.32, 80.89, 87.06), (Crop) Loss 1.7847, Accuracy: (55.09, 75.10, 81.99), (Drop) Loss 3.4652, Accuracy: (28.52, 44.45, 51.96), Time 3.33
2019-05-17 16:16:41,879: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 16:16:43,066: INFO: [train_wsdan.py:482]: Valid: Loss 1.76005,  Accuracy: Top-1 55.86, Top-3 76.47, Top-5 83.44, Time 79.30
2019-05-17 16:22:16,159: INFO: [train_wsdan.py:329]: 
	Batch 5500: (Raw) Loss 1.5286, Accuracy: (61.41, 80.96, 87.10), (Crop) Loss 1.7813, Accuracy: (55.17, 75.17, 82.03), (Drop) Loss 3.4543, Accuracy: (28.70, 44.65, 52.15), Time 3.34
2019-05-17 16:27:49,557: INFO: [train_wsdan.py:329]: 
	Batch 5600: (Raw) Loss 1.5255, Accuracy: (61.47, 81.01, 87.15), (Crop) Loss 1.7782, Accuracy: (55.23, 75.22, 82.06), (Drop) Loss 3.4397, Accuracy: (28.90, 44.88, 52.38), Time 3.32
2019-05-17 16:29:07,168: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 16:29:08,234: INFO: [train_wsdan.py:482]: Valid: Loss 1.79224,  Accuracy: Top-1 54.26, Top-3 74.81, Top-5 82.74, Time 77.48
2019-05-17 16:34:40,649: INFO: [train_wsdan.py:329]: 
	Batch 5700: (Raw) Loss 1.5228, Accuracy: (61.53, 81.05, 87.20), (Crop) Loss 1.7756, Accuracy: (55.29, 75.27, 82.10), (Drop) Loss 3.4337, Accuracy: (29.00, 44.98, 52.49), Time 3.33
2019-05-17 16:40:13,447: INFO: [train_wsdan.py:329]: 
	Batch 5800: (Raw) Loss 1.5199, Accuracy: (61.61, 81.10, 87.23), (Crop) Loss 1.7725, Accuracy: (55.35, 75.31, 82.13), (Drop) Loss 3.4249, Accuracy: (29.11, 45.11, 52.63), Time 3.32
2019-05-17 16:41:31,087: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 16:41:32,286: INFO: [train_wsdan.py:482]: Valid: Loss 1.72506,  Accuracy: Top-1 55.65, Top-3 76.62, Top-5 83.10, Time 77.55
2019-05-17 16:47:04,549: INFO: [train_wsdan.py:329]: 
	Batch 5900: (Raw) Loss 1.5173, Accuracy: (61.66, 81.14, 87.26), (Crop) Loss 1.7700, Accuracy: (55.41, 75.36, 82.16), (Drop) Loss 3.4200, Accuracy: (29.17, 45.20, 52.72), Time 3.32
2019-05-17 16:52:37,232: INFO: [train_wsdan.py:329]: 
	Batch 6000: (Raw) Loss 1.5145, Accuracy: (61.73, 81.19, 87.29), (Crop) Loss 1.7674, Accuracy: (55.48, 75.40, 82.20), (Drop) Loss 3.4142, Accuracy: (29.25, 45.30, 52.81), Time 3.35
2019-05-17 16:52:37,232: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 16:53:58,222: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 16:53:59,437: INFO: [train_wsdan.py:482]: Valid: Loss 1.68412,  Accuracy: Top-1 55.81, Top-3 77.33, Top-5 84.71, Time 79.57
2019-05-17 16:59:31,777: INFO: [train_wsdan.py:329]: 
	Batch 6100: (Raw) Loss 1.5109, Accuracy: (61.84, 81.24, 87.33), (Crop) Loss 1.7636, Accuracy: (55.57, 75.47, 82.25), (Drop) Loss 3.4032, Accuracy: (29.41, 45.49, 53.00), Time 3.33
2019-05-17 17:05:04,449: INFO: [train_wsdan.py:329]: 
	Batch 6200: (Raw) Loss 1.5073, Accuracy: (61.93, 81.30, 87.37), (Crop) Loss 1.7605, Accuracy: (55.66, 75.51, 82.28), (Drop) Loss 3.3875, Accuracy: (29.62, 45.76, 53.28), Time 3.34
2019-05-17 17:06:22,142: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 17:06:23,356: INFO: [train_wsdan.py:482]: Valid: Loss 1.71069,  Accuracy: Top-1 55.56, Top-3 76.56, Top-5 83.94, Time 77.60
2019-05-17 17:11:56,103: INFO: [train_wsdan.py:329]: 
	Batch 6300: (Raw) Loss 1.5042, Accuracy: (62.00, 81.35, 87.41), (Crop) Loss 1.7577, Accuracy: (55.71, 75.55, 82.32), (Drop) Loss 3.3776, Accuracy: (29.76, 45.92, 53.44), Time 3.31
2019-05-17 17:17:28,929: INFO: [train_wsdan.py:329]: 
	Batch 6400: (Raw) Loss 1.5011, Accuracy: (62.08, 81.40, 87.44), (Crop) Loss 1.7544, Accuracy: (55.79, 75.60, 82.36), (Drop) Loss 3.3736, Accuracy: (29.82, 45.99, 53.50), Time 3.39
2019-05-17 17:18:48,503: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 17:18:49,690: INFO: [train_wsdan.py:482]: Valid: Loss 1.62568,  Accuracy: Top-1 57.11, Top-3 77.86, Top-5 85.40, Time 79.48
2019-05-17 17:24:22,450: INFO: [train_wsdan.py:329]: 
	Batch 6500: (Raw) Loss 1.4976, Accuracy: (62.16, 81.47, 87.49), (Crop) Loss 1.7509, Accuracy: (55.87, 75.66, 82.41), (Drop) Loss 3.3723, Accuracy: (29.85, 46.01, 53.53), Time 3.32
2019-05-17 17:29:54,980: INFO: [train_wsdan.py:329]: 
	Batch 6600: (Raw) Loss 1.4944, Accuracy: (62.23, 81.51, 87.52), (Crop) Loss 1.7479, Accuracy: (55.92, 75.70, 82.44), (Drop) Loss 3.3711, Accuracy: (29.88, 46.03, 53.54), Time 3.31
2019-05-17 17:31:12,968: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 17:31:14,149: INFO: [train_wsdan.py:482]: Valid: Loss 1.57608,  Accuracy: Top-1 58.67, Top-3 79.12, Top-5 85.38, Time 77.89
2019-05-17 17:36:46,778: INFO: [train_wsdan.py:329]: 
	Batch 6700: (Raw) Loss 1.4913, Accuracy: (62.31, 81.56, 87.56), (Crop) Loss 1.7447, Accuracy: (55.98, 75.75, 82.47), (Drop) Loss 3.3665, Accuracy: (29.94, 46.11, 53.61), Time 3.34
2019-05-17 17:42:19,665: INFO: [train_wsdan.py:329]: 
	Batch 6800: (Raw) Loss 1.4877, Accuracy: (62.40, 81.62, 87.60), (Crop) Loss 1.7412, Accuracy: (56.05, 75.83, 82.53), (Drop) Loss 3.3607, Accuracy: (30.02, 46.21, 53.70), Time 3.33
2019-05-17 17:43:37,983: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 17:43:39,138: INFO: [train_wsdan.py:482]: Valid: Loss 1.59002,  Accuracy: Top-1 57.83, Top-3 79.14, Top-5 84.58, Time 78.22
2019-05-17 17:49:11,825: INFO: [train_wsdan.py:329]: 
	Batch 6900: (Raw) Loss 1.4842, Accuracy: (62.49, 81.68, 87.65), (Crop) Loss 1.7373, Accuracy: (56.12, 75.90, 82.58), (Drop) Loss 3.3540, Accuracy: (30.11, 46.32, 53.81), Time 3.32
2019-05-17 17:54:44,683: INFO: [train_wsdan.py:329]: 
	Batch 7000: (Raw) Loss 1.4807, Accuracy: (62.58, 81.75, 87.70), (Crop) Loss 1.7337, Accuracy: (56.19, 75.95, 82.62), (Drop) Loss 3.3504, Accuracy: (30.17, 46.37, 53.87), Time 3.29
2019-05-17 17:54:44,711: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 17:56:06,528: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 17:56:07,702: INFO: [train_wsdan.py:482]: Valid: Loss 1.63697,  Accuracy: Top-1 57.17, Top-3 78.02, Top-5 85.15, Time 80.36
2019-05-17 18:01:40,920: INFO: [train_wsdan.py:329]: 
	Batch 7100: (Raw) Loss 1.4780, Accuracy: (62.63, 81.79, 87.73), (Crop) Loss 1.7312, Accuracy: (56.24, 75.99, 82.65), (Drop) Loss 3.3457, Accuracy: (30.24, 46.45, 53.95), Time 3.34
2019-05-17 18:07:13,857: INFO: [train_wsdan.py:329]: 
	Batch 7200: (Raw) Loss 1.4756, Accuracy: (62.70, 81.83, 87.75), (Crop) Loss 1.7287, Accuracy: (56.30, 76.03, 82.68), (Drop) Loss 3.3413, Accuracy: (30.32, 46.53, 54.03), Time 3.31
2019-05-17 18:08:33,249: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 18:08:34,428: INFO: [train_wsdan.py:482]: Valid: Loss 1.78413,  Accuracy: Top-1 54.28, Top-3 74.75, Top-5 82.19, Time 79.24
2019-05-17 18:14:07,490: INFO: [train_wsdan.py:329]: 
	Batch 7300: (Raw) Loss 1.4736, Accuracy: (62.75, 81.87, 87.77), (Crop) Loss 1.7270, Accuracy: (56.35, 76.06, 82.71), (Drop) Loss 3.3351, Accuracy: (30.41, 46.64, 54.14), Time 3.33
2019-05-17 18:19:40,889: INFO: [train_wsdan.py:329]: 
	Batch 7400: (Raw) Loss 1.4715, Accuracy: (62.80, 81.91, 87.80), (Crop) Loss 1.7249, Accuracy: (56.41, 76.10, 82.74), (Drop) Loss 3.3241, Accuracy: (30.58, 46.84, 54.33), Time 3.32
2019-05-17 18:21:00,565: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 18:21:01,739: INFO: [train_wsdan.py:482]: Valid: Loss 1.61667,  Accuracy: Top-1 57.55, Top-3 78.58, Top-5 85.01, Time 79.54
2019-05-17 18:26:35,196: INFO: [train_wsdan.py:329]: 
	Batch 7500: (Raw) Loss 1.4688, Accuracy: (62.88, 81.95, 87.83), (Crop) Loss 1.7220, Accuracy: (56.46, 76.13, 82.78), (Drop) Loss 3.3156, Accuracy: (30.70, 46.97, 54.48), Time 3.32
2019-05-17 18:32:08,326: INFO: [train_wsdan.py:329]: 
	Batch 7600: (Raw) Loss 1.4662, Accuracy: (62.93, 82.00, 87.87), (Crop) Loss 1.7191, Accuracy: (56.52, 76.17, 82.82), (Drop) Loss 3.3066, Accuracy: (30.83, 47.12, 54.64), Time 3.32
2019-05-17 18:33:27,710: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 18:33:28,887: INFO: [train_wsdan.py:482]: Valid: Loss 1.61998,  Accuracy: Top-1 58.37, Top-3 78.40, Top-5 85.05, Time 79.25
2019-05-17 18:39:01,444: INFO: [train_wsdan.py:329]: 
	Batch 7700: (Raw) Loss 1.4630, Accuracy: (63.00, 82.05, 87.91), (Crop) Loss 1.7163, Accuracy: (56.59, 76.22, 82.86), (Drop) Loss 3.2955, Accuracy: (30.99, 47.30, 54.82), Time 3.31
2019-05-17 18:44:34,138: INFO: [train_wsdan.py:329]: 
	Batch 7800: (Raw) Loss 1.4598, Accuracy: (63.08, 82.11, 87.95), (Crop) Loss 1.7126, Accuracy: (56.67, 76.28, 82.91), (Drop) Loss 3.2873, Accuracy: (31.12, 47.43, 54.96), Time 3.32
2019-05-17 18:45:52,259: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 18:45:53,385: INFO: [train_wsdan.py:482]: Valid: Loss 1.67288,  Accuracy: Top-1 57.29, Top-3 78.25, Top-5 84.89, Time 77.96
2019-05-17 18:51:26,052: INFO: [train_wsdan.py:329]: 
	Batch 7900: (Raw) Loss 1.4573, Accuracy: (63.13, 82.16, 87.99), (Crop) Loss 1.7102, Accuracy: (56.72, 76.32, 82.94), (Drop) Loss 3.2819, Accuracy: (31.19, 47.53, 55.06), Time 3.32
2019-05-17 18:56:58,492: INFO: [train_wsdan.py:329]: 
	Batch 8000: (Raw) Loss 1.4551, Accuracy: (63.18, 82.20, 88.02), (Crop) Loss 1.7081, Accuracy: (56.76, 76.36, 82.96), (Drop) Loss 3.2736, Accuracy: (31.32, 47.67, 55.19), Time 3.31
2019-05-17 18:56:58,492: INFO: [train_wsdan.py:333]: saving the latest model from epoch 2
2019-05-17 18:58:20,261: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 18:58:21,440: INFO: [train_wsdan.py:482]: Valid: Loss 1.59355,  Accuracy: Top-1 58.98, Top-3 78.69, Top-5 85.14, Time 80.39
2019-05-17 19:03:54,092: INFO: [train_wsdan.py:329]: 
	Batch 8100: (Raw) Loss 1.4521, Accuracy: (63.25, 82.25, 88.05), (Crop) Loss 1.7046, Accuracy: (56.83, 76.42, 83.01), (Drop) Loss 3.2654, Accuracy: (31.45, 47.80, 55.33), Time 3.32
2019-05-17 19:09:26,778: INFO: [train_wsdan.py:329]: 
	Batch 8200: (Raw) Loss 1.4498, Accuracy: (63.31, 82.29, 88.08), (Crop) Loss 1.7022, Accuracy: (56.88, 76.46, 83.04), (Drop) Loss 3.2607, Accuracy: (31.52, 47.89, 55.41), Time 3.33
2019-05-17 19:10:44,864: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 19:10:46,037: INFO: [train_wsdan.py:482]: Valid: Loss 1.63463,  Accuracy: Top-1 57.04, Top-3 78.68, Top-5 84.91, Time 77.99
2019-05-17 19:16:01,623: INFO: [train_wsdan.py:375]: Train: (Raw) Loss 1.4477, Accuracy: (63.36, 82.32, 88.11), (Crop) Loss 1.6999, Accuracy: (56.92, 76.50, 83.07), (Drop) Loss 3.2583, Accuracy: (31.55, 47.92, 55.45), Time 30989.61
2019-05-17 19:17:18,599: INFO: [train_wsdan.py:470]: saving the best model from epoch 2
2019-05-17 19:17:19,835: INFO: [train_wsdan.py:482]: Valid: Loss 1.46935,  Accuracy: Top-1 60.13, Top-3 80.94, Top-5 86.58, Time 76.87
2019-05-17 19:17:19,842: INFO: [train_wsdan.py:219]: Epoch 003, Learning Rate 0.0006561
2019-05-17 19:23:08,418: INFO: [train_wsdan.py:329]: 
	Batch 100: (Raw) Loss 1.1787, Accuracy: (70.31, 87.12, 91.94), (Crop) Loss 1.5077, Accuracy: (60.25, 79.88, 86.03), (Drop) Loss 2.3750, Accuracy: (45.75, 64.34, 71.75), Time 3.42
2019-05-17 19:28:49,554: INFO: [train_wsdan.py:329]: 
	Batch 200: (Raw) Loss 1.1673, Accuracy: (69.91, 87.30, 92.17), (Crop) Loss 1.4831, Accuracy: (61.05, 80.44, 86.34), (Drop) Loss 2.3526, Accuracy: (46.36, 64.84, 71.62), Time 3.42
2019-05-17 19:30:08,769: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 19:30:09,976: INFO: [train_wsdan.py:482]: Valid: Loss 1.49034,  Accuracy: Top-1 61.06, Top-3 81.44, Top-5 87.50, Time 79.04
2019-05-17 19:35:43,685: INFO: [train_wsdan.py:329]: 
	Batch 300: (Raw) Loss 1.1673, Accuracy: (69.79, 87.07, 91.79), (Crop) Loss 1.4372, Accuracy: (61.80, 81.00, 86.78), (Drop) Loss 2.7447, Accuracy: (40.58, 57.72, 64.81), Time 3.31
2019-05-17 19:41:17,155: INFO: [train_wsdan.py:329]: 
	Batch 400: (Raw) Loss 1.1574, Accuracy: (70.16, 87.02, 91.62), (Crop) Loss 1.3966, Accuracy: (62.67, 81.46, 87.28), (Drop) Loss 2.9134, Accuracy: (37.73, 54.22, 61.16), Time 3.38
2019-05-17 19:42:37,533: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 19:42:38,795: INFO: [train_wsdan.py:482]: Valid: Loss 1.59467,  Accuracy: Top-1 57.77, Top-3 78.93, Top-5 85.52, Time 80.28
2019-05-17 19:48:12,215: INFO: [train_wsdan.py:329]: 
	Batch 500: (Raw) Loss 1.1409, Accuracy: (70.86, 87.43, 91.94), (Crop) Loss 1.3733, Accuracy: (63.24, 81.89, 87.55), (Drop) Loss 2.9819, Accuracy: (36.62, 53.04, 60.09), Time 3.33
2019-05-17 19:53:45,951: INFO: [train_wsdan.py:329]: 
	Batch 600: (Raw) Loss 1.1407, Accuracy: (70.85, 87.54, 91.98), (Crop) Loss 1.3727, Accuracy: (63.43, 81.95, 87.61), (Drop) Loss 2.9979, Accuracy: (35.99, 52.56, 59.75), Time 3.29
2019-05-17 19:55:08,759: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 19:55:10,050: INFO: [train_wsdan.py:482]: Valid: Loss 1.58258,  Accuracy: Top-1 57.58, Top-3 78.56, Top-5 85.27, Time 82.64
2019-05-17 20:00:42,222: INFO: [train_wsdan.py:329]: 
	Batch 700: (Raw) Loss 1.1411, Accuracy: (70.79, 87.58, 92.05), (Crop) Loss 1.3708, Accuracy: (63.51, 81.88, 87.51), (Drop) Loss 2.9666, Accuracy: (36.35, 53.13, 60.38), Time 3.30
2019-05-17 20:06:14,477: INFO: [train_wsdan.py:329]: 
	Batch 800: (Raw) Loss 1.1384, Accuracy: (70.92, 87.66, 92.12), (Crop) Loss 1.3697, Accuracy: (63.57, 81.95, 87.54), (Drop) Loss 2.8928, Accuracy: (37.33, 54.34, 61.66), Time 3.31
2019-05-17 20:07:38,400: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 20:07:39,662: INFO: [train_wsdan.py:482]: Valid: Loss 1.60460,  Accuracy: Top-1 57.39, Top-3 78.78, Top-5 85.55, Time 83.81
2019-05-17 20:13:11,892: INFO: [train_wsdan.py:329]: 
	Batch 900: (Raw) Loss 1.1406, Accuracy: (70.92, 87.57, 92.07), (Crop) Loss 1.3681, Accuracy: (63.65, 81.95, 87.50), (Drop) Loss 2.8695, Accuracy: (37.48, 54.67, 62.01), Time 3.30
2019-05-17 20:18:44,071: INFO: [train_wsdan.py:329]: 
	Batch 1000: (Raw) Loss 1.1363, Accuracy: (70.97, 87.62, 92.12), (Crop) Loss 1.3596, Accuracy: (63.80, 82.07, 87.62), (Drop) Loss 2.8757, Accuracy: (37.31, 54.46, 61.87), Time 3.30
2019-05-17 20:18:44,071: INFO: [train_wsdan.py:333]: saving the latest model from epoch 3
2019-05-17 20:20:08,166: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 20:20:09,451: INFO: [train_wsdan.py:482]: Valid: Loss 1.57619,  Accuracy: Top-1 58.37, Top-3 79.07, Top-5 86.16, Time 82.69
2019-05-17 20:25:42,121: INFO: [train_wsdan.py:329]: 
	Batch 1100: (Raw) Loss 1.1342, Accuracy: (71.02, 87.67, 92.17), (Crop) Loss 1.3569, Accuracy: (63.85, 82.11, 87.64), (Drop) Loss 2.8523, Accuracy: (37.63, 54.79, 62.29), Time 3.29
2019-05-17 20:31:14,445: INFO: [train_wsdan.py:329]: 
	Batch 1200: (Raw) Loss 1.1351, Accuracy: (71.04, 87.69, 92.17), (Crop) Loss 1.3584, Accuracy: (63.85, 82.14, 87.62), (Drop) Loss 2.8288, Accuracy: (37.98, 55.17, 62.71), Time 3.36
2019-05-17 20:32:36,233: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 20:32:37,431: INFO: [train_wsdan.py:482]: Valid: Loss 1.57473,  Accuracy: Top-1 59.29, Top-3 79.67, Top-5 85.97, Time 81.69
2019-05-17 20:38:10,015: INFO: [train_wsdan.py:329]: 
	Batch 1300: (Raw) Loss 1.1303, Accuracy: (71.19, 87.76, 92.23), (Crop) Loss 1.3511, Accuracy: (64.02, 82.21, 87.69), (Drop) Loss 2.8071, Accuracy: (38.20, 55.54, 63.11), Time 3.31
2019-05-17 20:43:42,715: INFO: [train_wsdan.py:329]: 
	Batch 1400: (Raw) Loss 1.1268, Accuracy: (71.29, 87.79, 92.26), (Crop) Loss 1.3446, Accuracy: (64.20, 82.32, 87.79), (Drop) Loss 2.7892, Accuracy: (38.49, 55.89, 63.42), Time 3.34
2019-05-17 20:45:04,774: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 20:45:06,036: INFO: [train_wsdan.py:482]: Valid: Loss 1.62297,  Accuracy: Top-1 58.92, Top-3 78.88, Top-5 85.91, Time 81.96
2019-05-17 20:50:38,069: INFO: [train_wsdan.py:329]: 
	Batch 1500: (Raw) Loss 1.1270, Accuracy: (71.34, 87.79, 92.30), (Crop) Loss 1.3426, Accuracy: (64.29, 82.35, 87.87), (Drop) Loss 2.7776, Accuracy: (38.66, 56.09, 63.66), Time 3.32
2019-05-17 20:56:10,144: INFO: [train_wsdan.py:329]: 
	Batch 1600: (Raw) Loss 1.1273, Accuracy: (71.32, 87.79, 92.29), (Crop) Loss 1.3413, Accuracy: (64.32, 82.40, 87.88), (Drop) Loss 2.7793, Accuracy: (38.61, 56.09, 63.65), Time 3.31
2019-05-17 20:57:32,925: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 20:57:34,276: INFO: [train_wsdan.py:482]: Valid: Loss 1.68402,  Accuracy: Top-1 56.30, Top-3 77.38, Top-5 84.66, Time 82.67
2019-05-17 21:03:05,994: INFO: [train_wsdan.py:329]: 
	Batch 1700: (Raw) Loss 1.1274, Accuracy: (71.28, 87.78, 92.30), (Crop) Loss 1.3387, Accuracy: (64.35, 82.41, 87.88), (Drop) Loss 2.7819, Accuracy: (38.59, 56.03, 63.65), Time 3.31
2019-05-17 21:08:37,609: INFO: [train_wsdan.py:329]: 
	Batch 1800: (Raw) Loss 1.1254, Accuracy: (71.38, 87.82, 92.32), (Crop) Loss 1.3365, Accuracy: (64.45, 82.47, 87.91), (Drop) Loss 2.7625, Accuracy: (38.91, 56.36, 63.98), Time 3.30
2019-05-17 21:10:01,223: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 21:10:02,474: INFO: [train_wsdan.py:482]: Valid: Loss 1.52741,  Accuracy: Top-1 59.72, Top-3 80.34, Top-5 86.70, Time 83.52
2019-05-17 21:15:33,835: INFO: [train_wsdan.py:329]: 
	Batch 1900: (Raw) Loss 1.1255, Accuracy: (71.41, 87.78, 92.31), (Crop) Loss 1.3383, Accuracy: (64.45, 82.40, 87.82), (Drop) Loss 2.7507, Accuracy: (39.10, 56.55, 64.16), Time 3.29
2019-05-17 21:21:05,753: INFO: [train_wsdan.py:329]: 
	Batch 2000: (Raw) Loss 1.1229, Accuracy: (71.49, 87.80, 92.32), (Crop) Loss 1.3369, Accuracy: (64.44, 82.47, 87.86), (Drop) Loss 2.7657, Accuracy: (38.93, 56.29, 63.92), Time 3.31
2019-05-17 21:21:05,754: INFO: [train_wsdan.py:333]: saving the latest model from epoch 3
2019-05-17 21:22:30,399: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 21:22:31,637: INFO: [train_wsdan.py:482]: Valid: Loss 1.61239,  Accuracy: Top-1 58.43, Top-3 79.13, Top-5 85.62, Time 83.19
2019-05-17 21:28:03,959: INFO: [train_wsdan.py:329]: 
	Batch 2100: (Raw) Loss 1.1211, Accuracy: (71.55, 87.83, 92.35), (Crop) Loss 1.3339, Accuracy: (64.53, 82.48, 87.89), (Drop) Loss 2.7577, Accuracy: (39.09, 56.45, 64.05), Time 3.36
2019-05-17 21:33:35,921: INFO: [train_wsdan.py:329]: 
	Batch 2200: (Raw) Loss 1.1207, Accuracy: (71.59, 87.85, 92.36), (Crop) Loss 1.3325, Accuracy: (64.55, 82.50, 87.92), (Drop) Loss 2.7567, Accuracy: (39.08, 56.48, 64.03), Time 3.39
2019-05-17 21:34:59,302: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 21:35:00,523: INFO: [train_wsdan.py:482]: Valid: Loss 1.48902,  Accuracy: Top-1 60.66, Top-3 80.86, Top-5 86.98, Time 83.21
2019-05-17 21:40:32,881: INFO: [train_wsdan.py:329]: 
	Batch 2300: (Raw) Loss 1.1170, Accuracy: (71.67, 87.91, 92.40), (Crop) Loss 1.3285, Accuracy: (64.67, 82.58, 87.98), (Drop) Loss 2.7410, Accuracy: (39.31, 56.75, 64.30), Time 3.30
2019-05-17 21:46:04,533: INFO: [train_wsdan.py:329]: 
	Batch 2400: (Raw) Loss 1.1136, Accuracy: (71.75, 87.96, 92.43), (Crop) Loss 1.3239, Accuracy: (64.76, 82.65, 88.03), (Drop) Loss 2.7343, Accuracy: (39.43, 56.87, 64.38), Time 3.29
2019-05-17 21:47:28,224: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 21:47:29,525: INFO: [train_wsdan.py:482]: Valid: Loss 1.52744,  Accuracy: Top-1 61.45, Top-3 79.43, Top-5 85.94, Time 83.59
2019-05-17 21:53:01,189: INFO: [train_wsdan.py:329]: 
	Batch 2500: (Raw) Loss 1.1118, Accuracy: (71.79, 87.99, 92.45), (Crop) Loss 1.3207, Accuracy: (64.84, 82.70, 88.06), (Drop) Loss 2.7293, Accuracy: (39.51, 56.96, 64.45), Time 3.32
2019-05-17 21:58:33,443: INFO: [train_wsdan.py:329]: 
	Batch 2600: (Raw) Loss 1.1100, Accuracy: (71.82, 88.03, 92.47), (Crop) Loss 1.3196, Accuracy: (64.86, 82.71, 88.10), (Drop) Loss 2.7201, Accuracy: (39.63, 57.13, 64.64), Time 3.32
2019-05-17 21:59:57,350: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 21:59:58,597: INFO: [train_wsdan.py:482]: Valid: Loss 1.57663,  Accuracy: Top-1 59.92, Top-3 79.29, Top-5 85.25, Time 83.81
2019-05-17 22:05:30,538: INFO: [train_wsdan.py:329]: 
	Batch 2700: (Raw) Loss 1.1098, Accuracy: (71.82, 88.03, 92.47), (Crop) Loss 1.3180, Accuracy: (64.90, 82.72, 88.11), (Drop) Loss 2.7185, Accuracy: (39.68, 57.14, 64.64), Time 3.30
2019-05-17 22:11:03,125: INFO: [train_wsdan.py:329]: 
	Batch 2800: (Raw) Loss 1.1079, Accuracy: (71.86, 88.05, 92.48), (Crop) Loss 1.3159, Accuracy: (64.96, 82.74, 88.12), (Drop) Loss 2.7088, Accuracy: (39.83, 57.33, 64.80), Time 3.29
2019-05-17 22:12:27,065: INFO: [train_wsdan.py:470]: saving the best model from epoch 3
2019-05-17 22:12:28,366: INFO: [train_wsdan.py:482]: Valid: Loss 1.50235,  Accuracy: Top-1 60.65, Top-3 80.65, Top-5 86.52, Time 83.84
2019-05-17 22:18:00,793: INFO: [train_wsdan.py:329]: 
	Batch 2900: (Raw) Loss 1.1076, Accuracy: (71.87, 88.04, 92.47), (Crop) Loss 1.3153, Accuracy: (65.00, 82.75, 88.11), (Drop) Loss 2.7129, Accuracy: (39.78, 57.26, 64.71), Time 3.30
2019-05-17 22:23:34,008: INFO: [train_wsdan.py:329]: 
	Batch 3000: (Raw) Loss 1.1051, Accuracy: (71.93, 88.08, 92.49), (Crop) Loss 1.3141, Accuracy: (65.04, 82.77, 88.11), (Drop) Loss 2.7100, Accuracy: (39.84, 57.33, 64.76), Time 3.29
2019-05-17 22:23:34,008: INFO: [train_wsdan.py:333]: saving the latest model from epoch 3
2019-05-17 22:44:18,980: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 22:44:21,635: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 22:44:21,717: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 22:44:21,864: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 22:44:23,736: INFO: [train_wsdan.py:151]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 22:44:23,736: INFO: [train_wsdan.py:219]: Epoch 003, Learning Rate 0.00059049
2019-05-17 22:48:46,242: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 22:48:48,759: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 22:48:48,812: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 22:48:48,929: INFO: [train_wsdan.py:110]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 22:51:02,170: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 22:51:04,700: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 22:51:04,752: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 22:51:04,768: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 22:51:05,890: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 22:51:05,890: INFO: [train_wsdan.py:220]: Epoch 003, Learning Rate 0.0006
2019-05-17 22:59:15,133: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 22:59:26,001: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 22:59:26,075: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 22:59:26,465: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 22:59:30,107: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 64, Training size: 265213, Validation size: 3030
2019-05-17 22:59:30,107: INFO: [train_wsdan.py:220]: Epoch 003, Learning Rate 0.0008
2019-05-17 23:11:19,518: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.9999, Accuracy: (74.69, 89.72, 93.86), (Crop) Loss 1.3148, Accuracy: (65.52, 82.89, 87.95), (Drop) Loss 2.1677, Accuracy: (49.84, 67.14, 74.27), Time 6.25
2019-05-17 23:21:47,817: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.9675, Accuracy: (75.70, 90.34, 94.13), (Crop) Loss 1.2678, Accuracy: (66.70, 83.43, 88.48), (Drop) Loss 2.1055, Accuracy: (50.87, 68.70, 75.38), Time 6.30
2019-05-17 23:24:00,521: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 23:24:08,716: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 23:24:08,779: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 23:24:08,800: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 23:24:10,754: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 64, Training size: 265213, Validation size: 3030
2019-05-17 23:24:10,754: INFO: [train_wsdan.py:220]: Epoch 003, Learning Rate 0.0008
2019-05-17 23:31:14,965: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 1.0688, Accuracy: (73.25, 88.77, 92.59), (Crop) Loss 1.4375, Accuracy: (62.88, 80.91, 86.27), (Drop) Loss 2.2828, Accuracy: (47.72, 65.61, 72.22), Time 3.61
2019-05-17 23:37:20,401: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 1.0284, Accuracy: (74.09, 89.54, 93.31), (Crop) Loss 1.3775, Accuracy: (63.78, 81.50, 86.99), (Drop) Loss 2.2084, Accuracy: (49.35, 66.88, 73.20), Time 3.67
2019-05-17 23:43:31,970: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 23:43:40,277: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 23:43:40,339: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 23:43:40,362: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 23:43:42,337: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 64, Training size: 265213, Validation size: 3030
2019-05-17 23:43:42,337: INFO: [train_wsdan.py:220]: Epoch 003, Learning Rate 0.0008
2019-05-17 23:50:39,846: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 1.0358, Accuracy: (74.50, 89.08, 93.20), (Crop) Loss 1.3608, Accuracy: (64.23, 82.00, 87.73), (Drop) Loss 2.2242, Accuracy: (49.50, 67.02, 73.30), Time 3.62
2019-05-17 23:56:44,586: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 1.0218, Accuracy: (75.06, 89.50, 93.30), (Crop) Loss 1.3588, Accuracy: (64.35, 81.95, 87.49), (Drop) Loss 2.1951, Accuracy: (50.38, 67.28, 73.82), Time 3.65
2019-05-17 23:59:11,262: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-17 23:59:16,779: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-17 23:59:16,842: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-17 23:59:16,864: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-17 23:59:18,748: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-05-17 23:59:18,748: INFO: [train_wsdan.py:220]: Epoch 003, Learning Rate 0.0007
2019-05-18 00:03:43,905: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 1.2695, Accuracy: (67.69, 86.03, 90.97), (Crop) Loss 1.6590, Accuracy: (56.59, 76.62, 83.50), (Drop) Loss 2.5341, Accuracy: (43.75, 61.28, 68.97), Time 2.17
2019-05-18 00:07:25,120: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 1.2150, Accuracy: (69.22, 86.53, 91.34), (Crop) Loss 1.6079, Accuracy: (58.67, 77.52, 83.89), (Drop) Loss 2.4610, Accuracy: (46.17, 62.64, 69.53), Time 2.23
2019-05-18 00:21:33,921: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-18 00:21:41,478: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-18 00:21:41,515: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-18 00:21:41,532: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-18 00:21:43,118: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 64, Training size: 265213, Validation size: 3030
2019-05-18 00:21:43,118: INFO: [train_wsdan.py:220]: Epoch 003, Learning Rate 0.0008
2019-05-18 00:28:28,230: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 1.0557, Accuracy: (74.28, 89.22, 93.17), (Crop) Loss 1.3839, Accuracy: (63.81, 82.05, 87.52), (Drop) Loss 2.2957, Accuracy: (47.83, 65.59, 72.52), Time 3.56
2019-05-18 00:34:22,323: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 1.0318, Accuracy: (74.69, 89.66, 93.38), (Crop) Loss 1.3715, Accuracy: (64.14, 81.95, 87.33), (Drop) Loss 2.2535, Accuracy: (48.79, 66.33, 72.88), Time 3.56
2019-05-18 00:35:17,017: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 00:35:20,124: INFO: [train_wsdan.py:483]: Valid: Loss 1.39200,  Accuracy: Top-1 63.54, Top-3 82.08, Top-5 88.19, Time 54.58
2019-05-18 00:41:06,680: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 1.0072, Accuracy: (75.05, 89.92, 93.60), (Crop) Loss 1.2873, Accuracy: (66.07, 83.32, 88.45), (Drop) Loss 2.5167, Accuracy: (44.12, 61.18, 68.01), Time 3.49
2019-05-18 00:46:53,221: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.9889, Accuracy: (75.42, 90.11, 93.75), (Crop) Loss 1.2385, Accuracy: (67.21, 84.05, 88.92), (Drop) Loss 2.5738, Accuracy: (43.00, 60.13, 66.90), Time 3.46
2019-05-18 00:47:31,313: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 00:47:34,057: INFO: [train_wsdan.py:483]: Valid: Loss 1.41882,  Accuracy: Top-1 61.82, Top-3 81.11, Top-5 87.48, Time 38.00
2019-05-18 00:53:21,635: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.9815, Accuracy: (75.74, 90.19, 93.81), (Crop) Loss 1.2182, Accuracy: (67.72, 84.45, 89.22), (Drop) Loss 2.5969, Accuracy: (42.52, 59.70, 66.64), Time 3.47
2019-05-18 00:59:09,451: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.9671, Accuracy: (76.09, 90.50, 94.05), (Crop) Loss 1.1948, Accuracy: (68.22, 84.78, 89.57), (Drop) Loss 2.5921, Accuracy: (42.49, 59.71, 66.68), Time 3.50
2019-05-18 00:59:46,849: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 00:59:49,676: INFO: [train_wsdan.py:483]: Valid: Loss 1.41273,  Accuracy: Top-1 62.43, Top-3 82.37, Top-5 88.35, Time 37.30
2019-05-18 01:05:37,295: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.9592, Accuracy: (76.22, 90.55, 94.13), (Crop) Loss 1.1803, Accuracy: (68.49, 84.98, 89.71), (Drop) Loss 2.6022, Accuracy: (42.29, 59.45, 66.42), Time 3.46
2019-05-18 01:11:24,984: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.9598, Accuracy: (76.24, 90.50, 94.09), (Crop) Loss 1.1797, Accuracy: (68.60, 85.04, 89.73), (Drop) Loss 2.6041, Accuracy: (42.24, 59.46, 66.46), Time 3.48
2019-05-18 01:12:02,899: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 01:12:04,043: INFO: [train_wsdan.py:483]: Valid: Loss 1.38426,  Accuracy: Top-1 63.19, Top-3 82.08, Top-5 88.45, Time 37.82
2019-05-18 01:17:51,759: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.9531, Accuracy: (76.39, 90.54, 94.15), (Crop) Loss 1.1668, Accuracy: (68.88, 85.19, 89.86), (Drop) Loss 2.6021, Accuracy: (42.22, 59.38, 66.42), Time 3.43
2019-05-18 01:23:39,516: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.9520, Accuracy: (76.40, 90.56, 94.14), (Crop) Loss 1.1621, Accuracy: (69.00, 85.28, 89.92), (Drop) Loss 2.6035, Accuracy: (42.13, 59.37, 66.38), Time 3.51
2019-05-18 01:23:39,517: INFO: [train_wsdan.py:334]: saving the latest model from epoch 3
2019-05-18 01:24:17,970: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 01:24:21,028: INFO: [train_wsdan.py:483]: Valid: Loss 1.35972,  Accuracy: Top-1 63.28, Top-3 82.67, Top-5 88.38, Time 37.10
2019-05-18 01:30:08,370: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.9495, Accuracy: (76.43, 90.59, 94.16), (Crop) Loss 1.1563, Accuracy: (69.12, 85.36, 89.95), (Drop) Loss 2.6182, Accuracy: (41.89, 59.07, 66.09), Time 3.47
2019-05-18 01:35:55,422: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.9468, Accuracy: (76.49, 90.62, 94.20), (Crop) Loss 1.1547, Accuracy: (69.14, 85.38, 89.96), (Drop) Loss 2.6318, Accuracy: (41.61, 58.81, 65.87), Time 3.47
2019-05-18 01:36:33,200: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 01:36:35,375: INFO: [train_wsdan.py:483]: Valid: Loss 1.36436,  Accuracy: Top-1 63.44, Top-3 82.47, Top-5 88.65, Time 37.67
2019-05-18 01:42:23,000: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.9434, Accuracy: (76.50, 90.67, 94.24), (Crop) Loss 1.1480, Accuracy: (69.24, 85.50, 90.06), (Drop) Loss 2.6156, Accuracy: (41.85, 59.06, 66.10), Time 3.46
2019-05-18 01:48:10,677: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.9395, Accuracy: (76.65, 90.72, 94.26), (Crop) Loss 1.1404, Accuracy: (69.42, 85.60, 90.14), (Drop) Loss 2.6096, Accuracy: (41.92, 59.10, 66.14), Time 3.51
2019-05-18 01:48:48,621: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 01:48:49,776: INFO: [train_wsdan.py:483]: Valid: Loss 1.41437,  Accuracy: Top-1 62.75, Top-3 82.31, Top-5 88.43, Time 37.85
2019-05-18 01:54:38,455: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.9396, Accuracy: (76.59, 90.71, 94.26), (Crop) Loss 1.1398, Accuracy: (69.36, 85.61, 90.16), (Drop) Loss 2.5992, Accuracy: (42.05, 59.26, 66.34), Time 3.49
2019-05-18 02:00:26,864: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.9394, Accuracy: (76.56, 90.74, 94.28), (Crop) Loss 1.1386, Accuracy: (69.38, 85.63, 90.18), (Drop) Loss 2.5696, Accuracy: (42.46, 59.77, 66.86), Time 3.49
2019-05-18 02:01:04,864: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 02:01:06,005: INFO: [train_wsdan.py:483]: Valid: Loss 1.36830,  Accuracy: Top-1 63.25, Top-3 82.57, Top-5 88.45, Time 37.91
2019-05-18 02:06:53,344: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.9361, Accuracy: (76.65, 90.80, 94.31), (Crop) Loss 1.1341, Accuracy: (69.49, 85.69, 90.23), (Drop) Loss 2.5627, Accuracy: (42.63, 59.91, 66.97), Time 3.48
2019-05-18 02:12:41,374: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.9364, Accuracy: (76.64, 90.80, 94.31), (Crop) Loss 1.1331, Accuracy: (69.49, 85.70, 90.24), (Drop) Loss 2.5646, Accuracy: (42.64, 59.88, 66.93), Time 3.50
2019-05-18 02:13:18,715: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 02:13:19,945: INFO: [train_wsdan.py:483]: Valid: Loss 1.40049,  Accuracy: Top-1 63.01, Top-3 82.83, Top-5 88.88, Time 37.25
2019-05-18 02:19:06,975: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.9344, Accuracy: (76.70, 90.83, 94.32), (Crop) Loss 1.1306, Accuracy: (69.54, 85.74, 90.26), (Drop) Loss 2.5535, Accuracy: (42.84, 60.09, 67.14), Time 3.48
2019-05-18 02:24:53,928: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.9318, Accuracy: (76.79, 90.88, 94.35), (Crop) Loss 1.1271, Accuracy: (69.63, 85.80, 90.31), (Drop) Loss 2.5381, Accuracy: (43.06, 60.33, 67.38), Time 3.46
2019-05-18 02:24:53,929: INFO: [train_wsdan.py:334]: saving the latest model from epoch 3
2019-05-18 02:25:33,065: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 02:25:34,222: INFO: [train_wsdan.py:483]: Valid: Loss 1.35596,  Accuracy: Top-1 63.67, Top-3 83.31, Top-5 88.74, Time 37.79
2019-05-18 02:31:21,736: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.9309, Accuracy: (76.79, 90.89, 94.36), (Crop) Loss 1.1270, Accuracy: (69.65, 85.81, 90.32), (Drop) Loss 2.5240, Accuracy: (43.28, 60.57, 67.63), Time 3.47
2019-05-18 02:37:09,924: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.9281, Accuracy: (76.88, 90.93, 94.39), (Crop) Loss 1.1239, Accuracy: (69.75, 85.84, 90.36), (Drop) Loss 2.5123, Accuracy: (43.48, 60.77, 67.81), Time 3.49
2019-05-18 02:37:47,298: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 02:37:50,567: INFO: [train_wsdan.py:483]: Valid: Loss 1.43326,  Accuracy: Top-1 62.34, Top-3 81.69, Top-5 87.48, Time 37.28
2019-05-18 02:43:38,684: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.9272, Accuracy: (76.93, 90.97, 94.42), (Crop) Loss 1.1222, Accuracy: (69.80, 85.88, 90.39), (Drop) Loss 2.5109, Accuracy: (43.52, 60.81, 67.86), Time 3.47
2019-05-18 02:49:26,811: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.9264, Accuracy: (76.96, 90.96, 94.41), (Crop) Loss 1.1209, Accuracy: (69.84, 85.89, 90.38), (Drop) Loss 2.5164, Accuracy: (43.46, 60.73, 67.77), Time 3.48
2019-05-18 02:50:04,583: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 02:50:05,734: INFO: [train_wsdan.py:483]: Valid: Loss 1.41299,  Accuracy: Top-1 63.12, Top-3 81.50, Top-5 87.25, Time 37.68
2019-05-18 02:55:53,708: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.9251, Accuracy: (77.00, 90.98, 94.41), (Crop) Loss 1.1185, Accuracy: (69.88, 85.93, 90.41), (Drop) Loss 2.5225, Accuracy: (43.38, 60.62, 67.65), Time 3.45
2019-05-18 03:01:41,328: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.9241, Accuracy: (77.03, 90.98, 94.43), (Crop) Loss 1.1176, Accuracy: (69.91, 85.93, 90.41), (Drop) Loss 2.5249, Accuracy: (43.37, 60.60, 67.63), Time 3.57
2019-05-18 03:02:18,750: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 03:02:19,903: INFO: [train_wsdan.py:483]: Valid: Loss 1.36760,  Accuracy: Top-1 63.87, Top-3 82.63, Top-5 88.45, Time 37.33
2019-05-18 03:08:06,989: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.9231, Accuracy: (77.05, 90.99, 94.43), (Crop) Loss 1.1166, Accuracy: (69.91, 85.95, 90.44), (Drop) Loss 2.5237, Accuracy: (43.39, 60.62, 67.63), Time 3.47
2019-05-18 03:13:54,417: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.9225, Accuracy: (77.05, 90.99, 94.44), (Crop) Loss 1.1160, Accuracy: (69.92, 85.95, 90.44), (Drop) Loss 2.5143, Accuracy: (43.53, 60.77, 67.80), Time 3.48
2019-05-18 03:14:31,831: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 03:14:33,015: INFO: [train_wsdan.py:483]: Valid: Loss 1.30769,  Accuracy: Top-1 64.32, Top-3 83.90, Top-5 89.33, Time 37.32
2019-05-18 03:20:20,491: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.9222, Accuracy: (77.06, 90.99, 94.43), (Crop) Loss 1.1157, Accuracy: (69.94, 85.96, 90.43), (Drop) Loss 2.5166, Accuracy: (43.52, 60.73, 67.73), Time 3.48
2019-05-18 03:26:08,235: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.9216, Accuracy: (77.08, 90.99, 94.44), (Crop) Loss 1.1156, Accuracy: (69.96, 85.95, 90.43), (Drop) Loss 2.5134, Accuracy: (43.58, 60.78, 67.75), Time 3.46
2019-05-18 03:26:08,235: INFO: [train_wsdan.py:334]: saving the latest model from epoch 3
2019-05-18 03:26:47,209: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 03:26:48,406: INFO: [train_wsdan.py:483]: Valid: Loss 1.29450,  Accuracy: Top-1 64.97, Top-3 83.71, Top-5 89.14, Time 37.64
2019-05-18 03:32:36,746: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.9214, Accuracy: (77.07, 91.02, 94.45), (Crop) Loss 1.1142, Accuracy: (69.99, 85.96, 90.45), (Drop) Loss 2.5152, Accuracy: (43.57, 60.73, 67.70), Time 3.49
2019-05-18 03:38:24,868: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.9198, Accuracy: (77.12, 91.04, 94.46), (Crop) Loss 1.1123, Accuracy: (70.02, 86.00, 90.48), (Drop) Loss 2.5154, Accuracy: (43.56, 60.72, 67.68), Time 3.47
2019-05-18 03:39:02,238: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 03:39:03,393: INFO: [train_wsdan.py:483]: Valid: Loss 1.36944,  Accuracy: Top-1 64.28, Top-3 83.97, Top-5 88.72, Time 37.27
2019-05-18 03:44:51,260: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.9188, Accuracy: (77.14, 91.05, 94.47), (Crop) Loss 1.1109, Accuracy: (70.05, 86.02, 90.50), (Drop) Loss 2.5101, Accuracy: (43.65, 60.82, 67.76), Time 3.48
2019-05-18 03:50:39,454: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.9177, Accuracy: (77.16, 91.07, 94.48), (Crop) Loss 1.1094, Accuracy: (70.09, 86.04, 90.53), (Drop) Loss 2.5129, Accuracy: (43.64, 60.77, 67.72), Time 3.47
2019-05-18 03:51:17,214: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 03:51:18,450: INFO: [train_wsdan.py:483]: Valid: Loss 1.35057,  Accuracy: Top-1 64.35, Top-3 82.79, Top-5 88.55, Time 37.67
2019-05-18 03:57:05,699: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.9171, Accuracy: (77.18, 91.08, 94.47), (Crop) Loss 1.1083, Accuracy: (70.12, 86.06, 90.55), (Drop) Loss 2.5227, Accuracy: (43.50, 60.59, 67.55), Time 3.46
2019-05-18 04:02:52,651: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.9155, Accuracy: (77.22, 91.11, 94.50), (Crop) Loss 1.1068, Accuracy: (70.15, 86.10, 90.58), (Drop) Loss 2.5240, Accuracy: (43.50, 60.55, 67.52), Time 3.46
2019-05-18 04:03:30,407: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 04:03:31,549: INFO: [train_wsdan.py:483]: Valid: Loss 1.30979,  Accuracy: Top-1 64.85, Top-3 83.64, Top-5 89.33, Time 37.66
2019-05-18 04:09:19,067: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.9150, Accuracy: (77.23, 91.11, 94.50), (Crop) Loss 1.1055, Accuracy: (70.19, 86.11, 90.59), (Drop) Loss 2.5191, Accuracy: (43.56, 60.64, 67.61), Time 3.46
2019-05-18 04:15:06,833: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.9135, Accuracy: (77.26, 91.13, 94.52), (Crop) Loss 1.1036, Accuracy: (70.22, 86.14, 90.61), (Drop) Loss 2.5148, Accuracy: (43.64, 60.70, 67.68), Time 3.47
2019-05-18 04:15:44,042: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 04:15:45,201: INFO: [train_wsdan.py:483]: Valid: Loss 1.33771,  Accuracy: Top-1 63.54, Top-3 82.99, Top-5 88.26, Time 37.11
2019-05-18 04:21:33,279: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.9129, Accuracy: (77.27, 91.13, 94.51), (Crop) Loss 1.1032, Accuracy: (70.23, 86.14, 90.61), (Drop) Loss 2.5129, Accuracy: (43.69, 60.74, 67.70), Time 3.46
2019-05-18 04:27:21,186: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.9118, Accuracy: (77.31, 91.15, 94.52), (Crop) Loss 1.1013, Accuracy: (70.26, 86.17, 90.64), (Drop) Loss 2.5148, Accuracy: (43.67, 60.69, 67.67), Time 3.47
2019-05-18 04:27:21,186: INFO: [train_wsdan.py:334]: saving the latest model from epoch 3
2019-05-18 04:27:59,852: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 04:28:02,575: INFO: [train_wsdan.py:483]: Valid: Loss 1.33910,  Accuracy: Top-1 63.54, Top-3 83.45, Top-5 88.36, Time 37.36
2019-05-18 04:33:50,268: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.9102, Accuracy: (77.35, 91.17, 94.53), (Crop) Loss 1.0994, Accuracy: (70.32, 86.19, 90.65), (Drop) Loss 2.5107, Accuracy: (43.74, 60.76, 67.72), Time 3.48
2019-05-18 04:36:41,741: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.9095, Accuracy: (77.37, 91.18, 94.54), (Crop) Loss 1.0987, Accuracy: (70.33, 86.21, 90.66), (Drop) Loss 2.5096, Accuracy: (43.75, 60.77, 67.74), Time 15298.62
2019-05-18 04:37:19,240: INFO: [train_wsdan.py:471]: saving the best model from epoch 3
2019-05-18 04:37:21,124: INFO: [train_wsdan.py:483]: Valid: Loss 1.31550,  Accuracy: Top-1 65.69, Top-3 83.87, Top-5 88.88, Time 37.40
2019-05-18 04:37:21,132: INFO: [train_wsdan.py:220]: Epoch 004, Learning Rate 0.000648
2019-05-18 04:43:21,788: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.9483, Accuracy: (76.88, 91.55, 95.05), (Crop) Loss 1.3060, Accuracy: (65.92, 83.38, 88.66), (Drop) Loss 2.1920, Accuracy: (50.31, 67.64, 74.03), Time 3.59
2019-05-18 04:49:16,158: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.9238, Accuracy: (77.42, 91.35, 94.62), (Crop) Loss 1.2806, Accuracy: (66.50, 83.45, 88.61), (Drop) Loss 2.1440, Accuracy: (51.17, 68.23, 74.30), Time 3.54
2019-05-18 04:49:53,854: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 04:49:55,007: INFO: [train_wsdan.py:483]: Valid: Loss 1.30395,  Accuracy: Top-1 65.20, Top-3 84.16, Top-5 89.21, Time 37.60
2019-05-18 04:55:42,675: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.8804, Accuracy: (78.41, 91.82, 95.06), (Crop) Loss 1.1580, Accuracy: (69.25, 85.22, 89.97), (Drop) Loss 2.2783, Accuracy: (48.29, 65.57, 71.82), Time 3.45
2019-05-18 05:01:30,395: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.8556, Accuracy: (79.12, 92.08, 95.24), (Crop) Loss 1.0944, Accuracy: (70.70, 86.16, 90.74), (Drop) Loss 2.3958, Accuracy: (46.20, 63.34, 69.77), Time 3.48
2019-05-18 05:02:07,875: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 05:02:09,029: INFO: [train_wsdan.py:483]: Valid: Loss 1.33056,  Accuracy: Top-1 64.75, Top-3 83.19, Top-5 88.97, Time 37.39
2019-05-18 05:07:56,653: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.8416, Accuracy: (79.53, 92.28, 95.39), (Crop) Loss 1.0589, Accuracy: (71.36, 86.76, 91.23), (Drop) Loss 2.4738, Accuracy: (45.03, 61.85, 68.41), Time 3.46
2019-05-18 05:13:44,295: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.8373, Accuracy: (79.69, 92.30, 95.39), (Crop) Loss 1.0400, Accuracy: (71.84, 86.99, 91.39), (Drop) Loss 2.5132, Accuracy: (44.41, 61.15, 67.70), Time 3.45
2019-05-18 05:14:22,692: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 05:14:23,848: INFO: [train_wsdan.py:483]: Valid: Loss 1.30584,  Accuracy: Top-1 66.43, Top-3 84.16, Top-5 89.20, Time 38.30
2019-05-18 05:20:11,058: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.8296, Accuracy: (79.89, 92.43, 95.48), (Crop) Loss 1.0221, Accuracy: (72.31, 87.28, 91.61), (Drop) Loss 2.5025, Accuracy: (44.41, 61.28, 67.85), Time 3.48
2019-05-18 05:25:58,469: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.8280, Accuracy: (80.01, 92.44, 95.47), (Crop) Loss 1.0132, Accuracy: (72.48, 87.44, 91.72), (Drop) Loss 2.5057, Accuracy: (44.43, 61.17, 67.75), Time 3.48
2019-05-18 05:26:36,565: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 05:26:37,734: INFO: [train_wsdan.py:483]: Valid: Loss 1.30488,  Accuracy: Top-1 65.49, Top-3 83.42, Top-5 89.17, Time 38.00
2019-05-18 05:32:25,576: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.8228, Accuracy: (80.10, 92.52, 95.52), (Crop) Loss 1.0056, Accuracy: (72.70, 87.56, 91.79), (Drop) Loss 2.4969, Accuracy: (44.57, 61.30, 67.89), Time 3.50
2019-05-18 05:38:13,590: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.8213, Accuracy: (80.10, 92.54, 95.53), (Crop) Loss 1.0019, Accuracy: (72.74, 87.65, 91.83), (Drop) Loss 2.4809, Accuracy: (44.75, 61.52, 68.19), Time 3.47
2019-05-18 05:38:13,590: INFO: [train_wsdan.py:334]: saving the latest model from epoch 4
2019-05-18 05:38:52,513: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 05:38:53,696: INFO: [train_wsdan.py:483]: Valid: Loss 1.31555,  Accuracy: Top-1 65.49, Top-3 83.94, Top-5 89.76, Time 37.64
2019-05-18 05:44:41,567: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.8168, Accuracy: (80.17, 92.59, 95.57), (Crop) Loss 0.9938, Accuracy: (72.91, 87.76, 91.90), (Drop) Loss 2.4628, Accuracy: (44.95, 61.82, 68.48), Time 3.48
2019-05-18 05:50:29,585: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.8148, Accuracy: (80.14, 92.65, 95.61), (Crop) Loss 0.9907, Accuracy: (72.95, 87.84, 91.93), (Drop) Loss 2.4566, Accuracy: (45.06, 61.91, 68.59), Time 3.47
2019-05-18 05:51:07,309: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 05:51:08,486: INFO: [train_wsdan.py:483]: Valid: Loss 1.33821,  Accuracy: Top-1 65.92, Top-3 83.81, Top-5 88.91, Time 37.63
2019-05-18 05:56:56,104: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.8128, Accuracy: (80.18, 92.68, 95.61), (Crop) Loss 0.9874, Accuracy: (73.02, 87.88, 91.93), (Drop) Loss 2.4524, Accuracy: (45.12, 61.96, 68.64), Time 3.47
2019-05-18 06:02:43,631: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.8107, Accuracy: (80.25, 92.73, 95.64), (Crop) Loss 0.9845, Accuracy: (73.11, 87.94, 91.96), (Drop) Loss 2.4386, Accuracy: (45.33, 62.25, 68.91), Time 3.47
2019-05-18 06:03:21,677: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 06:03:22,857: INFO: [train_wsdan.py:483]: Valid: Loss 1.30842,  Accuracy: Top-1 65.18, Top-3 83.97, Top-5 88.97, Time 37.95
2019-05-18 06:09:09,924: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.8081, Accuracy: (80.33, 92.74, 95.66), (Crop) Loss 0.9813, Accuracy: (73.18, 88.01, 92.01), (Drop) Loss 2.4282, Accuracy: (45.46, 62.38, 69.06), Time 3.45
2019-05-18 06:14:57,066: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.8081, Accuracy: (80.34, 92.75, 95.67), (Crop) Loss 0.9804, Accuracy: (73.26, 88.04, 92.02), (Drop) Loss 2.4255, Accuracy: (45.49, 62.39, 69.09), Time 3.47
2019-05-18 06:15:34,956: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 06:15:36,125: INFO: [train_wsdan.py:483]: Valid: Loss 1.29549,  Accuracy: Top-1 66.27, Top-3 84.13, Top-5 89.37, Time 37.79
2019-05-18 06:21:23,617: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.8076, Accuracy: (80.32, 92.78, 95.68), (Crop) Loss 0.9792, Accuracy: (73.28, 88.06, 92.03), (Drop) Loss 2.4206, Accuracy: (45.58, 62.52, 69.20), Time 3.47
2019-05-18 06:27:11,048: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.8073, Accuracy: (80.35, 92.79, 95.68), (Crop) Loss 0.9782, Accuracy: (73.29, 88.08, 92.05), (Drop) Loss 2.4176, Accuracy: (45.66, 62.57, 69.25), Time 3.47
2019-05-18 06:27:48,445: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 06:27:51,471: INFO: [train_wsdan.py:483]: Valid: Loss 1.28214,  Accuracy: Top-1 65.33, Top-3 84.32, Top-5 88.85, Time 37.30
2019-05-18 06:33:38,794: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.8064, Accuracy: (80.36, 92.79, 95.69), (Crop) Loss 0.9759, Accuracy: (73.36, 88.12, 92.07), (Drop) Loss 2.4041, Accuracy: (45.90, 62.79, 69.46), Time 3.46
2019-05-18 06:39:26,262: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.8045, Accuracy: (80.38, 92.81, 95.72), (Crop) Loss 0.9733, Accuracy: (73.42, 88.18, 92.12), (Drop) Loss 2.3850, Accuracy: (46.24, 63.10, 69.77), Time 3.47
2019-05-18 06:39:26,262: INFO: [train_wsdan.py:334]: saving the latest model from epoch 4
2019-05-18 06:40:06,788: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 06:40:07,958: INFO: [train_wsdan.py:483]: Valid: Loss 1.32033,  Accuracy: Top-1 64.84, Top-3 84.26, Top-5 89.82, Time 37.31
2019-05-18 06:45:55,580: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.8043, Accuracy: (80.40, 92.80, 95.72), (Crop) Loss 0.9731, Accuracy: (73.42, 88.15, 92.11), (Drop) Loss 2.3718, Accuracy: (46.44, 63.33, 70.00), Time 3.49
2019-05-18 06:51:42,972: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.8027, Accuracy: (80.43, 92.83, 95.73), (Crop) Loss 0.9706, Accuracy: (73.46, 88.20, 92.14), (Drop) Loss 2.3625, Accuracy: (46.59, 63.51, 70.17), Time 3.43
2019-05-18 06:52:21,151: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 06:52:22,315: INFO: [train_wsdan.py:483]: Valid: Loss 1.24628,  Accuracy: Top-1 66.37, Top-3 85.08, Top-5 89.76, Time 38.09
2019-05-18 06:58:09,619: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.8018, Accuracy: (80.46, 92.84, 95.73), (Crop) Loss 0.9688, Accuracy: (73.50, 88.23, 92.17), (Drop) Loss 2.3515, Accuracy: (46.77, 63.72, 70.36), Time 3.46
2019-05-18 07:03:57,253: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.8011, Accuracy: (80.47, 92.85, 95.74), (Crop) Loss 0.9675, Accuracy: (73.52, 88.25, 92.19), (Drop) Loss 2.3425, Accuracy: (46.93, 63.87, 70.50), Time 3.46
2019-05-18 07:04:34,679: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 07:04:35,852: INFO: [train_wsdan.py:483]: Valid: Loss 1.27494,  Accuracy: Top-1 66.57, Top-3 84.53, Top-5 90.53, Time 37.33
2019-05-18 07:10:23,434: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.8001, Accuracy: (80.52, 92.86, 95.74), (Crop) Loss 0.9657, Accuracy: (73.57, 88.27, 92.20), (Drop) Loss 2.3320, Accuracy: (47.12, 64.05, 70.67), Time 3.50
2019-05-18 07:16:11,039: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.7993, Accuracy: (80.56, 92.88, 95.74), (Crop) Loss 0.9639, Accuracy: (73.64, 88.28, 92.20), (Drop) Loss 2.3277, Accuracy: (47.18, 64.12, 70.75), Time 3.46
2019-05-18 07:16:49,199: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 07:16:50,365: INFO: [train_wsdan.py:483]: Valid: Loss 1.22510,  Accuracy: Top-1 66.50, Top-3 85.30, Top-5 90.02, Time 38.07
2019-05-18 07:22:37,659: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.8000, Accuracy: (80.54, 92.86, 95.73), (Crop) Loss 0.9647, Accuracy: (73.63, 88.28, 92.19), (Drop) Loss 2.3230, Accuracy: (47.25, 64.18, 70.82), Time 3.46
2019-05-18 07:28:25,272: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.7993, Accuracy: (80.55, 92.86, 95.74), (Crop) Loss 0.9634, Accuracy: (73.65, 88.30, 92.23), (Drop) Loss 2.3165, Accuracy: (47.35, 64.31, 70.93), Time 3.46
2019-05-18 07:29:02,723: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 07:29:03,888: INFO: [train_wsdan.py:483]: Valid: Loss 1.25929,  Accuracy: Top-1 66.31, Top-3 84.88, Top-5 89.73, Time 37.36
2019-05-18 07:34:51,506: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.7980, Accuracy: (80.60, 92.89, 95.76), (Crop) Loss 0.9615, Accuracy: (73.69, 88.34, 92.25), (Drop) Loss 2.3081, Accuracy: (47.50, 64.46, 71.06), Time 3.47
2019-05-18 07:40:39,084: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.7978, Accuracy: (80.60, 92.90, 95.77), (Crop) Loss 0.9613, Accuracy: (73.70, 88.35, 92.26), (Drop) Loss 2.3052, Accuracy: (47.55, 64.52, 71.12), Time 3.47
2019-05-18 07:40:39,117: INFO: [train_wsdan.py:334]: saving the latest model from epoch 4
2019-05-18 07:41:18,010: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 07:41:19,167: INFO: [train_wsdan.py:483]: Valid: Loss 1.23289,  Accuracy: Top-1 66.11, Top-3 85.20, Top-5 90.27, Time 37.52
2019-05-18 07:47:07,009: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.7970, Accuracy: (80.63, 92.90, 95.77), (Crop) Loss 0.9602, Accuracy: (73.74, 88.38, 92.27), (Drop) Loss 2.3041, Accuracy: (47.56, 64.52, 71.12), Time 3.48
2019-05-18 07:52:54,644: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.7961, Accuracy: (80.66, 92.90, 95.78), (Crop) Loss 0.9587, Accuracy: (73.79, 88.39, 92.28), (Drop) Loss 2.3034, Accuracy: (47.58, 64.54, 71.14), Time 3.47
2019-05-18 07:53:32,656: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 07:53:33,821: INFO: [train_wsdan.py:483]: Valid: Loss 1.26560,  Accuracy: Top-1 65.98, Top-3 85.34, Top-5 89.86, Time 37.92
2019-05-18 07:59:21,218: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.7955, Accuracy: (80.68, 92.91, 95.78), (Crop) Loss 0.9580, Accuracy: (73.79, 88.40, 92.29), (Drop) Loss 2.3042, Accuracy: (47.59, 64.53, 71.13), Time 3.46
2019-05-18 08:05:08,690: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.7953, Accuracy: (80.69, 92.91, 95.78), (Crop) Loss 0.9577, Accuracy: (73.79, 88.41, 92.30), (Drop) Loss 2.3069, Accuracy: (47.56, 64.49, 71.09), Time 3.45
2019-05-18 08:05:46,637: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 08:05:47,810: INFO: [train_wsdan.py:483]: Valid: Loss 1.27029,  Accuracy: Top-1 66.44, Top-3 84.23, Top-5 89.89, Time 37.85
2019-05-18 08:11:35,231: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.7952, Accuracy: (80.69, 92.91, 95.79), (Crop) Loss 0.9574, Accuracy: (73.80, 88.41, 92.31), (Drop) Loss 2.3037, Accuracy: (47.62, 64.56, 71.16), Time 3.46
2019-05-18 08:17:23,007: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.7953, Accuracy: (80.69, 92.91, 95.79), (Crop) Loss 0.9570, Accuracy: (73.80, 88.42, 92.32), (Drop) Loss 2.2982, Accuracy: (47.70, 64.65, 71.26), Time 3.48
2019-05-18 08:18:00,473: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 08:18:01,637: INFO: [train_wsdan.py:483]: Valid: Loss 1.24117,  Accuracy: Top-1 66.28, Top-3 85.08, Top-5 90.66, Time 37.37
2019-05-18 08:23:49,345: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.7949, Accuracy: (80.72, 92.92, 95.79), (Crop) Loss 0.9570, Accuracy: (73.81, 88.42, 92.32), (Drop) Loss 2.2950, Accuracy: (47.76, 64.70, 71.31), Time 3.48
2019-05-18 08:29:37,333: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.7943, Accuracy: (80.75, 92.94, 95.81), (Crop) Loss 0.9563, Accuracy: (73.83, 88.43, 92.33), (Drop) Loss 2.2963, Accuracy: (47.75, 64.69, 71.29), Time 3.47
2019-05-18 08:30:15,261: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 08:30:16,435: INFO: [train_wsdan.py:483]: Valid: Loss 1.29608,  Accuracy: Top-1 66.63, Top-3 83.97, Top-5 89.62, Time 37.83
2019-05-18 08:36:03,698: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.7938, Accuracy: (80.77, 92.95, 95.81), (Crop) Loss 0.9554, Accuracy: (73.86, 88.44, 92.34), (Drop) Loss 2.2932, Accuracy: (47.81, 64.75, 71.35), Time 3.48
2019-05-18 08:41:51,045: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.7939, Accuracy: (80.76, 92.96, 95.82), (Crop) Loss 0.9557, Accuracy: (73.84, 88.44, 92.36), (Drop) Loss 2.2956, Accuracy: (47.76, 64.72, 71.31), Time 3.50
2019-05-18 08:41:51,045: INFO: [train_wsdan.py:334]: saving the latest model from epoch 4
2019-05-18 08:42:29,883: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 08:42:31,057: INFO: [train_wsdan.py:483]: Valid: Loss 1.23654,  Accuracy: Top-1 67.25, Top-3 84.85, Top-5 90.66, Time 37.54
2019-05-18 08:48:18,875: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.7935, Accuracy: (80.76, 92.96, 95.82), (Crop) Loss 0.9549, Accuracy: (73.85, 88.45, 92.36), (Drop) Loss 2.2941, Accuracy: (47.77, 64.74, 71.33), Time 3.50
2019-05-18 08:50:51,971: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.7934, Accuracy: (80.77, 92.96, 95.82), (Crop) Loss 0.9547, Accuracy: (73.86, 88.45, 92.37), (Drop) Loss 2.2940, Accuracy: (47.77, 64.75, 71.33), Time 15210.84
2019-05-18 08:51:29,192: INFO: [train_wsdan.py:471]: saving the best model from epoch 4
2019-05-18 08:51:30,357: INFO: [train_wsdan.py:483]: Valid: Loss 1.26012,  Accuracy: Top-1 66.48, Top-3 84.91, Top-5 89.59, Time 37.12
2019-05-18 08:51:30,365: INFO: [train_wsdan.py:220]: Epoch 005, Learning Rate 0.00052488
2019-05-18 08:57:32,322: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.9175, Accuracy: (78.52, 91.41, 94.75), (Crop) Loss 1.2526, Accuracy: (67.89, 84.05, 89.11), (Drop) Loss 2.1167, Accuracy: (51.89, 69.03, 75.48), Time 3.57
2019-05-18 09:03:26,859: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.8782, Accuracy: (79.27, 92.01, 94.98), (Crop) Loss 1.2162, Accuracy: (68.59, 84.50, 89.35), (Drop) Loss 2.0431, Accuracy: (53.52, 69.99, 76.06), Time 3.54
2019-05-18 09:04:04,524: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 09:04:05,708: INFO: [train_wsdan.py:483]: Valid: Loss 1.23112,  Accuracy: Top-1 66.92, Top-3 84.88, Top-5 90.40, Time 37.57
2019-05-18 09:09:53,035: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.8236, Accuracy: (80.60, 92.78, 95.53), (Crop) Loss 1.0806, Accuracy: (71.57, 86.58, 91.00), (Drop) Loss 2.2543, Accuracy: (49.55, 65.97, 72.40), Time 3.47
2019-05-18 09:15:40,505: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.7920, Accuracy: (81.42, 93.27, 95.84), (Crop) Loss 1.0070, Accuracy: (73.13, 87.69, 91.85), (Drop) Loss 2.3139, Accuracy: (48.29, 64.68, 71.11), Time 3.53
2019-05-18 09:16:18,804: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 09:16:20,096: INFO: [train_wsdan.py:483]: Valid: Loss 1.29167,  Accuracy: Top-1 66.18, Top-3 83.97, Top-5 89.63, Time 38.20
2019-05-18 09:22:08,165: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.7761, Accuracy: (81.72, 93.48, 96.06), (Crop) Loss 0.9680, Accuracy: (74.08, 88.28, 92.28), (Drop) Loss 2.3342, Accuracy: (47.88, 64.17, 70.69), Time 3.46
2019-05-18 09:27:56,278: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.7614, Accuracy: (82.05, 93.66, 96.18), (Crop) Loss 0.9408, Accuracy: (74.73, 88.67, 92.57), (Drop) Loss 2.2782, Accuracy: (48.61, 65.09, 71.60), Time 3.55
2019-05-18 09:28:34,811: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 09:28:36,036: INFO: [train_wsdan.py:483]: Valid: Loss 1.23922,  Accuracy: Top-1 66.86, Top-3 84.75, Top-5 90.21, Time 38.44
2019-05-18 09:34:24,532: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.7529, Accuracy: (82.30, 93.75, 96.20), (Crop) Loss 0.9249, Accuracy: (75.10, 88.86, 92.70), (Drop) Loss 2.2703, Accuracy: (48.65, 65.22, 71.73), Time 3.48
2019-05-18 09:40:12,451: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.7479, Accuracy: (82.43, 93.83, 96.25), (Crop) Loss 0.9136, Accuracy: (75.30, 89.08, 92.86), (Drop) Loss 2.2524, Accuracy: (48.91, 65.52, 72.06), Time 3.49
2019-05-18 09:40:49,931: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 09:40:51,154: INFO: [train_wsdan.py:483]: Valid: Loss 1.26360,  Accuracy: Top-1 66.89, Top-3 84.53, Top-5 90.14, Time 37.39
2019-05-18 09:46:38,884: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.7414, Accuracy: (82.56, 93.93, 96.32), (Crop) Loss 0.9027, Accuracy: (75.43, 89.25, 92.98), (Drop) Loss 2.2496, Accuracy: (48.90, 65.53, 72.07), Time 3.53
2019-05-18 09:52:26,730: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.7385, Accuracy: (82.60, 94.00, 96.38), (Crop) Loss 0.8947, Accuracy: (75.54, 89.40, 93.06), (Drop) Loss 2.2802, Accuracy: (48.44, 65.00, 71.55), Time 3.48
2019-05-18 09:52:26,758: INFO: [train_wsdan.py:334]: saving the latest model from epoch 5
2019-05-18 09:53:05,975: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 09:53:07,150: INFO: [train_wsdan.py:483]: Valid: Loss 1.26608,  Accuracy: Top-1 66.14, Top-3 84.52, Top-5 89.79, Time 37.91
2019-05-18 09:58:54,632: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.7353, Accuracy: (82.64, 94.04, 96.41), (Crop) Loss 0.8879, Accuracy: (75.63, 89.48, 93.14), (Drop) Loss 2.2728, Accuracy: (48.57, 65.14, 71.66), Time 3.48
2019-05-18 10:04:42,056: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.7316, Accuracy: (82.77, 94.11, 96.47), (Crop) Loss 0.8812, Accuracy: (75.78, 89.59, 93.22), (Drop) Loss 2.2809, Accuracy: (48.44, 65.00, 71.55), Time 3.54
2019-05-18 10:05:20,306: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 10:05:21,468: INFO: [train_wsdan.py:483]: Valid: Loss 1.22318,  Accuracy: Top-1 67.22, Top-3 84.98, Top-5 90.57, Time 38.16
2019-05-18 10:11:09,405: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.7296, Accuracy: (82.82, 94.13, 96.47), (Crop) Loss 0.8763, Accuracy: (75.89, 89.62, 93.25), (Drop) Loss 2.2765, Accuracy: (48.55, 65.05, 71.58), Time 3.53
2019-05-18 10:16:57,302: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.7267, Accuracy: (82.93, 94.15, 96.49), (Crop) Loss 0.8704, Accuracy: (76.05, 89.71, 93.30), (Drop) Loss 2.2691, Accuracy: (48.69, 65.19, 71.68), Time 3.47
2019-05-18 10:17:34,848: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 10:17:36,024: INFO: [train_wsdan.py:483]: Valid: Loss 1.27330,  Accuracy: Top-1 66.47, Top-3 85.10, Top-5 89.91, Time 37.45
2019-05-18 10:23:23,928: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.7262, Accuracy: (82.95, 94.17, 96.50), (Crop) Loss 0.8675, Accuracy: (76.08, 89.76, 93.36), (Drop) Loss 2.2740, Accuracy: (48.60, 65.07, 71.55), Time 3.49
2019-05-18 10:29:11,956: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.7236, Accuracy: (83.01, 94.20, 96.52), (Crop) Loss 0.8639, Accuracy: (76.17, 89.82, 93.40), (Drop) Loss 2.2844, Accuracy: (48.49, 64.88, 71.31), Time 3.48
2019-05-18 10:29:49,842: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 10:29:50,999: INFO: [train_wsdan.py:483]: Valid: Loss 1.30556,  Accuracy: Top-1 66.44, Top-3 83.87, Top-5 89.17, Time 37.79
2019-05-18 10:35:38,256: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.7228, Accuracy: (83.01, 94.19, 96.54), (Crop) Loss 0.8625, Accuracy: (76.20, 89.84, 93.40), (Drop) Loss 2.2923, Accuracy: (48.31, 64.71, 71.17), Time 3.46
2019-05-18 10:41:26,046: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.7205, Accuracy: (83.07, 94.22, 96.57), (Crop) Loss 0.8597, Accuracy: (76.26, 89.87, 93.44), (Drop) Loss 2.2818, Accuracy: (48.49, 64.88, 71.32), Time 3.47
2019-05-18 10:42:03,806: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 10:42:06,846: INFO: [train_wsdan.py:483]: Valid: Loss 1.27656,  Accuracy: Top-1 66.73, Top-3 85.14, Top-5 90.08, Time 37.67
2019-05-18 10:47:54,454: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.7209, Accuracy: (83.05, 94.22, 96.57), (Crop) Loss 0.8590, Accuracy: (76.26, 89.89, 93.45), (Drop) Loss 2.2828, Accuracy: (48.47, 64.90, 71.31), Time 3.46
2019-05-18 10:53:42,264: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.7204, Accuracy: (83.09, 94.22, 96.57), (Crop) Loss 0.8586, Accuracy: (76.27, 89.91, 93.45), (Drop) Loss 2.2648, Accuracy: (48.81, 65.23, 71.60), Time 3.47
2019-05-18 10:53:42,264: INFO: [train_wsdan.py:334]: saving the latest model from epoch 5
2019-05-18 10:54:21,047: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 10:54:22,254: INFO: [train_wsdan.py:483]: Valid: Loss 1.22617,  Accuracy: Top-1 67.64, Top-3 84.91, Top-5 90.28, Time 37.43
2019-05-18 11:00:09,879: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.7190, Accuracy: (83.13, 94.24, 96.57), (Crop) Loss 0.8566, Accuracy: (76.30, 89.93, 93.47), (Drop) Loss 2.2546, Accuracy: (48.97, 65.39, 71.75), Time 3.47
2019-05-18 11:05:57,915: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.7189, Accuracy: (83.17, 94.25, 96.58), (Crop) Loss 0.8565, Accuracy: (76.31, 89.94, 93.46), (Drop) Loss 2.2473, Accuracy: (49.08, 65.55, 71.88), Time 3.48
2019-05-18 11:06:35,998: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 11:06:37,178: INFO: [train_wsdan.py:483]: Valid: Loss 1.24649,  Accuracy: Top-1 66.89, Top-3 85.14, Top-5 90.31, Time 37.95
2019-05-18 11:12:25,245: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.7177, Accuracy: (83.21, 94.28, 96.59), (Crop) Loss 0.8547, Accuracy: (76.32, 89.98, 93.49), (Drop) Loss 2.2572, Accuracy: (48.92, 65.37, 71.71), Time 3.51
2019-05-18 11:18:13,243: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.7167, Accuracy: (83.25, 94.28, 96.59), (Crop) Loss 0.8539, Accuracy: (76.35, 89.99, 93.50), (Drop) Loss 2.2576, Accuracy: (48.91, 65.36, 71.70), Time 3.45
2019-05-18 11:18:51,053: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 11:18:52,226: INFO: [train_wsdan.py:483]: Valid: Loss 1.21768,  Accuracy: Top-1 66.73, Top-3 85.62, Top-5 90.92, Time 37.72
2019-05-18 11:24:39,432: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.7151, Accuracy: (83.30, 94.29, 96.60), (Crop) Loss 0.8518, Accuracy: (76.41, 90.01, 93.51), (Drop) Loss 2.2516, Accuracy: (49.00, 65.46, 71.80), Time 3.47
2019-05-18 11:30:26,732: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.7146, Accuracy: (83.31, 94.30, 96.61), (Crop) Loss 0.8512, Accuracy: (76.42, 90.03, 93.52), (Drop) Loss 2.2474, Accuracy: (49.07, 65.55, 71.89), Time 3.46
2019-05-18 11:31:04,763: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 11:31:05,927: INFO: [train_wsdan.py:483]: Valid: Loss 1.20245,  Accuracy: Top-1 68.42, Top-3 85.63, Top-5 90.34, Time 37.94
2019-05-18 11:36:53,208: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.7143, Accuracy: (83.30, 94.30, 96.61), (Crop) Loss 0.8502, Accuracy: (76.42, 90.04, 93.53), (Drop) Loss 2.2410, Accuracy: (49.16, 65.65, 71.98), Time 3.46
2019-05-18 11:42:40,938: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.7148, Accuracy: (83.28, 94.29, 96.61), (Crop) Loss 0.8512, Accuracy: (76.39, 90.03, 93.52), (Drop) Loss 2.2324, Accuracy: (49.30, 65.82, 72.14), Time 3.47
2019-05-18 11:43:18,992: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 11:43:20,151: INFO: [train_wsdan.py:483]: Valid: Loss 1.21879,  Accuracy: Top-1 67.87, Top-3 84.85, Top-5 90.37, Time 37.96
2019-05-18 11:49:07,990: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.7140, Accuracy: (83.31, 94.30, 96.63), (Crop) Loss 0.8497, Accuracy: (76.43, 90.06, 93.53), (Drop) Loss 2.2308, Accuracy: (49.33, 65.85, 72.18), Time 3.47
2019-05-18 11:54:55,708: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.7136, Accuracy: (83.31, 94.31, 96.63), (Crop) Loss 0.8484, Accuracy: (76.47, 90.08, 93.55), (Drop) Loss 2.2327, Accuracy: (49.30, 65.81, 72.15), Time 3.47
2019-05-18 11:54:55,708: INFO: [train_wsdan.py:334]: saving the latest model from epoch 5
2019-05-18 11:55:35,636: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 11:55:36,880: INFO: [train_wsdan.py:483]: Valid: Loss 1.23249,  Accuracy: Top-1 67.18, Top-3 85.27, Top-5 90.31, Time 38.59
2019-05-18 12:01:25,180: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.7133, Accuracy: (83.32, 94.31, 96.63), (Crop) Loss 0.8478, Accuracy: (76.50, 90.08, 93.55), (Drop) Loss 2.2309, Accuracy: (49.31, 65.83, 72.17), Time 3.52
2019-05-18 12:07:13,355: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.7125, Accuracy: (83.36, 94.32, 96.63), (Crop) Loss 0.8470, Accuracy: (76.52, 90.08, 93.56), (Drop) Loss 2.2291, Accuracy: (49.33, 65.85, 72.18), Time 3.47
2019-05-18 12:07:51,610: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 12:07:52,783: INFO: [train_wsdan.py:483]: Valid: Loss 1.21081,  Accuracy: Top-1 67.74, Top-3 85.64, Top-5 90.54, Time 38.11
2019-05-18 12:13:40,238: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.7112, Accuracy: (83.39, 94.33, 96.64), (Crop) Loss 0.8458, Accuracy: (76.54, 90.11, 93.57), (Drop) Loss 2.2318, Accuracy: (49.27, 65.80, 72.13), Time 3.47
2019-05-18 12:19:27,833: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.7106, Accuracy: (83.41, 94.35, 96.66), (Crop) Loss 0.8448, Accuracy: (76.57, 90.12, 93.58), (Drop) Loss 2.2369, Accuracy: (49.19, 65.71, 72.04), Time 3.46
2019-05-18 12:20:06,047: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 12:20:07,225: INFO: [train_wsdan.py:483]: Valid: Loss 1.21757,  Accuracy: Top-1 67.71, Top-3 86.15, Top-5 90.57, Time 38.12
2019-05-18 12:25:54,801: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.7098, Accuracy: (83.41, 94.38, 96.67), (Crop) Loss 0.8437, Accuracy: (76.59, 90.14, 93.60), (Drop) Loss 2.2394, Accuracy: (49.15, 65.67, 72.01), Time 3.46
2019-05-18 12:31:42,316: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.7094, Accuracy: (83.43, 94.38, 96.68), (Crop) Loss 0.8435, Accuracy: (76.58, 90.15, 93.60), (Drop) Loss 2.2394, Accuracy: (49.15, 65.66, 72.01), Time 3.47
2019-05-18 12:32:19,475: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 12:32:20,436: INFO: [train_wsdan.py:483]: Valid: Loss 1.22774,  Accuracy: Top-1 67.78, Top-3 84.30, Top-5 89.83, Time 37.06
2019-05-18 12:38:08,099: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.7085, Accuracy: (83.45, 94.39, 96.69), (Crop) Loss 0.8423, Accuracy: (76.62, 90.16, 93.62), (Drop) Loss 2.2411, Accuracy: (49.15, 65.65, 71.97), Time 3.48
2019-05-18 12:43:56,126: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.7080, Accuracy: (83.48, 94.39, 96.70), (Crop) Loss 0.8412, Accuracy: (76.65, 90.18, 93.64), (Drop) Loss 2.2426, Accuracy: (49.14, 65.61, 71.94), Time 3.48
2019-05-18 12:44:34,035: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 12:44:35,203: INFO: [train_wsdan.py:483]: Valid: Loss 1.21858,  Accuracy: Top-1 68.10, Top-3 85.21, Top-5 90.18, Time 37.81
2019-05-18 12:50:22,921: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.7083, Accuracy: (83.47, 94.39, 96.69), (Crop) Loss 0.8417, Accuracy: (76.64, 90.17, 93.63), (Drop) Loss 2.2439, Accuracy: (49.12, 65.59, 71.92), Time 3.52
2019-05-18 12:56:11,002: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.7081, Accuracy: (83.45, 94.39, 96.70), (Crop) Loss 0.8416, Accuracy: (76.64, 90.17, 93.64), (Drop) Loss 2.2415, Accuracy: (49.16, 65.63, 71.96), Time 3.48
2019-05-18 12:56:11,002: INFO: [train_wsdan.py:334]: saving the latest model from epoch 5
2019-05-18 12:56:49,673: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 12:56:50,850: INFO: [train_wsdan.py:483]: Valid: Loss 1.22214,  Accuracy: Top-1 66.80, Top-3 84.75, Top-5 90.21, Time 37.32
2019-05-18 13:02:38,740: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.7075, Accuracy: (83.48, 94.40, 96.70), (Crop) Loss 0.8403, Accuracy: (76.68, 90.20, 93.65), (Drop) Loss 2.2398, Accuracy: (49.20, 65.67, 71.98), Time 3.47
2019-05-18 13:05:11,761: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.7072, Accuracy: (83.50, 94.40, 96.70), (Crop) Loss 0.8399, Accuracy: (76.70, 90.21, 93.66), (Drop) Loss 2.2385, Accuracy: (49.22, 65.69, 72.00), Time 15221.40
2019-05-18 13:05:49,357: INFO: [train_wsdan.py:471]: saving the best model from epoch 5
2019-05-18 13:05:51,880: INFO: [train_wsdan.py:483]: Valid: Loss 1.19641,  Accuracy: Top-1 68.00, Top-3 85.79, Top-5 91.18, Time 37.50
2019-05-18 13:05:51,889: INFO: [train_wsdan.py:220]: Epoch 006, Learning Rate 0.000425153
2019-05-18 13:11:52,263: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.8624, Accuracy: (79.45, 92.69, 95.56), (Crop) Loss 1.2215, Accuracy: (67.84, 84.38, 88.78), (Drop) Loss 2.0774, Accuracy: (52.44, 69.72, 75.86), Time 3.56
2019-05-18 13:17:47,014: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.8315, Accuracy: (80.16, 92.98, 95.77), (Crop) Loss 1.1673, Accuracy: (69.20, 85.34, 89.66), (Drop) Loss 2.0520, Accuracy: (53.09, 70.14, 76.27), Time 3.54
2019-05-18 13:18:25,859: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 13:18:28,370: INFO: [train_wsdan.py:483]: Valid: Loss 1.21246,  Accuracy: Top-1 67.61, Top-3 84.89, Top-5 90.11, Time 38.75
2019-05-18 13:24:16,022: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.7637, Accuracy: (82.03, 93.81, 96.26), (Crop) Loss 1.0118, Accuracy: (72.94, 87.63, 91.38), (Drop) Loss 2.1746, Accuracy: (50.79, 67.60, 73.83), Time 3.46
2019-05-18 13:30:03,539: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.7332, Accuracy: (82.92, 94.18, 96.57), (Crop) Loss 0.9360, Accuracy: (74.51, 88.70, 92.34), (Drop) Loss 2.2458, Accuracy: (49.37, 66.14, 72.45), Time 3.47
2019-05-18 13:30:41,555: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 13:30:42,722: INFO: [train_wsdan.py:483]: Valid: Loss 1.20813,  Accuracy: Top-1 67.71, Top-3 85.43, Top-5 90.60, Time 37.89
2019-05-18 13:36:30,293: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.7138, Accuracy: (83.56, 94.45, 96.72), (Crop) Loss 0.8863, Accuracy: (75.73, 89.44, 92.91), (Drop) Loss 2.2564, Accuracy: (49.19, 65.88, 72.16), Time 3.47
2019-05-18 13:42:18,053: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.6989, Accuracy: (83.98, 94.65, 96.88), (Crop) Loss 0.8565, Accuracy: (76.41, 89.90, 93.33), (Drop) Loss 2.2509, Accuracy: (49.27, 65.93, 72.22), Time 3.47
2019-05-18 13:42:56,106: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 13:42:57,941: INFO: [train_wsdan.py:483]: Valid: Loss 1.23013,  Accuracy: Top-1 68.52, Top-3 85.62, Top-5 90.41, Time 37.96
2019-05-18 13:48:45,592: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.6895, Accuracy: (84.31, 94.80, 96.93), (Crop) Loss 0.8378, Accuracy: (76.92, 90.18, 93.54), (Drop) Loss 2.2603, Accuracy: (49.13, 65.74, 72.01), Time 3.47
2019-05-18 13:54:33,353: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.6826, Accuracy: (84.46, 94.88, 96.99), (Crop) Loss 0.8232, Accuracy: (77.23, 90.43, 93.71), (Drop) Loss 2.2664, Accuracy: (49.07, 65.58, 71.84), Time 3.46
2019-05-18 13:55:10,790: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 13:55:11,988: INFO: [train_wsdan.py:483]: Valid: Loss 1.20325,  Accuracy: Top-1 68.97, Top-3 85.92, Top-5 91.25, Time 37.34
2019-05-18 14:01:00,122: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.6771, Accuracy: (84.65, 94.97, 97.05), (Crop) Loss 0.8116, Accuracy: (77.46, 90.56, 93.81), (Drop) Loss 2.2769, Accuracy: (48.94, 65.39, 71.61), Time 3.49
2019-05-18 14:06:48,332: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.6719, Accuracy: (84.77, 95.03, 97.09), (Crop) Loss 0.8014, Accuracy: (77.69, 90.70, 93.92), (Drop) Loss 2.2742, Accuracy: (49.10, 65.43, 71.62), Time 3.47
2019-05-18 14:06:48,332: INFO: [train_wsdan.py:334]: saving the latest model from epoch 6
2019-05-18 14:07:27,120: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 14:07:28,288: INFO: [train_wsdan.py:483]: Valid: Loss 1.22009,  Accuracy: Top-1 67.44, Top-3 85.27, Top-5 90.41, Time 37.49
2019-05-18 14:13:15,915: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.6685, Accuracy: (84.85, 95.05, 97.12), (Crop) Loss 0.7957, Accuracy: (77.80, 90.79, 93.98), (Drop) Loss 2.2606, Accuracy: (49.31, 65.67, 71.81), Time 3.48
2019-05-18 14:19:03,321: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.6632, Accuracy: (85.01, 95.12, 97.18), (Crop) Loss 0.7888, Accuracy: (78.00, 90.89, 94.04), (Drop) Loss 2.2462, Accuracy: (49.56, 65.86, 72.01), Time 3.48
2019-05-18 14:19:41,287: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 14:19:42,463: INFO: [train_wsdan.py:483]: Valid: Loss 1.20710,  Accuracy: Top-1 68.55, Top-3 85.11, Top-5 90.44, Time 37.87
2019-05-18 14:25:29,875: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.6594, Accuracy: (85.12, 95.17, 97.22), (Crop) Loss 0.7837, Accuracy: (78.16, 90.93, 94.08), (Drop) Loss 2.2444, Accuracy: (49.59, 65.88, 72.04), Time 3.47
2019-05-18 14:31:17,343: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.6579, Accuracy: (85.15, 95.19, 97.21), (Crop) Loss 0.7791, Accuracy: (78.27, 91.02, 94.17), (Drop) Loss 2.2345, Accuracy: (49.75, 66.05, 72.21), Time 3.48
2019-05-18 14:31:55,416: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 14:31:58,333: INFO: [train_wsdan.py:483]: Valid: Loss 1.21749,  Accuracy: Top-1 68.29, Top-3 85.86, Top-5 90.25, Time 37.94
2019-05-18 14:37:46,057: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.6558, Accuracy: (85.19, 95.23, 97.23), (Crop) Loss 0.7737, Accuracy: (78.41, 91.08, 94.22), (Drop) Loss 2.2223, Accuracy: (49.96, 66.24, 72.40), Time 3.47
2019-05-18 14:43:33,839: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.6536, Accuracy: (85.27, 95.28, 97.25), (Crop) Loss 0.7693, Accuracy: (78.53, 91.17, 94.30), (Drop) Loss 2.2236, Accuracy: (49.93, 66.21, 72.37), Time 3.47
2019-05-18 14:44:12,007: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 14:44:13,171: INFO: [train_wsdan.py:483]: Valid: Loss 1.19408,  Accuracy: Top-1 68.35, Top-3 85.67, Top-5 90.37, Time 38.07
2019-05-18 14:50:01,138: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.6531, Accuracy: (85.27, 95.28, 97.24), (Crop) Loss 0.7668, Accuracy: (78.57, 91.22, 94.32), (Drop) Loss 2.2216, Accuracy: (49.99, 66.23, 72.37), Time 3.48
2019-05-18 14:55:49,147: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.6523, Accuracy: (85.29, 95.30, 97.27), (Crop) Loss 0.7650, Accuracy: (78.62, 91.24, 94.35), (Drop) Loss 2.2303, Accuracy: (49.85, 66.05, 72.20), Time 3.48
2019-05-18 14:56:26,563: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 14:56:27,805: INFO: [train_wsdan.py:483]: Valid: Loss 1.23606,  Accuracy: Top-1 68.45, Top-3 85.18, Top-5 90.02, Time 37.31
2019-05-18 15:02:15,509: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.6513, Accuracy: (85.31, 95.31, 97.27), (Crop) Loss 0.7622, Accuracy: (78.68, 91.28, 94.39), (Drop) Loss 2.2288, Accuracy: (49.86, 66.05, 72.21), Time 3.47
2019-05-18 15:08:03,580: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.6509, Accuracy: (85.32, 95.32, 97.28), (Crop) Loss 0.7612, Accuracy: (78.70, 91.32, 94.41), (Drop) Loss 2.2178, Accuracy: (50.05, 66.24, 72.41), Time 3.45
2019-05-18 15:08:03,580: INFO: [train_wsdan.py:334]: saving the latest model from epoch 6
2019-05-18 15:08:42,827: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 15:08:44,045: INFO: [train_wsdan.py:483]: Valid: Loss 1.21341,  Accuracy: Top-1 68.61, Top-3 85.96, Top-5 90.83, Time 37.91
2019-05-18 15:14:31,884: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.6502, Accuracy: (85.33, 95.34, 97.29), (Crop) Loss 0.7600, Accuracy: (78.74, 91.33, 94.43), (Drop) Loss 2.2082, Accuracy: (50.19, 66.40, 72.57), Time 3.51
2019-05-18 15:20:19,734: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.6492, Accuracy: (85.34, 95.35, 97.30), (Crop) Loss 0.7588, Accuracy: (78.75, 91.35, 94.45), (Drop) Loss 2.2008, Accuracy: (50.32, 66.53, 72.68), Time 3.47
2019-05-18 15:20:56,982: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 15:20:58,205: INFO: [train_wsdan.py:483]: Valid: Loss 1.22988,  Accuracy: Top-1 67.19, Top-3 85.57, Top-5 90.57, Time 37.15
2019-05-18 15:26:46,006: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.6482, Accuracy: (85.36, 95.36, 97.31), (Crop) Loss 0.7589, Accuracy: (78.75, 91.35, 94.44), (Drop) Loss 2.1964, Accuracy: (50.36, 66.57, 72.77), Time 3.44
2019-05-18 15:32:34,520: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.6477, Accuracy: (85.39, 95.38, 97.31), (Crop) Loss 0.7586, Accuracy: (78.76, 91.34, 94.45), (Drop) Loss 2.1961, Accuracy: (50.37, 66.56, 72.76), Time 3.48
2019-05-18 15:33:11,704: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 15:33:12,872: INFO: [train_wsdan.py:483]: Valid: Loss 1.17525,  Accuracy: Top-1 68.91, Top-3 85.89, Top-5 90.95, Time 37.09
2019-05-18 15:39:00,817: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.6474, Accuracy: (85.39, 95.36, 97.31), (Crop) Loss 0.7574, Accuracy: (78.80, 91.35, 94.46), (Drop) Loss 2.1910, Accuracy: (50.45, 66.62, 72.82), Time 3.47
2019-05-18 15:44:48,675: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.6465, Accuracy: (85.41, 95.38, 97.32), (Crop) Loss 0.7556, Accuracy: (78.85, 91.39, 94.49), (Drop) Loss 2.1916, Accuracy: (50.44, 66.61, 72.81), Time 3.47
2019-05-18 15:45:26,763: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 15:45:27,960: INFO: [train_wsdan.py:483]: Valid: Loss 1.22248,  Accuracy: Top-1 68.95, Top-3 85.83, Top-5 90.96, Time 37.98
2019-05-18 15:51:15,726: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.6454, Accuracy: (85.45, 95.41, 97.34), (Crop) Loss 0.7547, Accuracy: (78.87, 91.40, 94.49), (Drop) Loss 2.1887, Accuracy: (50.50, 66.66, 72.85), Time 3.47
2019-05-18 15:57:03,267: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.6449, Accuracy: (85.47, 95.41, 97.35), (Crop) Loss 0.7531, Accuracy: (78.89, 91.43, 94.52), (Drop) Loss 2.1860, Accuracy: (50.55, 66.71, 72.90), Time 3.54
2019-05-18 15:57:41,587: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 15:57:42,759: INFO: [train_wsdan.py:483]: Valid: Loss 1.21713,  Accuracy: Top-1 68.81, Top-3 85.96, Top-5 91.35, Time 38.23
2019-05-18 16:03:30,530: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.6448, Accuracy: (85.49, 95.42, 97.35), (Crop) Loss 0.7525, Accuracy: (78.91, 91.45, 94.52), (Drop) Loss 2.1853, Accuracy: (50.58, 66.73, 72.91), Time 3.48
2019-05-18 16:09:17,978: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.6445, Accuracy: (85.50, 95.41, 97.34), (Crop) Loss 0.7526, Accuracy: (78.90, 91.43, 94.51), (Drop) Loss 2.1795, Accuracy: (50.68, 66.82, 72.98), Time 3.46
2019-05-18 16:09:17,979: INFO: [train_wsdan.py:334]: saving the latest model from epoch 6
2019-05-18 16:09:57,005: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 16:09:58,163: INFO: [train_wsdan.py:483]: Valid: Loss 1.19355,  Accuracy: Top-1 69.13, Top-3 85.66, Top-5 90.96, Time 37.68
2019-05-18 16:15:45,928: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.6435, Accuracy: (85.51, 95.42, 97.35), (Crop) Loss 0.7506, Accuracy: (78.95, 91.47, 94.55), (Drop) Loss 2.1779, Accuracy: (50.70, 66.85, 73.00), Time 3.49
2019-05-18 16:21:33,956: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.6432, Accuracy: (85.52, 95.43, 97.35), (Crop) Loss 0.7499, Accuracy: (78.98, 91.49, 94.56), (Drop) Loss 2.1761, Accuracy: (50.71, 66.87, 73.03), Time 3.47
2019-05-18 16:22:12,111: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 16:22:13,270: INFO: [train_wsdan.py:483]: Valid: Loss 1.20504,  Accuracy: Top-1 68.59, Top-3 86.05, Top-5 90.73, Time 38.06
2019-05-18 16:28:01,125: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.6424, Accuracy: (85.55, 95.43, 97.35), (Crop) Loss 0.7489, Accuracy: (79.01, 91.51, 94.57), (Drop) Loss 2.1723, Accuracy: (50.79, 66.92, 73.09), Time 3.50
2019-05-18 16:33:49,050: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.6425, Accuracy: (85.56, 95.43, 97.35), (Crop) Loss 0.7490, Accuracy: (79.01, 91.52, 94.58), (Drop) Loss 2.1724, Accuracy: (50.78, 66.93, 73.09), Time 3.49
2019-05-18 16:34:26,935: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 16:34:28,117: INFO: [train_wsdan.py:483]: Valid: Loss 1.20127,  Accuracy: Top-1 68.46, Top-3 86.08, Top-5 90.60, Time 37.79
2019-05-18 16:40:15,494: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.6424, Accuracy: (85.55, 95.44, 97.35), (Crop) Loss 0.7492, Accuracy: (79.00, 91.53, 94.59), (Drop) Loss 2.1720, Accuracy: (50.79, 66.92, 73.07), Time 3.48
2019-05-18 16:46:03,418: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.6418, Accuracy: (85.56, 95.45, 97.36), (Crop) Loss 0.7485, Accuracy: (79.03, 91.55, 94.60), (Drop) Loss 2.1736, Accuracy: (50.77, 66.89, 73.04), Time 3.48
2019-05-18 16:46:41,639: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 16:46:42,884: INFO: [train_wsdan.py:483]: Valid: Loss 1.20925,  Accuracy: Top-1 67.97, Top-3 85.70, Top-5 90.60, Time 38.10
2019-05-18 16:52:30,907: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.6416, Accuracy: (85.57, 95.45, 97.36), (Crop) Loss 0.7479, Accuracy: (79.04, 91.56, 94.61), (Drop) Loss 2.1732, Accuracy: (50.79, 66.89, 73.02), Time 3.48
2019-05-18 16:58:18,546: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.6414, Accuracy: (85.58, 95.45, 97.37), (Crop) Loss 0.7482, Accuracy: (79.02, 91.55, 94.60), (Drop) Loss 2.1766, Accuracy: (50.73, 66.83, 72.96), Time 3.45
2019-05-18 16:58:55,901: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 16:58:57,064: INFO: [train_wsdan.py:483]: Valid: Loss 1.19375,  Accuracy: Top-1 69.92, Top-3 85.93, Top-5 90.83, Time 37.26
2019-05-18 17:04:44,873: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.6414, Accuracy: (85.58, 95.43, 97.36), (Crop) Loss 0.7476, Accuracy: (79.05, 91.54, 94.60), (Drop) Loss 2.1764, Accuracy: (50.75, 66.83, 72.95), Time 3.47
2019-05-18 17:10:32,834: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.6410, Accuracy: (85.59, 95.44, 97.37), (Crop) Loss 0.7466, Accuracy: (79.07, 91.57, 94.61), (Drop) Loss 2.1773, Accuracy: (50.74, 66.80, 72.91), Time 3.48
2019-05-18 17:10:32,835: INFO: [train_wsdan.py:334]: saving the latest model from epoch 6
2019-05-18 17:11:13,656: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 17:11:14,870: INFO: [train_wsdan.py:483]: Valid: Loss 1.20210,  Accuracy: Top-1 68.95, Top-3 85.57, Top-5 91.08, Time 37.49
2019-05-18 17:17:03,074: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.6403, Accuracy: (85.60, 95.45, 97.38), (Crop) Loss 0.7452, Accuracy: (79.08, 91.59, 94.63), (Drop) Loss 2.1763, Accuracy: (50.76, 66.80, 72.90), Time 3.49
2019-05-18 17:19:36,342: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.6402, Accuracy: (85.60, 95.45, 97.38), (Crop) Loss 0.7449, Accuracy: (79.09, 91.59, 94.63), (Drop) Loss 2.1758, Accuracy: (50.76, 66.81, 72.92), Time 15224.45
2019-05-18 17:20:13,763: INFO: [train_wsdan.py:471]: saving the best model from epoch 6
2019-05-18 17:20:14,980: INFO: [train_wsdan.py:483]: Valid: Loss 1.16713,  Accuracy: Top-1 68.78, Top-3 86.22, Top-5 90.99, Time 37.32
2019-05-18 17:20:14,991: INFO: [train_wsdan.py:220]: Epoch 007, Learning Rate 0.000344374
2019-05-18 17:26:16,686: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7959, Accuracy: (82.03, 93.38, 96.17), (Crop) Loss 1.1829, Accuracy: (69.58, 85.70, 90.16), (Drop) Loss 2.0417, Accuracy: (53.48, 71.06, 76.58), Time 3.53
2019-05-18 17:32:11,369: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7927, Accuracy: (81.78, 93.29, 96.05), (Crop) Loss 1.1589, Accuracy: (69.75, 85.60, 89.93), (Drop) Loss 2.0312, Accuracy: (53.62, 70.70, 76.38), Time 3.55
2019-05-18 17:32:49,354: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 17:32:50,535: INFO: [train_wsdan.py:483]: Valid: Loss 1.21691,  Accuracy: Top-1 67.67, Top-3 85.60, Top-5 90.11, Time 37.89
2019-05-18 17:38:38,553: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.7236, Accuracy: (83.69, 94.25, 96.62), (Crop) Loss 0.9878, Accuracy: (73.73, 88.11, 91.92), (Drop) Loss 2.1164, Accuracy: (52.44, 68.91, 74.40), Time 3.48
2019-05-18 17:44:26,816: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.6865, Accuracy: (84.70, 94.76, 96.94), (Crop) Loss 0.8992, Accuracy: (75.71, 89.32, 92.83), (Drop) Loss 2.1923, Accuracy: (50.97, 67.09, 72.95), Time 3.51
2019-05-18 17:45:04,796: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 17:45:05,996: INFO: [train_wsdan.py:483]: Valid: Loss 1.18886,  Accuracy: Top-1 69.46, Top-3 86.09, Top-5 90.86, Time 37.88
2019-05-18 17:50:53,653: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.6617, Accuracy: (85.40, 95.09, 97.16), (Crop) Loss 0.8394, Accuracy: (77.15, 90.14, 93.46), (Drop) Loss 2.2575, Accuracy: (49.98, 65.91, 71.76), Time 3.47
2019-05-18 17:56:41,445: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.6477, Accuracy: (85.77, 95.29, 97.29), (Crop) Loss 0.8046, Accuracy: (77.94, 90.62, 93.84), (Drop) Loss 2.2523, Accuracy: (49.91, 65.80, 71.78), Time 3.49
2019-05-18 17:57:18,986: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 17:57:20,206: INFO: [train_wsdan.py:483]: Valid: Loss 1.18985,  Accuracy: Top-1 69.49, Top-3 85.57, Top-5 90.73, Time 37.40
2019-05-18 18:03:08,555: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.6363, Accuracy: (86.06, 95.46, 97.40), (Crop) Loss 0.7806, Accuracy: (78.47, 90.98, 94.12), (Drop) Loss 2.2610, Accuracy: (49.68, 65.62, 71.58), Time 3.48
2019-05-18 18:08:56,768: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.6282, Accuracy: (86.35, 95.59, 97.47), (Crop) Loss 0.7598, Accuracy: (78.95, 91.27, 94.34), (Drop) Loss 2.2752, Accuracy: (49.41, 65.41, 71.37), Time 3.45
2019-05-18 18:09:34,730: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 18:09:35,901: INFO: [train_wsdan.py:483]: Valid: Loss 1.19519,  Accuracy: Top-1 68.94, Top-3 86.63, Top-5 91.28, Time 37.87
2019-05-18 18:15:24,022: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.6230, Accuracy: (86.46, 95.68, 97.53), (Crop) Loss 0.7477, Accuracy: (79.18, 91.46, 94.48), (Drop) Loss 2.2864, Accuracy: (49.23, 65.15, 71.13), Time 3.47
2019-05-18 18:21:12,249: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.6196, Accuracy: (86.54, 95.75, 97.57), (Crop) Loss 0.7366, Accuracy: (79.46, 91.65, 94.60), (Drop) Loss 2.2752, Accuracy: (49.39, 65.31, 71.29), Time 3.47
2019-05-18 18:21:12,250: INFO: [train_wsdan.py:334]: saving the latest model from epoch 7
2019-05-18 18:21:50,840: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 18:21:52,050: INFO: [train_wsdan.py:483]: Valid: Loss 1.19790,  Accuracy: Top-1 69.01, Top-3 85.96, Top-5 90.92, Time 37.25
2019-05-18 18:27:40,101: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.6155, Accuracy: (86.65, 95.81, 97.61), (Crop) Loss 0.7258, Accuracy: (79.68, 91.80, 94.69), (Drop) Loss 2.2674, Accuracy: (49.52, 65.40, 71.40), Time 3.46
2019-05-18 18:33:28,406: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.6118, Accuracy: (86.76, 95.88, 97.63), (Crop) Loss 0.7178, Accuracy: (79.86, 91.93, 94.79), (Drop) Loss 2.2700, Accuracy: (49.46, 65.29, 71.31), Time 3.54
2019-05-18 18:34:06,656: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 18:34:07,816: INFO: [train_wsdan.py:483]: Valid: Loss 1.18741,  Accuracy: Top-1 69.23, Top-3 86.06, Top-5 90.83, Time 38.16
2019-05-18 18:39:56,043: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.6094, Accuracy: (86.81, 95.92, 97.66), (Crop) Loss 0.7128, Accuracy: (79.99, 92.02, 94.84), (Drop) Loss 2.2451, Accuracy: (49.91, 65.73, 71.71), Time 3.47
2019-05-18 18:45:44,033: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.6075, Accuracy: (86.88, 95.95, 97.68), (Crop) Loss 0.7059, Accuracy: (80.13, 92.12, 94.92), (Drop) Loss 2.2334, Accuracy: (50.11, 65.94, 71.88), Time 3.47
2019-05-18 18:46:21,701: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 18:46:22,875: INFO: [train_wsdan.py:483]: Valid: Loss 1.19209,  Accuracy: Top-1 69.39, Top-3 85.86, Top-5 90.96, Time 37.57
2019-05-18 18:52:10,894: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.6061, Accuracy: (86.90, 95.97, 97.69), (Crop) Loss 0.7024, Accuracy: (80.20, 92.16, 94.96), (Drop) Loss 2.2185, Accuracy: (50.39, 66.18, 72.11), Time 3.50
2019-05-18 18:57:58,898: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.6038, Accuracy: (86.98, 95.99, 97.71), (Crop) Loss 0.6976, Accuracy: (80.32, 92.22, 95.02), (Drop) Loss 2.2105, Accuracy: (50.53, 66.35, 72.26), Time 3.47
2019-05-18 18:58:37,231: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 18:58:38,411: INFO: [train_wsdan.py:483]: Valid: Loss 1.18967,  Accuracy: Top-1 69.14, Top-3 86.18, Top-5 90.95, Time 38.24
2019-05-18 19:04:26,745: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.6012, Accuracy: (87.06, 96.03, 97.74), (Crop) Loss 0.6930, Accuracy: (80.45, 92.28, 95.08), (Drop) Loss 2.2073, Accuracy: (50.56, 66.38, 72.29), Time 3.51
2019-05-18 19:10:15,214: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.5996, Accuracy: (87.10, 96.06, 97.76), (Crop) Loss 0.6898, Accuracy: (80.56, 92.33, 95.12), (Drop) Loss 2.1974, Accuracy: (50.71, 66.55, 72.45), Time 3.47
2019-05-18 19:10:52,890: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 19:10:54,075: INFO: [train_wsdan.py:483]: Valid: Loss 1.18257,  Accuracy: Top-1 68.68, Top-3 86.37, Top-5 90.92, Time 37.57
2019-05-18 19:16:42,484: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.5981, Accuracy: (87.14, 96.10, 97.78), (Crop) Loss 0.6893, Accuracy: (80.57, 92.34, 95.12), (Drop) Loss 2.1949, Accuracy: (50.68, 66.60, 72.50), Time 3.51
2019-05-18 19:22:30,925: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.5977, Accuracy: (87.15, 96.11, 97.79), (Crop) Loss 0.6879, Accuracy: (80.63, 92.37, 95.14), (Drop) Loss 2.2032, Accuracy: (50.54, 66.44, 72.35), Time 3.48
2019-05-18 19:22:30,926: INFO: [train_wsdan.py:334]: saving the latest model from epoch 7
2019-05-18 19:23:10,272: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 19:23:11,449: INFO: [train_wsdan.py:483]: Valid: Loss 1.20651,  Accuracy: Top-1 68.23, Top-3 86.18, Top-5 91.12, Time 38.00
2019-05-18 19:28:59,471: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.5956, Accuracy: (87.22, 96.14, 97.80), (Crop) Loss 0.6848, Accuracy: (80.72, 92.41, 95.17), (Drop) Loss 2.2083, Accuracy: (50.46, 66.36, 72.27), Time 3.47
2019-05-18 19:34:48,273: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.5958, Accuracy: (87.22, 96.12, 97.80), (Crop) Loss 0.6842, Accuracy: (80.72, 92.40, 95.18), (Drop) Loss 2.2096, Accuracy: (50.43, 66.32, 72.25), Time 3.47
2019-05-18 19:35:26,014: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 19:35:27,176: INFO: [train_wsdan.py:483]: Valid: Loss 1.18736,  Accuracy: Top-1 69.44, Top-3 86.76, Top-5 91.09, Time 37.65
2019-05-18 19:41:15,261: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.5951, Accuracy: (87.24, 96.13, 97.81), (Crop) Loss 0.6829, Accuracy: (80.77, 92.44, 95.21), (Drop) Loss 2.2064, Accuracy: (50.50, 66.38, 72.30), Time 3.51
2019-05-18 19:47:03,949: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.5952, Accuracy: (87.22, 96.13, 97.81), (Crop) Loss 0.6828, Accuracy: (80.74, 92.46, 95.23), (Drop) Loss 2.1964, Accuracy: (50.67, 66.54, 72.46), Time 3.48
2019-05-18 19:47:41,682: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 19:47:42,852: INFO: [train_wsdan.py:483]: Valid: Loss 1.19792,  Accuracy: Top-1 68.88, Top-3 86.89, Top-5 91.22, Time 37.64
2019-05-18 19:53:32,056: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.5943, Accuracy: (87.25, 96.13, 97.81), (Crop) Loss 0.6808, Accuracy: (80.79, 92.48, 95.25), (Drop) Loss 2.1870, Accuracy: (50.81, 66.69, 72.61), Time 3.47
2019-05-18 19:59:21,203: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.5934, Accuracy: (87.28, 96.15, 97.82), (Crop) Loss 0.6794, Accuracy: (80.82, 92.50, 95.26), (Drop) Loss 2.1797, Accuracy: (50.94, 66.80, 72.72), Time 3.49
2019-05-18 19:59:59,186: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 20:00:00,349: INFO: [train_wsdan.py:483]: Valid: Loss 1.22317,  Accuracy: Top-1 69.56, Top-3 86.44, Top-5 91.06, Time 37.89
2019-05-18 20:05:50,026: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.5930, Accuracy: (87.29, 96.15, 97.83), (Crop) Loss 0.6784, Accuracy: (80.83, 92.51, 95.27), (Drop) Loss 2.1815, Accuracy: (50.93, 66.76, 72.68), Time 3.51
2019-05-18 20:11:38,988: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.5923, Accuracy: (87.31, 96.16, 97.83), (Crop) Loss 0.6769, Accuracy: (80.87, 92.52, 95.29), (Drop) Loss 2.1818, Accuracy: (50.92, 66.75, 72.67), Time 3.53
2019-05-18 20:12:17,580: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 20:12:18,738: INFO: [train_wsdan.py:483]: Valid: Loss 1.20248,  Accuracy: Top-1 69.34, Top-3 86.12, Top-5 90.44, Time 38.50
2019-05-18 20:18:07,286: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.5917, Accuracy: (87.32, 96.16, 97.83), (Crop) Loss 0.6761, Accuracy: (80.89, 92.53, 95.29), (Drop) Loss 2.1763, Accuracy: (51.01, 66.85, 72.77), Time 3.49
2019-05-18 20:23:55,738: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.5914, Accuracy: (87.33, 96.16, 97.84), (Crop) Loss 0.6749, Accuracy: (80.92, 92.55, 95.31), (Drop) Loss 2.1707, Accuracy: (51.12, 66.95, 72.86), Time 3.47
2019-05-18 20:23:55,758: INFO: [train_wsdan.py:334]: saving the latest model from epoch 7
2019-05-18 20:24:34,660: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 20:24:35,832: INFO: [train_wsdan.py:483]: Valid: Loss 1.15431,  Accuracy: Top-1 69.76, Top-3 86.34, Top-5 91.25, Time 37.60
2019-05-18 20:30:23,830: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.5915, Accuracy: (87.33, 96.16, 97.84), (Crop) Loss 0.6746, Accuracy: (80.93, 92.54, 95.31), (Drop) Loss 2.1612, Accuracy: (51.27, 67.12, 73.03), Time 3.52
2019-05-18 20:36:12,622: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.5909, Accuracy: (87.34, 96.17, 97.85), (Crop) Loss 0.6733, Accuracy: (80.98, 92.56, 95.31), (Drop) Loss 2.1540, Accuracy: (51.40, 67.24, 73.14), Time 3.51
2019-05-18 20:36:50,643: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 20:36:51,845: INFO: [train_wsdan.py:483]: Valid: Loss 1.17981,  Accuracy: Top-1 69.85, Top-3 86.28, Top-5 91.22, Time 37.93
2019-05-18 20:42:39,807: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.5902, Accuracy: (87.36, 96.17, 97.85), (Crop) Loss 0.6721, Accuracy: (80.99, 92.58, 95.33), (Drop) Loss 2.1504, Accuracy: (51.45, 67.29, 73.20), Time 3.48
2019-05-18 20:48:28,198: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.5902, Accuracy: (87.36, 96.17, 97.85), (Crop) Loss 0.6714, Accuracy: (81.01, 92.60, 95.33), (Drop) Loss 2.1471, Accuracy: (51.52, 67.35, 73.26), Time 3.47
2019-05-18 20:49:06,029: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 20:49:07,192: INFO: [train_wsdan.py:483]: Valid: Loss 1.16672,  Accuracy: Top-1 69.00, Top-3 86.22, Top-5 90.60, Time 37.73
2019-05-18 20:54:55,810: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.5900, Accuracy: (87.38, 96.18, 97.85), (Crop) Loss 0.6709, Accuracy: (81.04, 92.60, 95.34), (Drop) Loss 2.1442, Accuracy: (51.57, 67.39, 73.30), Time 3.50
2019-05-18 21:00:44,406: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.5901, Accuracy: (87.38, 96.17, 97.85), (Crop) Loss 0.6710, Accuracy: (81.05, 92.60, 95.34), (Drop) Loss 2.1366, Accuracy: (51.68, 67.52, 73.43), Time 3.47
2019-05-18 21:01:22,366: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 21:01:23,548: INFO: [train_wsdan.py:483]: Valid: Loss 1.19323,  Accuracy: Top-1 68.97, Top-3 86.12, Top-5 91.15, Time 37.87
2019-05-18 21:07:12,013: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.5894, Accuracy: (87.40, 96.19, 97.86), (Crop) Loss 0.6702, Accuracy: (81.06, 92.62, 95.34), (Drop) Loss 2.1312, Accuracy: (51.77, 67.62, 73.51), Time 3.52
2019-05-18 21:13:00,010: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.5891, Accuracy: (87.40, 96.19, 97.87), (Crop) Loss 0.6692, Accuracy: (81.08, 92.63, 95.36), (Drop) Loss 2.1266, Accuracy: (51.84, 67.68, 73.58), Time 3.48
2019-05-18 21:13:38,046: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 21:13:39,225: INFO: [train_wsdan.py:483]: Valid: Loss 1.18780,  Accuracy: Top-1 68.22, Top-3 85.73, Top-5 90.70, Time 37.94
2019-05-18 21:19:27,107: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.5889, Accuracy: (87.39, 96.19, 97.87), (Crop) Loss 0.6683, Accuracy: (81.10, 92.64, 95.37), (Drop) Loss 2.1305, Accuracy: (51.77, 67.61, 73.51), Time 3.50
2019-05-18 21:25:15,204: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.5883, Accuracy: (87.41, 96.20, 97.88), (Crop) Loss 0.6674, Accuracy: (81.12, 92.66, 95.38), (Drop) Loss 2.1287, Accuracy: (51.81, 67.63, 73.54), Time 3.48
2019-05-18 21:25:15,224: INFO: [train_wsdan.py:334]: saving the latest model from epoch 7
2019-05-18 21:25:54,324: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 21:25:55,533: INFO: [train_wsdan.py:483]: Valid: Loss 1.15295,  Accuracy: Top-1 69.07, Top-3 86.64, Top-5 90.93, Time 37.78
2019-05-18 21:31:44,159: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.5878, Accuracy: (87.44, 96.21, 97.88), (Crop) Loss 0.6668, Accuracy: (81.13, 92.67, 95.39), (Drop) Loss 2.1289, Accuracy: (51.83, 67.63, 73.54), Time 3.47
2019-05-18 21:34:17,492: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.5876, Accuracy: (87.45, 96.21, 97.88), (Crop) Loss 0.6661, Accuracy: (81.14, 92.68, 95.40), (Drop) Loss 2.1281, Accuracy: (51.83, 67.64, 73.55), Time 15242.50
2019-05-18 21:34:54,704: INFO: [train_wsdan.py:471]: saving the best model from epoch 7
2019-05-18 21:34:55,881: INFO: [train_wsdan.py:483]: Valid: Loss 1.16183,  Accuracy: Top-1 70.11, Top-3 86.51, Top-5 91.44, Time 37.11
2019-05-18 21:34:55,889: INFO: [train_wsdan.py:220]: Epoch 008, Learning Rate 0.000278943
2019-05-18 21:40:57,389: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7766, Accuracy: (82.53, 93.94, 96.45), (Crop) Loss 1.1455, Accuracy: (70.47, 86.08, 90.23), (Drop) Loss 1.9983, Accuracy: (55.23, 71.55, 77.28), Time 3.54
2019-05-18 21:46:52,138: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7687, Accuracy: (82.74, 93.73, 96.28), (Crop) Loss 1.1318, Accuracy: (70.55, 86.05, 90.26), (Drop) Loss 1.9859, Accuracy: (54.73, 71.48, 77.16), Time 3.55
2019-05-18 21:47:29,465: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 21:47:30,637: INFO: [train_wsdan.py:483]: Valid: Loss 1.20251,  Accuracy: Top-1 68.19, Top-3 85.08, Top-5 90.70, Time 37.23
2019-05-18 21:53:18,971: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.7000, Accuracy: (84.58, 94.69, 96.89), (Crop) Loss 0.9569, Accuracy: (74.57, 88.60, 92.25), (Drop) Loss 2.1219, Accuracy: (52.20, 68.59, 74.49), Time 3.50
2019-05-18 21:59:07,007: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.6542, Accuracy: (85.78, 95.38, 97.29), (Crop) Loss 0.8536, Accuracy: (76.93, 90.07, 93.39), (Drop) Loss 2.1858, Accuracy: (51.21, 67.29, 73.14), Time 3.47
2019-05-18 21:59:45,800: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 21:59:46,985: INFO: [train_wsdan.py:483]: Valid: Loss 1.16011,  Accuracy: Top-1 69.26, Top-3 86.02, Top-5 91.15, Time 38.70
2019-05-18 22:05:35,275: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.6289, Accuracy: (86.48, 95.74, 97.51), (Crop) Loss 0.7988, Accuracy: (78.26, 90.84, 93.94), (Drop) Loss 2.1996, Accuracy: (50.92, 66.82, 72.76), Time 3.47
2019-05-18 22:11:23,387: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.6094, Accuracy: (87.08, 95.97, 97.67), (Crop) Loss 0.7564, Accuracy: (79.23, 91.39, 94.33), (Drop) Loss 2.2164, Accuracy: (50.68, 66.51, 72.40), Time 3.49
2019-05-18 22:12:01,237: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 22:12:02,479: INFO: [train_wsdan.py:483]: Valid: Loss 1.17441,  Accuracy: Top-1 69.56, Top-3 85.82, Top-5 90.60, Time 37.74
2019-05-18 22:17:50,496: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5959, Accuracy: (87.49, 96.19, 97.80), (Crop) Loss 0.7273, Accuracy: (79.94, 91.84, 94.65), (Drop) Loss 2.2163, Accuracy: (50.75, 66.47, 72.27), Time 3.50
2019-05-18 22:23:38,742: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5867, Accuracy: (87.78, 96.32, 97.87), (Crop) Loss 0.7044, Accuracy: (80.45, 92.22, 94.94), (Drop) Loss 2.1934, Accuracy: (51.11, 66.81, 72.66), Time 3.46
2019-05-18 22:24:16,578: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 22:24:17,742: INFO: [train_wsdan.py:483]: Valid: Loss 1.19311,  Accuracy: Top-1 69.63, Top-3 85.92, Top-5 90.79, Time 37.74
2019-05-18 22:30:05,519: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.5811, Accuracy: (87.93, 96.38, 97.91), (Crop) Loss 0.6904, Accuracy: (80.75, 92.41, 95.09), (Drop) Loss 2.1764, Accuracy: (51.40, 67.05, 72.88), Time 3.49
2019-05-18 22:35:53,046: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.5779, Accuracy: (88.03, 96.44, 97.95), (Crop) Loss 0.6798, Accuracy: (81.06, 92.55, 95.18), (Drop) Loss 2.1854, Accuracy: (51.25, 66.86, 72.69), Time 3.51
2019-05-18 22:35:53,071: INFO: [train_wsdan.py:334]: saving the latest model from epoch 8
2019-05-18 22:36:31,657: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 22:36:32,821: INFO: [train_wsdan.py:483]: Valid: Loss 1.17847,  Accuracy: Top-1 69.95, Top-3 86.06, Top-5 90.99, Time 37.31
2019-05-18 22:42:21,053: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.5724, Accuracy: (88.16, 96.50, 97.98), (Crop) Loss 0.6681, Accuracy: (81.35, 92.72, 95.30), (Drop) Loss 2.1686, Accuracy: (51.58, 67.09, 72.90), Time 3.47
2019-05-18 22:48:09,668: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.5696, Accuracy: (88.25, 96.53, 98.00), (Crop) Loss 0.6594, Accuracy: (81.58, 92.84, 95.39), (Drop) Loss 2.1694, Accuracy: (51.61, 67.10, 72.88), Time 3.47
2019-05-18 22:48:47,354: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 22:48:48,588: INFO: [train_wsdan.py:483]: Valid: Loss 1.17257,  Accuracy: Top-1 69.82, Top-3 86.31, Top-5 91.05, Time 37.57
2019-05-18 22:54:37,512: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.5674, Accuracy: (88.28, 96.56, 98.03), (Crop) Loss 0.6532, Accuracy: (81.70, 92.92, 95.47), (Drop) Loss 2.1630, Accuracy: (51.72, 67.17, 72.94), Time 3.48
2019-05-18 23:00:25,928: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.5647, Accuracy: (88.34, 96.60, 98.08), (Crop) Loss 0.6474, Accuracy: (81.83, 93.00, 95.53), (Drop) Loss 2.1447, Accuracy: (52.04, 67.49, 73.23), Time 3.48
2019-05-18 23:01:03,718: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 23:01:06,548: INFO: [train_wsdan.py:483]: Valid: Loss 1.18854,  Accuracy: Top-1 70.18, Top-3 87.03, Top-5 91.48, Time 37.69
2019-05-18 23:06:54,969: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.5637, Accuracy: (88.40, 96.60, 98.07), (Crop) Loss 0.6440, Accuracy: (81.95, 93.03, 95.56), (Drop) Loss 2.1332, Accuracy: (52.23, 67.66, 73.40), Time 3.50
2019-05-18 23:12:43,105: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.5615, Accuracy: (88.46, 96.61, 98.08), (Crop) Loss 0.6392, Accuracy: (82.07, 93.09, 95.59), (Drop) Loss 2.1223, Accuracy: (52.43, 67.85, 73.57), Time 3.47
2019-05-18 23:13:21,064: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 23:13:22,248: INFO: [train_wsdan.py:483]: Valid: Loss 1.20006,  Accuracy: Top-1 69.95, Top-3 87.09, Top-5 91.80, Time 37.86
2019-05-18 23:19:10,428: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.5599, Accuracy: (88.52, 96.63, 98.09), (Crop) Loss 0.6350, Accuracy: (82.16, 93.15, 95.62), (Drop) Loss 2.1175, Accuracy: (52.51, 67.92, 73.66), Time 3.46
2019-05-18 23:24:58,388: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.5581, Accuracy: (88.58, 96.65, 98.11), (Crop) Loss 0.6313, Accuracy: (82.24, 93.20, 95.66), (Drop) Loss 2.1133, Accuracy: (52.58, 67.95, 73.72), Time 3.47
2019-05-18 23:25:36,730: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 23:25:37,902: INFO: [train_wsdan.py:483]: Valid: Loss 1.19161,  Accuracy: Top-1 69.36, Top-3 85.99, Top-5 91.22, Time 38.25
2019-05-18 23:31:26,060: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.5578, Accuracy: (88.59, 96.64, 98.11), (Crop) Loss 0.6294, Accuracy: (82.29, 93.24, 95.69), (Drop) Loss 2.1072, Accuracy: (52.69, 68.05, 73.83), Time 3.48
2019-05-18 23:37:14,146: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.5570, Accuracy: (88.59, 96.66, 98.13), (Crop) Loss 0.6284, Accuracy: (82.31, 93.24, 95.69), (Drop) Loss 2.1036, Accuracy: (52.73, 68.12, 73.89), Time 3.49
2019-05-18 23:37:14,147: INFO: [train_wsdan.py:334]: saving the latest model from epoch 8
2019-05-18 23:37:53,593: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 23:37:54,753: INFO: [train_wsdan.py:483]: Valid: Loss 1.17144,  Accuracy: Top-1 70.34, Top-3 87.06, Top-5 91.51, Time 38.07
2019-05-18 23:43:42,694: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.5566, Accuracy: (88.59, 96.66, 98.12), (Crop) Loss 0.6263, Accuracy: (82.36, 93.28, 95.72), (Drop) Loss 2.0968, Accuracy: (52.85, 68.24, 73.99), Time 3.47
2019-05-18 23:49:30,851: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.5548, Accuracy: (88.62, 96.69, 98.14), (Crop) Loss 0.6232, Accuracy: (82.42, 93.32, 95.76), (Drop) Loss 2.0946, Accuracy: (52.86, 68.28, 74.04), Time 3.51
2019-05-18 23:50:09,003: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-18 23:50:10,171: INFO: [train_wsdan.py:483]: Valid: Loss 1.16392,  Accuracy: Top-1 69.88, Top-3 86.54, Top-5 91.22, Time 38.04
2019-05-18 23:55:58,153: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.5548, Accuracy: (88.63, 96.69, 98.14), (Crop) Loss 0.6220, Accuracy: (82.46, 93.36, 95.78), (Drop) Loss 2.0881, Accuracy: (52.97, 68.40, 74.15), Time 3.46
2019-05-19 00:01:46,055: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.5538, Accuracy: (88.66, 96.70, 98.15), (Crop) Loss 0.6202, Accuracy: (82.51, 93.39, 95.79), (Drop) Loss 2.0788, Accuracy: (53.13, 68.55, 74.30), Time 3.47
2019-05-19 00:02:23,794: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 00:02:24,962: INFO: [train_wsdan.py:483]: Valid: Loss 1.18546,  Accuracy: Top-1 69.27, Top-3 86.57, Top-5 91.48, Time 37.64
2019-05-19 00:08:12,710: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.5536, Accuracy: (88.68, 96.72, 98.16), (Crop) Loss 0.6187, Accuracy: (82.53, 93.41, 95.80), (Drop) Loss 2.0766, Accuracy: (53.15, 68.58, 74.34), Time 3.49
2019-05-19 00:14:00,270: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.5529, Accuracy: (88.71, 96.72, 98.17), (Crop) Loss 0.6164, Accuracy: (82.58, 93.44, 95.84), (Drop) Loss 2.0746, Accuracy: (53.17, 68.61, 74.37), Time 3.47
2019-05-19 00:14:38,082: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 00:14:39,252: INFO: [train_wsdan.py:483]: Valid: Loss 1.16841,  Accuracy: Top-1 70.44, Top-3 86.99, Top-5 91.35, Time 37.72
2019-05-19 00:20:27,128: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.5520, Accuracy: (88.74, 96.74, 98.18), (Crop) Loss 0.6143, Accuracy: (82.63, 93.48, 95.86), (Drop) Loss 2.0768, Accuracy: (53.13, 68.56, 74.32), Time 3.49
2019-05-19 00:26:14,662: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.5517, Accuracy: (88.74, 96.74, 98.19), (Crop) Loss 0.6133, Accuracy: (82.63, 93.50, 95.88), (Drop) Loss 2.0763, Accuracy: (53.11, 68.56, 74.33), Time 3.47
2019-05-19 00:26:53,103: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 00:26:54,277: INFO: [train_wsdan.py:483]: Valid: Loss 1.17409,  Accuracy: Top-1 70.44, Top-3 86.73, Top-5 91.22, Time 38.35
2019-05-19 00:32:42,261: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.5510, Accuracy: (88.75, 96.75, 98.19), (Crop) Loss 0.6117, Accuracy: (82.68, 93.53, 95.89), (Drop) Loss 2.0785, Accuracy: (53.09, 68.51, 74.29), Time 3.47
2019-05-19 00:38:30,255: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.5510, Accuracy: (88.77, 96.75, 98.19), (Crop) Loss 0.6106, Accuracy: (82.71, 93.54, 95.91), (Drop) Loss 2.0776, Accuracy: (53.11, 68.52, 74.29), Time 3.49
2019-05-19 00:38:30,256: INFO: [train_wsdan.py:334]: saving the latest model from epoch 8
2019-05-19 00:39:09,405: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 00:39:10,586: INFO: [train_wsdan.py:483]: Valid: Loss 1.15498,  Accuracy: Top-1 70.50, Top-3 87.03, Top-5 91.31, Time 37.79
2019-05-19 00:44:58,548: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.5510, Accuracy: (88.77, 96.75, 98.19), (Crop) Loss 0.6097, Accuracy: (82.73, 93.55, 95.91), (Drop) Loss 2.0759, Accuracy: (53.14, 68.56, 74.32), Time 3.48
2019-05-19 00:50:46,719: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.5506, Accuracy: (88.77, 96.75, 98.20), (Crop) Loss 0.6089, Accuracy: (82.75, 93.57, 95.92), (Drop) Loss 2.0713, Accuracy: (53.21, 68.63, 74.38), Time 3.49
2019-05-19 00:51:24,856: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 00:51:26,087: INFO: [train_wsdan.py:483]: Valid: Loss 1.16209,  Accuracy: Top-1 70.18, Top-3 86.34, Top-5 91.44, Time 38.04
2019-05-19 00:57:14,297: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.5501, Accuracy: (88.77, 96.76, 98.20), (Crop) Loss 0.6078, Accuracy: (82.75, 93.57, 95.93), (Drop) Loss 2.0686, Accuracy: (53.25, 68.68, 74.44), Time 3.52
2019-05-19 01:03:02,468: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.5497, Accuracy: (88.79, 96.76, 98.20), (Crop) Loss 0.6079, Accuracy: (82.75, 93.56, 95.93), (Drop) Loss 2.0607, Accuracy: (53.39, 68.83, 74.57), Time 3.52
2019-05-19 01:03:40,550: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 01:03:41,725: INFO: [train_wsdan.py:483]: Valid: Loss 1.13794,  Accuracy: Top-1 70.34, Top-3 87.52, Top-5 91.58, Time 37.93
2019-05-19 01:09:30,252: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.5494, Accuracy: (88.81, 96.76, 98.20), (Crop) Loss 0.6071, Accuracy: (82.77, 93.58, 95.94), (Drop) Loss 2.0520, Accuracy: (53.54, 68.99, 74.71), Time 3.48
2019-05-19 01:15:18,832: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.5493, Accuracy: (88.81, 96.77, 98.20), (Crop) Loss 0.6063, Accuracy: (82.79, 93.59, 95.95), (Drop) Loss 2.0443, Accuracy: (53.67, 69.14, 74.85), Time 3.47
2019-05-19 01:15:56,819: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 01:15:57,996: INFO: [train_wsdan.py:483]: Valid: Loss 1.18345,  Accuracy: Top-1 69.43, Top-3 86.80, Top-5 91.31, Time 37.89
2019-05-19 01:21:46,704: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.5488, Accuracy: (88.82, 96.78, 98.21), (Crop) Loss 0.6053, Accuracy: (82.81, 93.60, 95.96), (Drop) Loss 2.0458, Accuracy: (53.65, 69.12, 74.83), Time 3.48
2019-05-19 01:27:35,446: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.5487, Accuracy: (88.84, 96.78, 98.20), (Crop) Loss 0.6046, Accuracy: (82.83, 93.60, 95.96), (Drop) Loss 2.0421, Accuracy: (53.73, 69.18, 74.88), Time 3.50
2019-05-19 01:28:13,436: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 01:28:14,664: INFO: [train_wsdan.py:483]: Valid: Loss 1.18025,  Accuracy: Top-1 70.04, Top-3 86.67, Top-5 91.31, Time 37.89
2019-05-19 01:34:02,846: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.5483, Accuracy: (88.85, 96.79, 98.21), (Crop) Loss 0.6042, Accuracy: (82.83, 93.61, 95.96), (Drop) Loss 2.0389, Accuracy: (53.78, 69.23, 74.94), Time 3.48
2019-05-19 01:39:50,909: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.5479, Accuracy: (88.87, 96.79, 98.21), (Crop) Loss 0.6034, Accuracy: (82.85, 93.62, 95.97), (Drop) Loss 2.0397, Accuracy: (53.76, 69.22, 74.92), Time 3.49
2019-05-19 01:39:50,909: INFO: [train_wsdan.py:334]: saving the latest model from epoch 8
2019-05-19 01:40:30,763: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 01:40:31,928: INFO: [train_wsdan.py:483]: Valid: Loss 1.19299,  Accuracy: Top-1 69.40, Top-3 86.02, Top-5 90.80, Time 38.56
2019-05-19 01:46:19,657: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.5475, Accuracy: (88.88, 96.79, 98.21), (Crop) Loss 0.6028, Accuracy: (82.87, 93.63, 95.98), (Drop) Loss 2.0384, Accuracy: (53.79, 69.25, 74.95), Time 3.48
2019-05-19 01:48:52,662: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.5472, Accuracy: (88.89, 96.80, 98.21), (Crop) Loss 0.6022, Accuracy: (82.89, 93.64, 95.99), (Drop) Loss 2.0361, Accuracy: (53.82, 69.28, 74.99), Time 15236.77
2019-05-19 01:49:29,907: INFO: [train_wsdan.py:471]: saving the best model from epoch 8
2019-05-19 01:49:31,096: INFO: [train_wsdan.py:483]: Valid: Loss 1.17674,  Accuracy: Top-1 69.82, Top-3 86.67, Top-5 90.83, Time 37.14
2019-05-19 01:49:31,105: INFO: [train_wsdan.py:220]: Epoch 009, Learning Rate 0.000225944
2019-05-19 01:55:32,355: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7726, Accuracy: (82.64, 93.62, 96.31), (Crop) Loss 1.1358, Accuracy: (70.34, 86.47, 90.47), (Drop) Loss 2.0131, Accuracy: (54.64, 71.11, 76.86), Time 3.54
2019-05-19 02:01:26,982: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7510, Accuracy: (83.17, 93.98, 96.45), (Crop) Loss 1.1103, Accuracy: (70.89, 86.55, 90.81), (Drop) Loss 1.9627, Accuracy: (54.92, 71.69, 77.62), Time 3.56
2019-05-19 02:02:05,728: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 02:02:06,896: INFO: [train_wsdan.py:483]: Valid: Loss 1.18325,  Accuracy: Top-1 68.45, Top-3 85.24, Top-5 90.73, Time 38.65
2019-05-19 02:07:54,849: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6731, Accuracy: (85.40, 94.95, 97.02), (Crop) Loss 0.9222, Accuracy: (75.32, 89.16, 92.79), (Drop) Loss 2.0343, Accuracy: (53.71, 70.01, 76.02), Time 3.46
2019-05-19 02:13:42,537: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.6274, Accuracy: (86.68, 95.57, 97.42), (Crop) Loss 0.8149, Accuracy: (77.93, 90.65, 93.84), (Drop) Loss 2.0987, Accuracy: (52.55, 68.70, 74.69), Time 3.44
2019-05-19 02:14:20,796: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 02:14:21,981: INFO: [train_wsdan.py:483]: Valid: Loss 1.16841,  Accuracy: Top-1 69.88, Top-3 86.57, Top-5 91.42, Time 38.14
2019-05-19 02:20:10,045: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.6012, Accuracy: (87.57, 95.97, 97.63), (Crop) Loss 0.7518, Accuracy: (79.50, 91.53, 94.48), (Drop) Loss 2.1298, Accuracy: (52.21, 68.06, 73.95), Time 3.51
2019-05-19 02:25:58,371: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5824, Accuracy: (88.07, 96.24, 97.84), (Crop) Loss 0.7091, Accuracy: (80.49, 92.13, 94.93), (Drop) Loss 2.0970, Accuracy: (52.80, 68.51, 74.34), Time 3.48
2019-05-19 02:26:36,675: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 02:26:37,859: INFO: [train_wsdan.py:483]: Valid: Loss 1.18307,  Accuracy: Top-1 70.43, Top-3 87.03, Top-5 91.57, Time 38.21
2019-05-19 02:32:26,344: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5708, Accuracy: (88.43, 96.40, 97.96), (Crop) Loss 0.6828, Accuracy: (81.13, 92.49, 95.17), (Drop) Loss 2.0942, Accuracy: (52.88, 68.47, 74.35), Time 3.48
2019-05-19 02:38:15,004: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5600, Accuracy: (88.75, 96.59, 98.05), (Crop) Loss 0.6610, Accuracy: (81.65, 92.78, 95.37), (Drop) Loss 2.0705, Accuracy: (53.31, 68.86, 74.71), Time 3.56
2019-05-19 02:38:52,699: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 02:38:53,861: INFO: [train_wsdan.py:483]: Valid: Loss 1.18279,  Accuracy: Top-1 69.36, Top-3 86.96, Top-5 91.31, Time 37.60
2019-05-19 02:44:41,873: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.5535, Accuracy: (88.95, 96.68, 98.13), (Crop) Loss 0.6434, Accuracy: (82.09, 93.02, 95.56), (Drop) Loss 2.0631, Accuracy: (53.44, 68.88, 74.69), Time 3.45
2019-05-19 02:50:30,091: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.5476, Accuracy: (89.12, 96.76, 98.17), (Crop) Loss 0.6297, Accuracy: (82.38, 93.21, 95.68), (Drop) Loss 2.0594, Accuracy: (53.46, 68.94, 74.75), Time 3.47
2019-05-19 02:50:30,091: INFO: [train_wsdan.py:334]: saving the latest model from epoch 9
2019-05-19 02:51:09,408: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 02:51:10,564: INFO: [train_wsdan.py:483]: Valid: Loss 1.16819,  Accuracy: Top-1 69.40, Top-3 86.74, Top-5 91.12, Time 37.98
2019-05-19 02:56:59,142: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.5429, Accuracy: (89.27, 96.83, 98.22), (Crop) Loss 0.6186, Accuracy: (82.63, 93.38, 95.78), (Drop) Loss 2.0495, Accuracy: (53.63, 69.07, 74.85), Time 3.48
2019-05-19 03:02:46,898: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.5393, Accuracy: (89.36, 96.88, 98.25), (Crop) Loss 0.6097, Accuracy: (82.86, 93.51, 95.88), (Drop) Loss 2.0427, Accuracy: (53.77, 69.21, 74.94), Time 3.48
2019-05-19 03:03:25,151: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 03:03:26,328: INFO: [train_wsdan.py:483]: Valid: Loss 1.21076,  Accuracy: Top-1 69.63, Top-3 86.58, Top-5 91.38, Time 38.16
2019-05-19 03:09:14,524: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.5364, Accuracy: (89.45, 96.93, 98.29), (Crop) Loss 0.6017, Accuracy: (83.04, 93.61, 95.94), (Drop) Loss 2.0418, Accuracy: (53.75, 69.22, 74.95), Time 3.48
2019-05-19 03:15:02,507: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.5340, Accuracy: (89.48, 96.95, 98.31), (Crop) Loss 0.5957, Accuracy: (83.20, 93.70, 95.99), (Drop) Loss 2.0378, Accuracy: (53.83, 69.30, 75.02), Time 3.48
2019-05-19 03:15:41,151: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 03:15:42,314: INFO: [train_wsdan.py:483]: Valid: Loss 1.16545,  Accuracy: Top-1 70.51, Top-3 86.61, Top-5 91.73, Time 38.47
2019-05-19 03:21:30,750: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.5320, Accuracy: (89.54, 96.98, 98.33), (Crop) Loss 0.5898, Accuracy: (83.34, 93.79, 96.06), (Drop) Loss 2.0290, Accuracy: (53.99, 69.43, 75.13), Time 3.50
2019-05-19 03:27:19,567: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.5299, Accuracy: (89.62, 97.02, 98.37), (Crop) Loss 0.5841, Accuracy: (83.46, 93.87, 96.13), (Drop) Loss 2.0185, Accuracy: (54.16, 69.64, 75.32), Time 3.50
2019-05-19 03:27:58,082: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 03:27:59,243: INFO: [train_wsdan.py:483]: Valid: Loss 1.18404,  Accuracy: Top-1 70.18, Top-3 86.22, Top-5 90.83, Time 38.42
2019-05-19 03:33:47,118: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.5279, Accuracy: (89.69, 97.06, 98.39), (Crop) Loss 0.5793, Accuracy: (83.58, 93.94, 96.18), (Drop) Loss 2.0015, Accuracy: (54.49, 69.93, 75.58), Time 3.47
2019-05-19 03:39:34,449: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.5262, Accuracy: (89.75, 97.09, 98.40), (Crop) Loss 0.5751, Accuracy: (83.65, 93.98, 96.21), (Drop) Loss 1.9912, Accuracy: (54.69, 70.12, 75.74), Time 3.47
2019-05-19 03:40:12,584: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 03:40:13,784: INFO: [train_wsdan.py:483]: Valid: Loss 1.19078,  Accuracy: Top-1 70.21, Top-3 86.73, Top-5 91.38, Time 38.04
2019-05-19 03:46:01,404: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.5255, Accuracy: (89.77, 97.09, 98.42), (Crop) Loss 0.5726, Accuracy: (83.70, 94.02, 96.24), (Drop) Loss 1.9812, Accuracy: (54.90, 70.27, 75.88), Time 3.48
2019-05-19 03:51:49,383: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.5239, Accuracy: (89.81, 97.12, 98.43), (Crop) Loss 0.5697, Accuracy: (83.77, 94.05, 96.26), (Drop) Loss 1.9716, Accuracy: (55.11, 70.46, 76.02), Time 3.52
2019-05-19 03:51:49,384: INFO: [train_wsdan.py:334]: saving the latest model from epoch 9
2019-05-19 03:52:27,867: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 03:52:29,043: INFO: [train_wsdan.py:483]: Valid: Loss 1.18746,  Accuracy: Top-1 70.50, Top-3 86.64, Top-5 91.18, Time 37.17
2019-05-19 03:58:17,293: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.5226, Accuracy: (89.84, 97.14, 98.44), (Crop) Loss 0.5678, Accuracy: (83.81, 94.09, 96.29), (Drop) Loss 1.9597, Accuracy: (55.33, 70.65, 76.21), Time 3.48
2019-05-19 04:04:05,661: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.5217, Accuracy: (89.88, 97.14, 98.45), (Crop) Loss 0.5660, Accuracy: (83.87, 94.11, 96.30), (Drop) Loss 1.9507, Accuracy: (55.50, 70.82, 76.35), Time 3.47
2019-05-19 04:04:43,476: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 04:04:44,654: INFO: [train_wsdan.py:483]: Valid: Loss 1.17132,  Accuracy: Top-1 70.18, Top-3 86.34, Top-5 91.41, Time 37.72
2019-05-19 04:10:32,851: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.5206, Accuracy: (89.91, 97.16, 98.46), (Crop) Loss 0.5639, Accuracy: (83.90, 94.14, 96.32), (Drop) Loss 1.9439, Accuracy: (55.64, 70.96, 76.46), Time 3.47
2019-05-19 04:16:21,264: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.5198, Accuracy: (89.93, 97.17, 98.47), (Crop) Loss 0.5618, Accuracy: (83.95, 94.17, 96.34), (Drop) Loss 1.9358, Accuracy: (55.79, 71.06, 76.56), Time 3.53
2019-05-19 04:16:58,803: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 04:17:00,008: INFO: [train_wsdan.py:483]: Valid: Loss 1.16443,  Accuracy: Top-1 70.01, Top-3 86.45, Top-5 91.31, Time 37.45
2019-05-19 04:22:48,285: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.5191, Accuracy: (89.97, 97.19, 98.47), (Crop) Loss 0.5593, Accuracy: (84.01, 94.21, 96.37), (Drop) Loss 1.9295, Accuracy: (55.93, 71.19, 76.65), Time 3.47
2019-05-19 04:28:36,557: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.5189, Accuracy: (89.98, 97.19, 98.49), (Crop) Loss 0.5586, Accuracy: (84.02, 94.22, 96.38), (Drop) Loss 1.9267, Accuracy: (55.98, 71.22, 76.69), Time 3.49
2019-05-19 04:29:13,965: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 04:29:17,078: INFO: [train_wsdan.py:483]: Valid: Loss 1.17237,  Accuracy: Top-1 70.96, Top-3 87.32, Top-5 91.87, Time 37.27
2019-05-19 04:35:05,481: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.5182, Accuracy: (89.99, 97.19, 98.49), (Crop) Loss 0.5568, Accuracy: (84.07, 94.25, 96.40), (Drop) Loss 1.9216, Accuracy: (56.05, 71.30, 76.77), Time 3.48
2019-05-19 04:40:53,335: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.5177, Accuracy: (89.99, 97.20, 98.49), (Crop) Loss 0.5547, Accuracy: (84.13, 94.27, 96.42), (Drop) Loss 1.9215, Accuracy: (56.08, 71.29, 76.75), Time 3.51
2019-05-19 04:41:30,996: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 04:41:32,240: INFO: [train_wsdan.py:483]: Valid: Loss 1.16771,  Accuracy: Top-1 70.86, Top-3 86.77, Top-5 91.61, Time 37.57
2019-05-19 04:47:20,377: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.5173, Accuracy: (90.00, 97.20, 98.50), (Crop) Loss 0.5534, Accuracy: (84.17, 94.28, 96.43), (Drop) Loss 1.9253, Accuracy: (56.00, 71.19, 76.68), Time 3.56
2019-05-19 04:53:08,978: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.5169, Accuracy: (90.01, 97.22, 98.50), (Crop) Loss 0.5527, Accuracy: (84.18, 94.30, 96.44), (Drop) Loss 1.9281, Accuracy: (55.97, 71.14, 76.62), Time 3.48
2019-05-19 04:53:08,978: INFO: [train_wsdan.py:334]: saving the latest model from epoch 9
2019-05-19 04:53:47,617: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 04:53:48,770: INFO: [train_wsdan.py:483]: Valid: Loss 1.19173,  Accuracy: Top-1 69.59, Top-3 86.77, Top-5 91.38, Time 37.28
2019-05-19 04:59:36,872: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.5172, Accuracy: (90.01, 97.21, 98.50), (Crop) Loss 0.5525, Accuracy: (84.19, 94.30, 96.45), (Drop) Loss 1.9313, Accuracy: (55.91, 71.08, 76.56), Time 3.48
2019-05-19 05:05:25,116: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.5169, Accuracy: (90.02, 97.21, 98.50), (Crop) Loss 0.5513, Accuracy: (84.22, 94.31, 96.46), (Drop) Loss 1.9325, Accuracy: (55.90, 71.06, 76.53), Time 3.51
2019-05-19 05:06:02,623: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 05:06:03,794: INFO: [train_wsdan.py:483]: Valid: Loss 1.15025,  Accuracy: Top-1 70.60, Top-3 87.32, Top-5 91.71, Time 37.41
2019-05-19 05:11:51,600: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.5159, Accuracy: (90.05, 97.23, 98.51), (Crop) Loss 0.5487, Accuracy: (84.27, 94.34, 96.49), (Drop) Loss 1.9334, Accuracy: (55.89, 71.03, 76.51), Time 3.51
2019-05-19 05:17:39,630: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.5157, Accuracy: (90.07, 97.22, 98.51), (Crop) Loss 0.5481, Accuracy: (84.30, 94.34, 96.49), (Drop) Loss 1.9331, Accuracy: (55.91, 71.03, 76.50), Time 3.46
2019-05-19 05:18:17,957: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 05:18:19,139: INFO: [train_wsdan.py:483]: Valid: Loss 1.16468,  Accuracy: Top-1 70.01, Top-3 86.86, Top-5 91.77, Time 38.23
2019-05-19 05:24:06,816: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.5157, Accuracy: (90.08, 97.22, 98.51), (Crop) Loss 0.5475, Accuracy: (84.32, 94.35, 96.50), (Drop) Loss 1.9288, Accuracy: (56.00, 71.10, 76.55), Time 3.48
2019-05-19 05:29:54,497: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.5155, Accuracy: (90.08, 97.21, 98.51), (Crop) Loss 0.5470, Accuracy: (84.33, 94.36, 96.51), (Drop) Loss 1.9232, Accuracy: (56.11, 71.20, 76.64), Time 3.48
2019-05-19 05:30:32,436: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 05:30:33,597: INFO: [train_wsdan.py:483]: Valid: Loss 1.16534,  Accuracy: Top-1 70.31, Top-3 86.60, Top-5 91.35, Time 37.84
2019-05-19 05:36:21,454: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.5149, Accuracy: (90.11, 97.22, 98.52), (Crop) Loss 0.5462, Accuracy: (84.35, 94.37, 96.52), (Drop) Loss 1.9192, Accuracy: (56.19, 71.27, 76.70), Time 3.50
2019-05-19 05:42:09,226: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.5146, Accuracy: (90.11, 97.23, 98.52), (Crop) Loss 0.5458, Accuracy: (84.37, 94.38, 96.52), (Drop) Loss 1.9168, Accuracy: (56.22, 71.31, 76.74), Time 3.46
2019-05-19 05:42:47,187: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 05:42:48,385: INFO: [train_wsdan.py:483]: Valid: Loss 1.17699,  Accuracy: Top-1 69.73, Top-3 86.60, Top-5 91.77, Time 37.80
2019-05-19 05:48:36,419: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.5145, Accuracy: (90.10, 97.24, 98.53), (Crop) Loss 0.5455, Accuracy: (84.38, 94.39, 96.53), (Drop) Loss 1.9137, Accuracy: (56.27, 71.35, 76.78), Time 3.47
2019-05-19 05:54:25,174: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.5143, Accuracy: (90.11, 97.23, 98.52), (Crop) Loss 0.5448, Accuracy: (84.40, 94.38, 96.53), (Drop) Loss 1.9159, Accuracy: (56.24, 71.30, 76.74), Time 3.48
2019-05-19 05:54:25,175: INFO: [train_wsdan.py:334]: saving the latest model from epoch 9
2019-05-19 05:55:03,883: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 05:55:05,055: INFO: [train_wsdan.py:483]: Valid: Loss 1.16795,  Accuracy: Top-1 70.37, Top-3 86.80, Top-5 91.38, Time 37.36
2019-05-19 06:00:53,250: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.5140, Accuracy: (90.12, 97.23, 98.52), (Crop) Loss 0.5439, Accuracy: (84.42, 94.40, 96.54), (Drop) Loss 1.9191, Accuracy: (56.20, 71.26, 76.69), Time 3.48
2019-05-19 06:03:26,433: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.5139, Accuracy: (90.13, 97.24, 98.52), (Crop) Loss 0.5441, Accuracy: (84.41, 94.39, 96.54), (Drop) Loss 1.9193, Accuracy: (56.19, 71.26, 76.68), Time 15235.33
2019-05-19 06:04:04,348: INFO: [train_wsdan.py:471]: saving the best model from epoch 9
2019-05-19 06:04:05,574: INFO: [train_wsdan.py:483]: Valid: Loss 1.15039,  Accuracy: Top-1 70.34, Top-3 86.90, Top-5 91.15, Time 37.81
2019-05-19 06:04:05,582: INFO: [train_wsdan.py:220]: Epoch 010, Learning Rate 0.000183014
2019-05-19 06:10:06,105: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7430, Accuracy: (83.47, 94.33, 96.84), (Crop) Loss 1.1323, Accuracy: (70.38, 86.20, 90.77), (Drop) Loss 2.0170, Accuracy: (54.80, 71.38, 76.95), Time 3.55
2019-05-19 06:16:00,634: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7381, Accuracy: (83.47, 94.23, 96.62), (Crop) Loss 1.1101, Accuracy: (71.11, 86.29, 90.73), (Drop) Loss 1.9555, Accuracy: (55.37, 72.26, 77.81), Time 3.53
2019-05-19 06:16:39,074: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 06:16:40,236: INFO: [train_wsdan.py:483]: Valid: Loss 1.19568,  Accuracy: Top-1 68.45, Top-3 85.47, Top-5 90.54, Time 38.34
2019-05-19 06:22:27,731: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6579, Accuracy: (85.67, 95.31, 97.28), (Crop) Loss 0.9135, Accuracy: (75.59, 89.17, 92.82), (Drop) Loss 1.9303, Accuracy: (55.96, 72.22, 77.56), Time 3.47
2019-05-19 06:28:15,227: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.6124, Accuracy: (87.13, 95.95, 97.66), (Crop) Loss 0.8035, Accuracy: (78.30, 90.77, 93.96), (Drop) Loss 1.9515, Accuracy: (55.61, 71.58, 76.95), Time 3.48
2019-05-19 06:28:52,922: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 06:28:54,102: INFO: [train_wsdan.py:483]: Valid: Loss 1.18342,  Accuracy: Top-1 71.12, Top-3 87.12, Top-5 91.38, Time 37.60
2019-05-19 06:34:41,456: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.5822, Accuracy: (88.12, 96.41, 97.93), (Crop) Loss 0.7348, Accuracy: (79.87, 91.74, 94.61), (Drop) Loss 1.9614, Accuracy: (55.44, 71.30, 76.61), Time 3.47
2019-05-19 06:40:28,904: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5639, Accuracy: (88.67, 96.67, 98.09), (Crop) Loss 0.6875, Accuracy: (81.06, 92.38, 95.05), (Drop) Loss 1.9543, Accuracy: (55.59, 71.26, 76.60), Time 3.47
2019-05-19 06:41:06,783: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 06:41:08,015: INFO: [train_wsdan.py:483]: Valid: Loss 1.18061,  Accuracy: Top-1 70.37, Top-3 86.80, Top-5 91.55, Time 37.78
2019-05-19 06:46:55,978: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5480, Accuracy: (89.14, 96.86, 98.23), (Crop) Loss 0.6508, Accuracy: (82.01, 92.87, 95.42), (Drop) Loss 1.9315, Accuracy: (55.95, 71.57, 76.92), Time 3.47
2019-05-19 06:52:43,691: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5378, Accuracy: (89.48, 97.01, 98.31), (Crop) Loss 0.6260, Accuracy: (82.62, 93.22, 95.65), (Drop) Loss 1.9256, Accuracy: (55.99, 71.57, 77.03), Time 3.47
2019-05-19 06:53:21,705: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 06:53:22,906: INFO: [train_wsdan.py:483]: Valid: Loss 1.19477,  Accuracy: Top-1 69.63, Top-3 86.70, Top-5 91.61, Time 37.87
2019-05-19 06:59:10,938: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.5282, Accuracy: (89.82, 97.14, 98.37), (Crop) Loss 0.6053, Accuracy: (83.11, 93.50, 95.86), (Drop) Loss 1.9134, Accuracy: (56.31, 71.76, 77.11), Time 3.48
2019-05-19 07:04:58,978: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.5213, Accuracy: (90.04, 97.21, 98.42), (Crop) Loss 0.5888, Accuracy: (83.52, 93.72, 96.02), (Drop) Loss 1.9125, Accuracy: (56.37, 71.74, 77.06), Time 3.47
2019-05-19 07:04:58,979: INFO: [train_wsdan.py:334]: saving the latest model from epoch 10
2019-05-19 07:05:37,738: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 07:05:38,966: INFO: [train_wsdan.py:483]: Valid: Loss 1.18237,  Accuracy: Top-1 70.34, Top-3 87.25, Top-5 91.38, Time 37.40
2019-05-19 07:11:26,965: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.5170, Accuracy: (90.17, 97.28, 98.46), (Crop) Loss 0.5774, Accuracy: (83.81, 93.85, 96.12), (Drop) Loss 1.9126, Accuracy: (56.38, 71.68, 77.00), Time 3.50
2019-05-19 07:17:14,475: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.5142, Accuracy: (90.26, 97.31, 98.49), (Crop) Loss 0.5691, Accuracy: (84.05, 93.93, 96.17), (Drop) Loss 1.9196, Accuracy: (56.32, 71.54, 76.85), Time 3.48
2019-05-19 07:17:51,970: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 07:17:53,201: INFO: [train_wsdan.py:483]: Valid: Loss 1.20845,  Accuracy: Top-1 69.75, Top-3 86.77, Top-5 91.15, Time 37.39
2019-05-19 07:23:40,762: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.5118, Accuracy: (90.34, 97.33, 98.52), (Crop) Loss 0.5623, Accuracy: (84.22, 94.01, 96.27), (Drop) Loss 1.9165, Accuracy: (56.36, 71.57, 76.91), Time 3.48
2019-05-19 07:29:28,503: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.5101, Accuracy: (90.37, 97.34, 98.53), (Crop) Loss 0.5558, Accuracy: (84.36, 94.09, 96.33), (Drop) Loss 1.9195, Accuracy: (56.30, 71.46, 76.82), Time 3.45
2019-05-19 07:30:05,927: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 07:30:07,161: INFO: [train_wsdan.py:483]: Valid: Loss 1.16821,  Accuracy: Top-1 70.38, Top-3 86.90, Top-5 91.35, Time 37.33
2019-05-19 07:35:55,361: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.5072, Accuracy: (90.47, 97.38, 98.55), (Crop) Loss 0.5483, Accuracy: (84.56, 94.20, 96.40), (Drop) Loss 1.9142, Accuracy: (56.44, 71.53, 76.86), Time 3.51
2019-05-19 07:41:43,859: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.5058, Accuracy: (90.55, 97.42, 98.57), (Crop) Loss 0.5427, Accuracy: (84.71, 94.29, 96.46), (Drop) Loss 1.9042, Accuracy: (56.64, 71.68, 77.00), Time 3.47
2019-05-19 07:42:21,563: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 07:42:22,728: INFO: [train_wsdan.py:483]: Valid: Loss 1.16887,  Accuracy: Top-1 70.34, Top-3 86.83, Top-5 91.67, Time 37.61
2019-05-19 07:48:10,932: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.5037, Accuracy: (90.61, 97.45, 98.58), (Crop) Loss 0.5374, Accuracy: (84.82, 94.35, 96.51), (Drop) Loss 1.8986, Accuracy: (56.73, 71.76, 77.11), Time 3.47
2019-05-19 07:53:58,801: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.5013, Accuracy: (90.68, 97.50, 98.61), (Crop) Loss 0.5319, Accuracy: (84.95, 94.42, 96.56), (Drop) Loss 1.8948, Accuracy: (56.78, 71.82, 77.15), Time 3.48
2019-05-19 07:54:36,645: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 07:54:37,834: INFO: [train_wsdan.py:483]: Valid: Loss 1.21067,  Accuracy: Top-1 70.50, Top-3 86.48, Top-5 91.44, Time 37.70
2019-05-19 08:00:25,362: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.4998, Accuracy: (90.75, 97.52, 98.63), (Crop) Loss 0.5273, Accuracy: (85.08, 94.50, 96.60), (Drop) Loss 1.8861, Accuracy: (56.95, 71.96, 77.30), Time 3.46
2019-05-19 08:06:12,939: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.4990, Accuracy: (90.77, 97.52, 98.64), (Crop) Loss 0.5255, Accuracy: (85.11, 94.53, 96.61), (Drop) Loss 1.8884, Accuracy: (56.90, 71.90, 77.24), Time 3.47
2019-05-19 08:06:12,939: INFO: [train_wsdan.py:334]: saving the latest model from epoch 10
2019-05-19 08:06:51,689: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 08:06:52,887: INFO: [train_wsdan.py:483]: Valid: Loss 1.17601,  Accuracy: Top-1 70.66, Top-3 86.93, Top-5 91.74, Time 37.41
2019-05-19 08:12:40,928: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.4968, Accuracy: (90.84, 97.55, 98.65), (Crop) Loss 0.5213, Accuracy: (85.21, 94.60, 96.65), (Drop) Loss 1.8841, Accuracy: (57.01, 71.97, 77.27), Time 3.46
2019-05-19 08:18:28,920: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.4953, Accuracy: (90.88, 97.57, 98.66), (Crop) Loss 0.5187, Accuracy: (85.27, 94.63, 96.69), (Drop) Loss 1.8814, Accuracy: (57.07, 72.00, 77.27), Time 3.48
2019-05-19 08:19:06,625: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 08:19:07,791: INFO: [train_wsdan.py:483]: Valid: Loss 1.18120,  Accuracy: Top-1 70.77, Top-3 87.23, Top-5 91.87, Time 37.61
2019-05-19 08:24:55,876: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.4949, Accuracy: (90.90, 97.58, 98.67), (Crop) Loss 0.5167, Accuracy: (85.33, 94.66, 96.70), (Drop) Loss 1.8781, Accuracy: (57.14, 72.05, 77.31), Time 3.49
2019-05-19 08:30:43,866: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.4939, Accuracy: (90.93, 97.59, 98.67), (Crop) Loss 0.5148, Accuracy: (85.38, 94.69, 96.72), (Drop) Loss 1.8796, Accuracy: (57.12, 72.02, 77.25), Time 3.48
2019-05-19 08:31:21,664: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 08:31:22,841: INFO: [train_wsdan.py:483]: Valid: Loss 1.16452,  Accuracy: Top-1 70.40, Top-3 87.13, Top-5 91.84, Time 37.70
2019-05-19 08:37:10,487: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.4932, Accuracy: (90.96, 97.60, 98.68), (Crop) Loss 0.5130, Accuracy: (85.42, 94.71, 96.74), (Drop) Loss 1.8782, Accuracy: (57.13, 72.04, 77.28), Time 3.48
2019-05-19 08:42:58,602: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.4923, Accuracy: (90.97, 97.61, 98.69), (Crop) Loss 0.5111, Accuracy: (85.47, 94.74, 96.76), (Drop) Loss 1.8775, Accuracy: (57.15, 72.05, 77.27), Time 3.53
2019-05-19 08:43:36,707: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 08:43:37,887: INFO: [train_wsdan.py:483]: Valid: Loss 1.17871,  Accuracy: Top-1 70.28, Top-3 87.32, Top-5 91.71, Time 38.01
2019-05-19 08:49:25,750: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.4922, Accuracy: (90.98, 97.61, 98.69), (Crop) Loss 0.5092, Accuracy: (85.50, 94.78, 96.78), (Drop) Loss 1.8731, Accuracy: (57.23, 72.12, 77.34), Time 3.46
2019-05-19 08:55:13,778: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.4915, Accuracy: (91.00, 97.61, 98.69), (Crop) Loss 0.5076, Accuracy: (85.54, 94.80, 96.81), (Drop) Loss 1.8707, Accuracy: (57.27, 72.16, 77.37), Time 3.47
2019-05-19 08:55:51,632: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 08:55:53,417: INFO: [train_wsdan.py:483]: Valid: Loss 1.17271,  Accuracy: Top-1 70.63, Top-3 87.09, Top-5 92.00, Time 37.76
2019-05-19 09:01:41,578: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.4909, Accuracy: (91.01, 97.62, 98.70), (Crop) Loss 0.5061, Accuracy: (85.58, 94.83, 96.82), (Drop) Loss 1.8653, Accuracy: (57.37, 72.25, 77.45), Time 3.49
2019-05-19 09:07:29,591: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.4909, Accuracy: (91.01, 97.62, 98.70), (Crop) Loss 0.5050, Accuracy: (85.61, 94.85, 96.83), (Drop) Loss 1.8611, Accuracy: (57.45, 72.32, 77.53), Time 3.48
2019-05-19 09:07:29,641: INFO: [train_wsdan.py:334]: saving the latest model from epoch 10
2019-05-19 09:08:08,840: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 09:08:10,018: INFO: [train_wsdan.py:483]: Valid: Loss 1.17874,  Accuracy: Top-1 70.50, Top-3 86.38, Top-5 91.51, Time 37.88
2019-05-19 09:13:58,279: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.4903, Accuracy: (91.04, 97.63, 98.70), (Crop) Loss 0.5039, Accuracy: (85.64, 94.87, 96.85), (Drop) Loss 1.8572, Accuracy: (57.52, 72.39, 77.59), Time 3.48
2019-05-19 09:19:46,391: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.4900, Accuracy: (91.05, 97.63, 98.71), (Crop) Loss 0.5025, Accuracy: (85.67, 94.88, 96.86), (Drop) Loss 1.8559, Accuracy: (57.53, 72.41, 77.61), Time 3.48
2019-05-19 09:20:24,249: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 09:20:25,425: INFO: [train_wsdan.py:483]: Valid: Loss 1.18350,  Accuracy: Top-1 70.15, Top-3 87.09, Top-5 91.67, Time 37.76
2019-05-19 09:26:13,861: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.4895, Accuracy: (91.07, 97.64, 98.71), (Crop) Loss 0.5016, Accuracy: (85.70, 94.89, 96.87), (Drop) Loss 1.8544, Accuracy: (57.58, 72.41, 77.62), Time 3.48
2019-05-19 09:32:02,086: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.4894, Accuracy: (91.07, 97.63, 98.71), (Crop) Loss 0.5013, Accuracy: (85.71, 94.89, 96.87), (Drop) Loss 1.8535, Accuracy: (57.60, 72.42, 77.63), Time 3.50
2019-05-19 09:32:39,777: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 09:32:40,947: INFO: [train_wsdan.py:483]: Valid: Loss 1.19415,  Accuracy: Top-1 70.34, Top-3 87.16, Top-5 91.55, Time 37.60
2019-05-19 09:38:29,063: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.4890, Accuracy: (91.10, 97.64, 98.71), (Crop) Loss 0.5003, Accuracy: (85.73, 94.91, 96.88), (Drop) Loss 1.8520, Accuracy: (57.62, 72.45, 77.64), Time 3.47
2019-05-19 09:44:16,933: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.4889, Accuracy: (91.09, 97.64, 98.71), (Crop) Loss 0.4994, Accuracy: (85.75, 94.93, 96.90), (Drop) Loss 1.8509, Accuracy: (57.62, 72.47, 77.67), Time 3.46
2019-05-19 09:44:54,536: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 09:44:57,493: INFO: [train_wsdan.py:483]: Valid: Loss 1.18500,  Accuracy: Top-1 70.44, Top-3 86.38, Top-5 91.61, Time 37.51
2019-05-19 09:50:45,599: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.4887, Accuracy: (91.10, 97.64, 98.72), (Crop) Loss 0.4989, Accuracy: (85.76, 94.94, 96.90), (Drop) Loss 1.8491, Accuracy: (57.67, 72.50, 77.69), Time 3.48
2019-05-19 09:56:33,429: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.4882, Accuracy: (91.11, 97.65, 98.72), (Crop) Loss 0.4980, Accuracy: (85.79, 94.96, 96.91), (Drop) Loss 1.8511, Accuracy: (57.62, 72.46, 77.64), Time 3.51
2019-05-19 09:57:11,005: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 09:57:12,169: INFO: [train_wsdan.py:483]: Valid: Loss 1.20712,  Accuracy: Top-1 69.95, Top-3 86.67, Top-5 91.41, Time 37.48
2019-05-19 10:03:00,367: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.4882, Accuracy: (91.11, 97.65, 98.72), (Crop) Loss 0.4979, Accuracy: (85.78, 94.96, 96.91), (Drop) Loss 1.8479, Accuracy: (57.67, 72.51, 77.70), Time 3.53
2019-05-19 10:08:48,328: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.4882, Accuracy: (91.09, 97.64, 98.73), (Crop) Loss 0.4978, Accuracy: (85.78, 94.95, 96.90), (Drop) Loss 1.8474, Accuracy: (57.67, 72.52, 77.71), Time 3.48
2019-05-19 10:08:48,346: INFO: [train_wsdan.py:334]: saving the latest model from epoch 10
2019-05-19 10:09:26,972: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 10:09:28,140: INFO: [train_wsdan.py:483]: Valid: Loss 1.15681,  Accuracy: Top-1 71.02, Top-3 87.25, Top-5 92.10, Time 37.32
2019-05-19 10:15:16,033: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.4883, Accuracy: (91.09, 97.64, 98.72), (Crop) Loss 0.4975, Accuracy: (85.79, 94.96, 96.91), (Drop) Loss 1.8451, Accuracy: (57.70, 72.56, 77.74), Time 3.47
2019-05-19 10:17:49,211: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.4883, Accuracy: (91.10, 97.64, 98.72), (Crop) Loss 0.4973, Accuracy: (85.80, 94.96, 96.90), (Drop) Loss 1.8454, Accuracy: (57.70, 72.57, 77.74), Time 15223.63
2019-05-19 10:18:26,636: INFO: [train_wsdan.py:471]: saving the best model from epoch 10
2019-05-19 10:18:27,806: INFO: [train_wsdan.py:483]: Valid: Loss 1.18331,  Accuracy: Top-1 70.47, Top-3 87.25, Top-5 91.74, Time 37.32
2019-05-19 10:18:27,814: INFO: [train_wsdan.py:220]: Epoch 011, Learning Rate 0.000148242
2019-05-19 10:24:29,208: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7324, Accuracy: (84.19, 94.58, 96.84), (Crop) Loss 1.1335, Accuracy: (71.11, 86.42, 90.31), (Drop) Loss 1.9727, Accuracy: (55.47, 72.14, 77.88), Time 3.55
2019-05-19 10:30:24,001: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7243, Accuracy: (84.00, 94.67, 97.03), (Crop) Loss 1.1087, Accuracy: (71.37, 86.68, 90.62), (Drop) Loss 1.9466, Accuracy: (55.36, 71.91, 77.65), Time 3.54
2019-05-19 10:31:01,982: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 10:31:03,222: INFO: [train_wsdan.py:483]: Valid: Loss 1.22181,  Accuracy: Top-1 67.31, Top-3 85.69, Top-5 90.24, Time 37.87
2019-05-19 10:36:51,618: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6460, Accuracy: (86.29, 95.65, 97.53), (Crop) Loss 0.9003, Accuracy: (76.43, 89.56, 92.81), (Drop) Loss 1.9578, Accuracy: (55.19, 71.43, 76.99), Time 3.56
2019-05-19 10:42:39,983: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.5980, Accuracy: (87.73, 96.26, 97.92), (Crop) Loss 0.7816, Accuracy: (79.32, 91.16, 94.02), (Drop) Loss 1.9708, Accuracy: (55.25, 71.06, 76.50), Time 3.48
2019-05-19 10:43:18,401: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 10:43:19,866: INFO: [train_wsdan.py:483]: Valid: Loss 1.18809,  Accuracy: Top-1 70.08, Top-3 86.77, Top-5 91.77, Time 38.32
2019-05-19 10:49:07,456: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.5682, Accuracy: (88.64, 96.62, 98.13), (Crop) Loss 0.7111, Accuracy: (80.95, 92.07, 94.70), (Drop) Loss 1.9690, Accuracy: (55.42, 70.90, 76.39), Time 3.47
2019-05-19 10:54:55,565: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5465, Accuracy: (89.31, 96.90, 98.33), (Crop) Loss 0.6611, Accuracy: (82.18, 92.73, 95.21), (Drop) Loss 1.9597, Accuracy: (55.65, 71.02, 76.44), Time 3.46
2019-05-19 10:55:33,106: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 10:55:34,284: INFO: [train_wsdan.py:483]: Valid: Loss 1.18561,  Accuracy: Top-1 70.34, Top-3 87.09, Top-5 92.06, Time 37.45
2019-05-19 11:01:22,251: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5337, Accuracy: (89.70, 97.07, 98.43), (Crop) Loss 0.6278, Accuracy: (82.95, 93.20, 95.54), (Drop) Loss 1.9587, Accuracy: (55.73, 71.00, 76.38), Time 3.47
2019-05-19 11:07:09,856: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5226, Accuracy: (90.03, 97.22, 98.53), (Crop) Loss 0.6012, Accuracy: (83.60, 93.59, 95.80), (Drop) Loss 1.9442, Accuracy: (55.91, 71.21, 76.52), Time 3.47
2019-05-19 11:07:48,172: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 11:07:49,412: INFO: [train_wsdan.py:483]: Valid: Loss 1.19438,  Accuracy: Top-1 70.28, Top-3 86.90, Top-5 91.48, Time 38.20
2019-05-19 11:13:37,421: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.5149, Accuracy: (90.32, 97.32, 98.58), (Crop) Loss 0.5811, Accuracy: (84.06, 93.86, 96.03), (Drop) Loss 1.9370, Accuracy: (56.08, 71.32, 76.61), Time 3.48
2019-05-19 11:19:25,657: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.5077, Accuracy: (90.55, 97.40, 98.61), (Crop) Loss 0.5623, Accuracy: (84.51, 94.10, 96.21), (Drop) Loss 1.9320, Accuracy: (56.20, 71.35, 76.63), Time 3.47
2019-05-19 11:19:25,686: INFO: [train_wsdan.py:334]: saving the latest model from epoch 11
2019-05-19 11:20:05,124: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 11:20:06,365: INFO: [train_wsdan.py:483]: Valid: Loss 1.20550,  Accuracy: Top-1 70.73, Top-3 87.09, Top-5 91.38, Time 38.14
2019-05-19 11:25:54,629: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.5027, Accuracy: (90.76, 97.46, 98.67), (Crop) Loss 0.5505, Accuracy: (84.77, 94.25, 96.33), (Drop) Loss 1.9288, Accuracy: (56.29, 71.41, 76.70), Time 3.47
2019-05-19 11:31:42,949: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.4988, Accuracy: (90.89, 97.51, 98.70), (Crop) Loss 0.5386, Accuracy: (85.05, 94.43, 96.45), (Drop) Loss 1.9229, Accuracy: (56.41, 71.51, 76.74), Time 3.47
2019-05-19 11:32:20,998: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 11:32:24,156: INFO: [train_wsdan.py:483]: Valid: Loss 1.19656,  Accuracy: Top-1 70.15, Top-3 86.61, Top-5 91.93, Time 37.95
2019-05-19 11:38:11,911: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.4946, Accuracy: (91.00, 97.57, 98.74), (Crop) Loss 0.5280, Accuracy: (85.29, 94.57, 96.56), (Drop) Loss 1.9231, Accuracy: (56.43, 71.51, 76.71), Time 3.48
2019-05-19 11:44:00,185: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.4922, Accuracy: (91.08, 97.61, 98.76), (Crop) Loss 0.5211, Accuracy: (85.43, 94.67, 96.63), (Drop) Loss 1.9277, Accuracy: (56.41, 71.43, 76.64), Time 3.46
2019-05-19 11:44:37,795: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 11:44:38,975: INFO: [train_wsdan.py:483]: Valid: Loss 1.21228,  Accuracy: Top-1 70.31, Top-3 86.31, Top-5 91.12, Time 37.51
2019-05-19 11:50:26,914: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.4904, Accuracy: (91.15, 97.62, 98.77), (Crop) Loss 0.5153, Accuracy: (85.54, 94.75, 96.69), (Drop) Loss 1.9307, Accuracy: (56.37, 71.37, 76.59), Time 3.47
2019-05-19 11:56:14,774: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.4891, Accuracy: (91.18, 97.64, 98.77), (Crop) Loss 0.5105, Accuracy: (85.65, 94.82, 96.73), (Drop) Loss 1.9350, Accuracy: (56.29, 71.28, 76.49), Time 3.47
2019-05-19 11:56:52,959: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 11:56:54,115: INFO: [train_wsdan.py:483]: Valid: Loss 1.18282,  Accuracy: Top-1 70.34, Top-3 86.73, Top-5 91.55, Time 38.09
2019-05-19 12:02:42,264: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.4865, Accuracy: (91.28, 97.68, 98.79), (Crop) Loss 0.5051, Accuracy: (85.80, 94.89, 96.79), (Drop) Loss 1.9326, Accuracy: (56.35, 71.28, 76.50), Time 3.48
2019-05-19 12:08:30,623: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.4853, Accuracy: (91.32, 97.68, 98.79), (Crop) Loss 0.5008, Accuracy: (85.94, 94.92, 96.81), (Drop) Loss 1.9409, Accuracy: (56.23, 71.12, 76.34), Time 3.48
2019-05-19 12:09:08,619: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 12:09:09,794: INFO: [train_wsdan.py:483]: Valid: Loss 1.18820,  Accuracy: Top-1 70.33, Top-3 86.67, Top-5 91.48, Time 37.90
2019-05-19 12:14:58,197: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.4837, Accuracy: (91.39, 97.70, 98.79), (Crop) Loss 0.4973, Accuracy: (86.02, 94.97, 96.85), (Drop) Loss 1.9443, Accuracy: (56.18, 71.06, 76.29), Time 3.48
2019-05-19 12:20:46,671: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.4819, Accuracy: (91.45, 97.73, 98.80), (Crop) Loss 0.4935, Accuracy: (86.11, 95.01, 96.88), (Drop) Loss 1.9355, Accuracy: (56.34, 71.19, 76.40), Time 3.48
2019-05-19 12:20:46,671: INFO: [train_wsdan.py:334]: saving the latest model from epoch 11
2019-05-19 12:21:26,031: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 12:21:27,207: INFO: [train_wsdan.py:483]: Valid: Loss 1.20780,  Accuracy: Top-1 70.27, Top-3 86.67, Top-5 91.35, Time 38.03
2019-05-19 12:27:15,202: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.4800, Accuracy: (91.52, 97.75, 98.82), (Crop) Loss 0.4895, Accuracy: (86.18, 95.07, 96.91), (Drop) Loss 1.9337, Accuracy: (56.36, 71.21, 76.41), Time 3.46
2019-05-19 12:33:03,242: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.4793, Accuracy: (91.57, 97.75, 98.82), (Crop) Loss 0.4872, Accuracy: (86.25, 95.10, 96.94), (Drop) Loss 1.9295, Accuracy: (56.45, 71.27, 76.46), Time 3.45
2019-05-19 12:33:41,045: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 12:33:43,143: INFO: [train_wsdan.py:483]: Valid: Loss 1.20478,  Accuracy: Top-1 70.21, Top-3 86.63, Top-5 91.54, Time 37.69
2019-05-19 12:39:31,063: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.4778, Accuracy: (91.61, 97.77, 98.83), (Crop) Loss 0.4841, Accuracy: (86.32, 95.14, 96.96), (Drop) Loss 1.9250, Accuracy: (56.53, 71.32, 76.51), Time 3.47
2019-05-19 12:45:18,686: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.4766, Accuracy: (91.63, 97.80, 98.84), (Crop) Loss 0.4807, Accuracy: (86.40, 95.18, 97.00), (Drop) Loss 1.9215, Accuracy: (56.59, 71.38, 76.55), Time 3.46
2019-05-19 12:45:56,491: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 12:45:57,679: INFO: [train_wsdan.py:483]: Valid: Loss 1.15690,  Accuracy: Top-1 71.38, Top-3 87.45, Top-5 91.55, Time 37.71
2019-05-19 12:51:45,797: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.4754, Accuracy: (91.67, 97.81, 98.85), (Crop) Loss 0.4787, Accuracy: (86.44, 95.22, 97.03), (Drop) Loss 1.9220, Accuracy: (56.61, 71.41, 76.57), Time 3.50
2019-05-19 12:57:34,196: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.4746, Accuracy: (91.70, 97.82, 98.85), (Crop) Loss 0.4768, Accuracy: (86.49, 95.24, 97.05), (Drop) Loss 1.9184, Accuracy: (56.68, 71.46, 76.61), Time 3.51
2019-05-19 12:58:12,156: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 12:58:13,355: INFO: [train_wsdan.py:483]: Valid: Loss 1.18529,  Accuracy: Top-1 70.53, Top-3 87.03, Top-5 91.45, Time 37.87
2019-05-19 13:04:02,022: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.4739, Accuracy: (91.72, 97.83, 98.86), (Crop) Loss 0.4752, Accuracy: (86.54, 95.26, 97.07), (Drop) Loss 1.9151, Accuracy: (56.76, 71.52, 76.67), Time 3.47
2019-05-19 13:09:50,794: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.4731, Accuracy: (91.74, 97.84, 98.86), (Crop) Loss 0.4729, Accuracy: (86.58, 95.29, 97.09), (Drop) Loss 1.9115, Accuracy: (56.81, 71.58, 76.74), Time 3.48
2019-05-19 13:10:28,948: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 13:10:30,118: INFO: [train_wsdan.py:483]: Valid: Loss 1.20648,  Accuracy: Top-1 70.11, Top-3 86.67, Top-5 91.31, Time 38.06
2019-05-19 13:16:18,458: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.4726, Accuracy: (91.76, 97.84, 98.87), (Crop) Loss 0.4711, Accuracy: (86.61, 95.32, 97.11), (Drop) Loss 1.9075, Accuracy: (56.85, 71.65, 76.79), Time 3.46
2019-05-19 13:22:05,744: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.4719, Accuracy: (91.77, 97.85, 98.88), (Crop) Loss 0.4694, Accuracy: (86.64, 95.34, 97.13), (Drop) Loss 1.9040, Accuracy: (56.93, 71.71, 76.85), Time 3.45
2019-05-19 13:22:05,744: INFO: [train_wsdan.py:334]: saving the latest model from epoch 11
2019-05-19 13:22:44,961: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 13:22:46,125: INFO: [train_wsdan.py:483]: Valid: Loss 1.19904,  Accuracy: Top-1 70.60, Top-3 87.19, Top-5 91.61, Time 37.91
2019-05-19 13:28:33,731: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.4716, Accuracy: (91.78, 97.86, 98.88), (Crop) Loss 0.4685, Accuracy: (86.66, 95.34, 97.13), (Drop) Loss 1.9001, Accuracy: (56.99, 71.78, 76.91), Time 3.47
2019-05-19 13:34:21,477: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.4713, Accuracy: (91.80, 97.87, 98.89), (Crop) Loss 0.4672, Accuracy: (86.70, 95.37, 97.15), (Drop) Loss 1.8967, Accuracy: (57.05, 71.81, 76.96), Time 3.48
2019-05-19 13:34:59,136: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 13:35:00,318: INFO: [train_wsdan.py:483]: Valid: Loss 1.19135,  Accuracy: Top-1 71.21, Top-3 86.51, Top-5 91.57, Time 37.56
2019-05-19 13:40:48,570: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.4707, Accuracy: (91.82, 97.88, 98.89), (Crop) Loss 0.4663, Accuracy: (86.73, 95.38, 97.16), (Drop) Loss 1.8946, Accuracy: (57.11, 71.84, 76.98), Time 3.53
2019-05-19 13:46:36,824: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.4704, Accuracy: (91.83, 97.89, 98.90), (Crop) Loss 0.4654, Accuracy: (86.74, 95.39, 97.17), (Drop) Loss 1.8896, Accuracy: (57.18, 71.93, 77.06), Time 3.47
2019-05-19 13:47:14,277: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 13:47:15,457: INFO: [train_wsdan.py:483]: Valid: Loss 1.18873,  Accuracy: Top-1 70.89, Top-3 87.00, Top-5 92.00, Time 37.31
2019-05-19 13:53:03,828: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.4700, Accuracy: (91.84, 97.89, 98.90), (Crop) Loss 0.4643, Accuracy: (86.76, 95.41, 97.18), (Drop) Loss 1.8876, Accuracy: (57.24, 71.97, 77.10), Time 3.47
2019-05-19 13:58:52,297: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.4697, Accuracy: (91.86, 97.89, 98.90), (Crop) Loss 0.4635, Accuracy: (86.78, 95.42, 97.19), (Drop) Loss 1.8843, Accuracy: (57.31, 72.02, 77.15), Time 3.47
2019-05-19 13:59:29,827: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 13:59:31,087: INFO: [train_wsdan.py:483]: Valid: Loss 1.18959,  Accuracy: Top-1 70.63, Top-3 87.06, Top-5 92.06, Time 37.43
2019-05-19 14:05:19,154: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.4695, Accuracy: (91.87, 97.90, 98.91), (Crop) Loss 0.4626, Accuracy: (86.80, 95.44, 97.20), (Drop) Loss 1.8807, Accuracy: (57.35, 72.08, 77.21), Time 3.51
2019-05-19 14:11:06,812: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.4696, Accuracy: (91.85, 97.90, 98.91), (Crop) Loss 0.4620, Accuracy: (86.81, 95.45, 97.21), (Drop) Loss 1.8792, Accuracy: (57.38, 72.10, 77.25), Time 3.48
2019-05-19 14:11:44,638: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 14:11:45,821: INFO: [train_wsdan.py:483]: Valid: Loss 1.18306,  Accuracy: Top-1 70.89, Top-3 86.80, Top-5 91.38, Time 37.73
2019-05-19 14:17:33,839: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.4694, Accuracy: (91.86, 97.89, 98.90), (Crop) Loss 0.4614, Accuracy: (86.82, 95.45, 97.21), (Drop) Loss 1.8769, Accuracy: (57.45, 72.14, 77.28), Time 3.48
2019-05-19 14:23:21,693: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.4691, Accuracy: (91.88, 97.89, 98.90), (Crop) Loss 0.4606, Accuracy: (86.84, 95.46, 97.22), (Drop) Loss 1.8742, Accuracy: (57.50, 72.18, 77.30), Time 3.45
2019-05-19 14:23:21,694: INFO: [train_wsdan.py:334]: saving the latest model from epoch 11
2019-05-19 14:24:00,625: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 14:24:03,718: INFO: [train_wsdan.py:483]: Valid: Loss 1.19557,  Accuracy: Top-1 70.95, Top-3 86.77, Top-5 91.44, Time 37.61
2019-05-19 14:29:51,526: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.4687, Accuracy: (91.90, 97.90, 98.90), (Crop) Loss 0.4599, Accuracy: (86.88, 95.46, 97.22), (Drop) Loss 1.8717, Accuracy: (57.55, 72.21, 77.33), Time 3.49
2019-05-19 14:32:24,813: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.4686, Accuracy: (91.90, 97.90, 98.91), (Crop) Loss 0.4597, Accuracy: (86.88, 95.46, 97.23), (Drop) Loss 1.8709, Accuracy: (57.56, 72.23, 77.34), Time 15237.00
2019-05-19 14:33:02,358: INFO: [train_wsdan.py:471]: saving the best model from epoch 11
2019-05-19 14:33:03,543: INFO: [train_wsdan.py:483]: Valid: Loss 1.17327,  Accuracy: Top-1 70.57, Top-3 86.87, Top-5 91.22, Time 37.44
2019-05-19 14:33:03,551: INFO: [train_wsdan.py:220]: Epoch 012, Learning Rate 0.000120076
2019-05-19 14:39:03,946: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7364, Accuracy: (83.88, 94.47, 96.77), (Crop) Loss 1.1325, Accuracy: (70.97, 86.28, 90.27), (Drop) Loss 2.0576, Accuracy: (54.00, 70.28, 76.25), Time 3.54
2019-05-19 14:44:58,032: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7248, Accuracy: (83.81, 94.57, 96.78), (Crop) Loss 1.1082, Accuracy: (71.36, 86.70, 90.45), (Drop) Loss 2.0017, Accuracy: (54.47, 70.87, 76.94), Time 3.54
2019-05-19 14:45:36,391: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 14:45:37,566: INFO: [train_wsdan.py:483]: Valid: Loss 1.17540,  Accuracy: Top-1 68.71, Top-3 85.89, Top-5 90.66, Time 38.27
2019-05-19 14:51:25,226: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6361, Accuracy: (86.43, 95.71, 97.49), (Crop) Loss 0.8871, Accuracy: (76.82, 89.70, 92.74), (Drop) Loss 1.9801, Accuracy: (55.12, 70.84, 76.66), Time 3.48
2019-05-19 14:57:13,359: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.5830, Accuracy: (88.18, 96.40, 97.94), (Crop) Loss 0.7614, Accuracy: (79.96, 91.42, 94.00), (Drop) Loss 1.9746, Accuracy: (55.35, 70.64, 76.33), Time 3.47
2019-05-19 14:57:50,855: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 14:57:52,043: INFO: [train_wsdan.py:483]: Valid: Loss 1.17982,  Accuracy: Top-1 70.44, Top-3 87.26, Top-5 91.74, Time 37.37
2019-05-19 15:03:40,141: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.5522, Accuracy: (89.13, 96.82, 98.18), (Crop) Loss 0.6859, Accuracy: (81.67, 92.41, 94.78), (Drop) Loss 1.9466, Accuracy: (55.88, 71.03, 76.55), Time 3.47
2019-05-19 15:09:28,132: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5313, Accuracy: (89.83, 97.10, 98.35), (Crop) Loss 0.6333, Accuracy: (82.97, 93.12, 95.36), (Drop) Loss 1.9173, Accuracy: (56.41, 71.49, 76.95), Time 3.48
2019-05-19 15:10:05,897: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 15:10:07,068: INFO: [train_wsdan.py:483]: Valid: Loss 1.18821,  Accuracy: Top-1 70.70, Top-3 87.00, Top-5 91.61, Time 37.67
2019-05-19 15:15:55,406: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5156, Accuracy: (90.29, 97.32, 98.50), (Crop) Loss 0.5953, Accuracy: (83.88, 93.60, 95.74), (Drop) Loss 1.8997, Accuracy: (56.78, 71.74, 77.12), Time 3.46
2019-05-19 15:21:43,781: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5072, Accuracy: (90.64, 97.44, 98.56), (Crop) Loss 0.5714, Accuracy: (84.46, 93.94, 95.97), (Drop) Loss 1.8806, Accuracy: (57.22, 72.08, 77.36), Time 3.47
2019-05-19 15:22:21,457: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 15:22:22,667: INFO: [train_wsdan.py:483]: Valid: Loss 1.19170,  Accuracy: Top-1 71.22, Top-3 87.32, Top-5 91.80, Time 37.58
2019-05-19 15:28:10,892: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.4984, Accuracy: (90.93, 97.58, 98.64), (Crop) Loss 0.5503, Accuracy: (85.03, 94.23, 96.20), (Drop) Loss 1.8605, Accuracy: (57.59, 72.42, 77.64), Time 3.47
2019-05-19 15:33:59,489: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.4918, Accuracy: (91.17, 97.67, 98.71), (Crop) Loss 0.5348, Accuracy: (85.38, 94.42, 96.34), (Drop) Loss 1.8503, Accuracy: (57.78, 72.62, 77.78), Time 3.49
2019-05-19 15:33:59,489: INFO: [train_wsdan.py:334]: saving the latest model from epoch 12
2019-05-19 15:34:37,851: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 15:34:39,026: INFO: [train_wsdan.py:483]: Valid: Loss 1.19680,  Accuracy: Top-1 70.70, Top-3 87.22, Top-5 91.81, Time 37.01
2019-05-19 15:40:27,511: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.4871, Accuracy: (91.35, 97.73, 98.74), (Crop) Loss 0.5219, Accuracy: (85.70, 94.61, 96.45), (Drop) Loss 1.8333, Accuracy: (58.12, 72.90, 78.02), Time 3.47
2019-05-19 15:46:16,268: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.4832, Accuracy: (91.51, 97.77, 98.76), (Crop) Loss 0.5112, Accuracy: (85.94, 94.73, 96.58), (Drop) Loss 1.8241, Accuracy: (58.31, 73.04, 78.14), Time 3.46
2019-05-19 15:46:54,242: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 15:46:55,439: INFO: [train_wsdan.py:483]: Valid: Loss 1.21746,  Accuracy: Top-1 70.27, Top-3 86.86, Top-5 91.15, Time 37.88
2019-05-19 15:52:43,618: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.4800, Accuracy: (91.62, 97.81, 98.79), (Crop) Loss 0.5029, Accuracy: (86.15, 94.83, 96.66), (Drop) Loss 1.8194, Accuracy: (58.41, 73.14, 78.20), Time 3.49
2019-05-19 15:58:32,134: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.4778, Accuracy: (91.69, 97.82, 98.80), (Crop) Loss 0.4955, Accuracy: (86.30, 94.95, 96.75), (Drop) Loss 1.8146, Accuracy: (58.54, 73.22, 78.27), Time 3.48
2019-05-19 15:59:10,189: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 15:59:11,347: INFO: [train_wsdan.py:483]: Valid: Loss 1.20404,  Accuracy: Top-1 70.50, Top-3 86.96, Top-5 91.67, Time 37.90
2019-05-19 16:04:59,464: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.4752, Accuracy: (91.78, 97.87, 98.84), (Crop) Loss 0.4886, Accuracy: (86.48, 95.04, 96.83), (Drop) Loss 1.8067, Accuracy: (58.68, 73.36, 78.37), Time 3.46
2019-05-19 16:10:47,672: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.4731, Accuracy: (91.83, 97.90, 98.87), (Crop) Loss 0.4831, Accuracy: (86.62, 95.12, 96.90), (Drop) Loss 1.8071, Accuracy: (58.66, 73.36, 78.36), Time 3.50
2019-05-19 16:11:25,748: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 16:11:26,931: INFO: [train_wsdan.py:483]: Valid: Loss 1.20321,  Accuracy: Top-1 70.70, Top-3 87.06, Top-5 91.84, Time 37.98
2019-05-19 16:17:15,350: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.4711, Accuracy: (91.90, 97.94, 98.89), (Crop) Loss 0.4768, Accuracy: (86.76, 95.21, 96.98), (Drop) Loss 1.8051, Accuracy: (58.71, 73.38, 78.39), Time 3.44
2019-05-19 16:23:03,587: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.4695, Accuracy: (91.95, 97.96, 98.90), (Crop) Loss 0.4718, Accuracy: (86.88, 95.28, 97.03), (Drop) Loss 1.8103, Accuracy: (58.65, 73.30, 78.29), Time 3.47
2019-05-19 16:23:41,208: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 16:23:42,362: INFO: [train_wsdan.py:483]: Valid: Loss 1.21190,  Accuracy: Top-1 70.47, Top-3 86.87, Top-5 91.54, Time 37.53
2019-05-19 16:29:30,983: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.4680, Accuracy: (92.01, 97.98, 98.92), (Crop) Loss 0.4669, Accuracy: (86.99, 95.33, 97.08), (Drop) Loss 1.8193, Accuracy: (58.50, 73.16, 78.15), Time 3.47
2019-05-19 16:35:19,660: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.4669, Accuracy: (92.06, 97.99, 98.92), (Crop) Loss 0.4641, Accuracy: (87.07, 95.36, 97.10), (Drop) Loss 1.8199, Accuracy: (58.51, 73.15, 78.15), Time 3.48
2019-05-19 16:35:19,661: INFO: [train_wsdan.py:334]: saving the latest model from epoch 12
2019-05-19 16:35:59,345: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 16:36:00,526: INFO: [train_wsdan.py:483]: Valid: Loss 1.21229,  Accuracy: Top-1 70.73, Top-3 87.16, Top-5 91.68, Time 38.40
2019-05-19 16:41:49,551: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.4656, Accuracy: (92.12, 98.01, 98.93), (Crop) Loss 0.4607, Accuracy: (87.13, 95.42, 97.14), (Drop) Loss 1.8162, Accuracy: (58.58, 73.22, 78.23), Time 3.47
2019-05-19 16:47:38,262: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.4647, Accuracy: (92.16, 98.02, 98.94), (Crop) Loss 0.4578, Accuracy: (87.22, 95.45, 97.17), (Drop) Loss 1.8182, Accuracy: (58.54, 73.17, 78.18), Time 3.47
2019-05-19 16:48:16,322: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 16:48:17,480: INFO: [train_wsdan.py:483]: Valid: Loss 1.21013,  Accuracy: Top-1 70.82, Top-3 86.87, Top-5 91.64, Time 37.96
2019-05-19 16:54:05,762: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.4630, Accuracy: (92.21, 98.04, 98.95), (Crop) Loss 0.4535, Accuracy: (87.32, 95.50, 97.21), (Drop) Loss 1.8242, Accuracy: (58.44, 73.05, 78.07), Time 3.49
2019-05-19 16:59:54,058: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.4623, Accuracy: (92.24, 98.04, 98.95), (Crop) Loss 0.4508, Accuracy: (87.39, 95.54, 97.23), (Drop) Loss 1.8243, Accuracy: (58.45, 73.04, 78.07), Time 3.47
2019-05-19 17:00:32,315: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 17:00:33,491: INFO: [train_wsdan.py:483]: Valid: Loss 1.22366,  Accuracy: Top-1 69.75, Top-3 86.74, Top-5 91.51, Time 38.16
2019-05-19 17:06:21,718: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.4613, Accuracy: (92.28, 98.06, 98.96), (Crop) Loss 0.4477, Accuracy: (87.45, 95.59, 97.27), (Drop) Loss 1.8184, Accuracy: (58.56, 73.13, 78.15), Time 3.46
2019-05-19 17:12:09,800: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.4603, Accuracy: (92.32, 98.07, 98.97), (Crop) Loss 0.4453, Accuracy: (87.52, 95.62, 97.29), (Drop) Loss 1.8171, Accuracy: (58.60, 73.17, 78.19), Time 3.46
2019-05-19 17:12:47,765: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 17:12:48,960: INFO: [train_wsdan.py:483]: Valid: Loss 1.23187,  Accuracy: Top-1 70.73, Top-3 86.73, Top-5 91.93, Time 37.87
2019-05-19 17:18:37,562: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.4600, Accuracy: (92.32, 98.08, 98.98), (Crop) Loss 0.4438, Accuracy: (87.55, 95.64, 97.30), (Drop) Loss 1.8112, Accuracy: (58.71, 73.29, 78.29), Time 3.48
2019-05-19 17:24:25,631: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.4588, Accuracy: (92.35, 98.09, 98.99), (Crop) Loss 0.4415, Accuracy: (87.61, 95.68, 97.32), (Drop) Loss 1.8076, Accuracy: (58.77, 73.34, 78.33), Time 3.48
2019-05-19 17:25:03,554: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 17:25:04,725: INFO: [train_wsdan.py:483]: Valid: Loss 1.19421,  Accuracy: Top-1 70.93, Top-3 87.28, Top-5 92.13, Time 37.83
2019-05-19 17:30:52,923: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.4578, Accuracy: (92.37, 98.10, 99.00), (Crop) Loss 0.4389, Accuracy: (87.67, 95.72, 97.34), (Drop) Loss 1.8042, Accuracy: (58.84, 73.40, 78.38), Time 3.48
2019-05-19 17:36:41,682: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.4573, Accuracy: (92.38, 98.10, 99.00), (Crop) Loss 0.4378, Accuracy: (87.71, 95.74, 97.36), (Drop) Loss 1.8071, Accuracy: (58.80, 73.34, 78.33), Time 3.47
2019-05-19 17:36:41,682: INFO: [train_wsdan.py:334]: saving the latest model from epoch 12
2019-05-19 17:37:20,891: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 17:37:22,083: INFO: [train_wsdan.py:483]: Valid: Loss 1.18627,  Accuracy: Top-1 70.83, Top-3 87.64, Top-5 91.71, Time 37.90
2019-05-19 17:43:09,788: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.4570, Accuracy: (92.39, 98.11, 99.00), (Crop) Loss 0.4365, Accuracy: (87.74, 95.76, 97.37), (Drop) Loss 1.8095, Accuracy: (58.77, 73.31, 78.29), Time 3.47
2019-05-19 17:48:58,638: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.4565, Accuracy: (92.42, 98.11, 99.01), (Crop) Loss 0.4345, Accuracy: (87.78, 95.79, 97.39), (Drop) Loss 1.8128, Accuracy: (58.72, 73.23, 78.22), Time 3.48
2019-05-19 17:49:36,687: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 17:49:37,849: INFO: [train_wsdan.py:483]: Valid: Loss 1.21865,  Accuracy: Top-1 70.77, Top-3 87.22, Top-5 91.84, Time 37.96
2019-05-19 17:55:26,560: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.4561, Accuracy: (92.41, 98.12, 99.02), (Crop) Loss 0.4337, Accuracy: (87.79, 95.79, 97.40), (Drop) Loss 1.8117, Accuracy: (58.74, 73.25, 78.23), Time 3.47
2019-05-19 18:01:15,029: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.4554, Accuracy: (92.43, 98.13, 99.02), (Crop) Loss 0.4322, Accuracy: (87.82, 95.81, 97.42), (Drop) Loss 1.8087, Accuracy: (58.78, 73.31, 78.28), Time 3.47
2019-05-19 18:01:52,537: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 18:01:53,716: INFO: [train_wsdan.py:483]: Valid: Loss 1.19404,  Accuracy: Top-1 70.63, Top-3 87.38, Top-5 91.84, Time 37.41
2019-05-19 18:07:42,247: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.4547, Accuracy: (92.46, 98.14, 99.03), (Crop) Loss 0.4308, Accuracy: (87.87, 95.83, 97.43), (Drop) Loss 1.8091, Accuracy: (58.79, 73.28, 78.26), Time 3.48
2019-05-19 18:13:30,738: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.4545, Accuracy: (92.47, 98.14, 99.02), (Crop) Loss 0.4302, Accuracy: (87.88, 95.84, 97.44), (Drop) Loss 1.8126, Accuracy: (58.74, 73.22, 78.22), Time 3.47
2019-05-19 18:14:08,822: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 18:14:10,028: INFO: [train_wsdan.py:483]: Valid: Loss 1.18971,  Accuracy: Top-1 70.57, Top-3 87.22, Top-5 91.51, Time 37.99
2019-05-19 18:19:58,730: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.4545, Accuracy: (92.46, 98.14, 99.02), (Crop) Loss 0.4297, Accuracy: (87.89, 95.85, 97.45), (Drop) Loss 1.8172, Accuracy: (58.66, 73.15, 78.14), Time 3.48
2019-05-19 18:25:47,690: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.4543, Accuracy: (92.47, 98.14, 99.02), (Crop) Loss 0.4288, Accuracy: (87.90, 95.86, 97.45), (Drop) Loss 1.8212, Accuracy: (58.60, 73.08, 78.07), Time 3.48
2019-05-19 18:26:25,510: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 18:26:26,699: INFO: [train_wsdan.py:483]: Valid: Loss 1.19970,  Accuracy: Top-1 70.86, Top-3 87.42, Top-5 91.74, Time 37.68
2019-05-19 18:32:14,532: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.4541, Accuracy: (92.48, 98.14, 99.02), (Crop) Loss 0.4284, Accuracy: (87.90, 95.86, 97.46), (Drop) Loss 1.8267, Accuracy: (58.52, 72.99, 77.97), Time 3.49
2019-05-19 18:38:02,555: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.4538, Accuracy: (92.48, 98.15, 99.02), (Crop) Loss 0.4279, Accuracy: (87.91, 95.87, 97.47), (Drop) Loss 1.8286, Accuracy: (58.50, 72.96, 77.94), Time 3.46
2019-05-19 18:38:02,555: INFO: [train_wsdan.py:334]: saving the latest model from epoch 12
2019-05-19 18:38:42,300: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 18:38:45,457: INFO: [train_wsdan.py:483]: Valid: Loss 1.21166,  Accuracy: Top-1 69.98, Top-3 86.70, Top-5 91.55, Time 37.90
2019-05-19 18:44:32,461: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.4530, Accuracy: (92.51, 98.15, 99.03), (Crop) Loss 0.4266, Accuracy: (87.93, 95.89, 97.49), (Drop) Loss 1.8280, Accuracy: (58.53, 72.96, 77.95), Time 3.48
2019-05-19 18:47:06,029: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.4529, Accuracy: (92.51, 98.16, 99.03), (Crop) Loss 0.4261, Accuracy: (87.95, 95.90, 97.49), (Drop) Loss 1.8288, Accuracy: (58.52, 72.96, 77.93), Time 15242.48
2019-05-19 18:47:43,405: INFO: [train_wsdan.py:471]: saving the best model from epoch 12
2019-05-19 18:47:44,592: INFO: [train_wsdan.py:483]: Valid: Loss 1.21467,  Accuracy: Top-1 70.47, Top-3 87.22, Top-5 91.94, Time 37.27
2019-05-19 18:47:44,603: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 9.72613e-05
2019-05-19 18:53:46,365: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7247, Accuracy: (83.81, 94.69, 96.83), (Crop) Loss 1.1418, Accuracy: (70.52, 86.12, 90.36), (Drop) Loss 2.0074, Accuracy: (54.19, 71.67, 77.11), Time 3.56
2019-05-19 18:59:40,839: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7194, Accuracy: (83.95, 94.73, 96.98), (Crop) Loss 1.1189, Accuracy: (70.84, 86.44, 90.53), (Drop) Loss 1.9926, Accuracy: (54.31, 71.38, 77.04), Time 3.55
2019-05-19 19:00:18,428: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 19:00:19,616: INFO: [train_wsdan.py:483]: Valid: Loss 1.19015,  Accuracy: Top-1 68.58, Top-3 85.99, Top-5 90.83, Time 37.49
2019-05-19 19:06:07,001: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6300, Accuracy: (86.52, 95.88, 97.68), (Crop) Loss 0.8953, Accuracy: (76.35, 89.55, 92.82), (Drop) Loss 1.9228, Accuracy: (55.91, 72.07, 77.67), Time 3.51
2019-05-19 19:11:54,791: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.5797, Accuracy: (88.15, 96.46, 98.04), (Crop) Loss 0.7624, Accuracy: (79.72, 91.29, 94.11), (Drop) Loss 1.9106, Accuracy: (56.37, 71.95, 77.38), Time 3.48
2019-05-19 19:12:32,863: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 19:12:34,027: INFO: [train_wsdan.py:483]: Valid: Loss 1.20604,  Accuracy: Top-1 70.86, Top-3 86.96, Top-5 91.84, Time 37.98
2019-05-19 19:18:22,542: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.5470, Accuracy: (89.29, 96.84, 98.25), (Crop) Loss 0.6774, Accuracy: (81.85, 92.38, 94.96), (Drop) Loss 1.8934, Accuracy: (56.73, 72.10, 77.45), Time 3.47
2019-05-19 19:24:10,949: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5263, Accuracy: (90.02, 97.11, 98.42), (Crop) Loss 0.6229, Accuracy: (83.24, 93.12, 95.49), (Drop) Loss 1.8833, Accuracy: (57.10, 72.18, 77.44), Time 3.48
2019-05-19 19:24:49,150: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 19:24:50,314: INFO: [train_wsdan.py:483]: Valid: Loss 1.21421,  Accuracy: Top-1 70.53, Top-3 87.06, Top-5 91.90, Time 38.11
2019-05-19 19:30:38,407: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5116, Accuracy: (90.51, 97.29, 98.53), (Crop) Loss 0.5865, Accuracy: (84.19, 93.63, 95.85), (Drop) Loss 1.8701, Accuracy: (57.43, 72.40, 77.55), Time 3.47
2019-05-19 19:36:26,688: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.4997, Accuracy: (90.93, 97.46, 98.62), (Crop) Loss 0.5563, Accuracy: (84.91, 94.04, 96.14), (Drop) Loss 1.8484, Accuracy: (57.88, 72.77, 77.90), Time 3.44
2019-05-19 19:37:05,548: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 19:37:06,715: INFO: [train_wsdan.py:483]: Valid: Loss 1.21100,  Accuracy: Top-1 71.35, Top-3 87.28, Top-5 91.51, Time 38.71
2019-05-19 19:42:54,595: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.4903, Accuracy: (91.24, 97.59, 98.71), (Crop) Loss 0.5337, Accuracy: (85.43, 94.37, 96.38), (Drop) Loss 1.8388, Accuracy: (58.11, 72.93, 78.00), Time 3.46
2019-05-19 19:48:42,258: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.4840, Accuracy: (91.48, 97.68, 98.77), (Crop) Loss 0.5163, Accuracy: (85.84, 94.62, 96.55), (Drop) Loss 1.8353, Accuracy: (58.25, 72.97, 78.00), Time 3.49
2019-05-19 19:48:42,258: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-05-19 19:49:21,398: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 19:49:22,597: INFO: [train_wsdan.py:483]: Valid: Loss 1.21676,  Accuracy: Top-1 70.83, Top-3 87.25, Top-5 91.73, Time 37.86
2019-05-19 19:55:10,354: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.4796, Accuracy: (91.64, 97.75, 98.80), (Crop) Loss 0.5028, Accuracy: (86.15, 94.79, 96.67), (Drop) Loss 1.8322, Accuracy: (58.33, 72.96, 78.01), Time 3.52
2019-05-19 20:00:58,257: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.4743, Accuracy: (91.81, 97.81, 98.83), (Crop) Loss 0.4895, Accuracy: (86.49, 94.96, 96.81), (Drop) Loss 1.8352, Accuracy: (58.34, 72.94, 77.97), Time 3.48
2019-05-19 20:01:36,205: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 20:01:37,369: INFO: [train_wsdan.py:483]: Valid: Loss 1.20956,  Accuracy: Top-1 71.03, Top-3 86.54, Top-5 91.48, Time 37.85
2019-05-19 20:07:25,905: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.4709, Accuracy: (91.95, 97.86, 98.86), (Crop) Loss 0.4796, Accuracy: (86.73, 95.09, 96.90), (Drop) Loss 1.8328, Accuracy: (58.43, 72.96, 77.98), Time 3.47
2019-05-19 20:13:14,611: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.4680, Accuracy: (92.04, 97.90, 98.88), (Crop) Loss 0.4714, Accuracy: (86.90, 95.21, 96.99), (Drop) Loss 1.8296, Accuracy: (58.47, 72.94, 77.99), Time 3.49
2019-05-19 20:13:52,626: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 20:13:53,835: INFO: [train_wsdan.py:483]: Valid: Loss 1.20379,  Accuracy: Top-1 70.53, Top-3 87.29, Top-5 91.77, Time 37.92
2019-05-19 20:19:42,794: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.4654, Accuracy: (92.12, 97.93, 98.90), (Crop) Loss 0.4639, Accuracy: (87.09, 95.29, 97.05), (Drop) Loss 1.8342, Accuracy: (58.44, 72.86, 77.91), Time 3.52
2019-05-19 20:25:31,220: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.4626, Accuracy: (92.23, 97.98, 98.94), (Crop) Loss 0.4574, Accuracy: (87.24, 95.38, 97.12), (Drop) Loss 1.8343, Accuracy: (58.42, 72.89, 77.92), Time 3.49
2019-05-19 20:26:08,642: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 20:26:11,976: INFO: [train_wsdan.py:483]: Valid: Loss 1.22919,  Accuracy: Top-1 70.47, Top-3 87.06, Top-5 91.57, Time 37.33
2019-05-19 20:32:00,248: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.4602, Accuracy: (92.32, 98.01, 98.96), (Crop) Loss 0.4507, Accuracy: (87.41, 95.46, 97.18), (Drop) Loss 1.8373, Accuracy: (58.39, 72.81, 77.85), Time 3.48
2019-05-19 20:37:48,693: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.4582, Accuracy: (92.38, 98.02, 98.97), (Crop) Loss 0.4449, Accuracy: (87.54, 95.54, 97.24), (Drop) Loss 1.8491, Accuracy: (58.20, 72.59, 77.63), Time 3.48
2019-05-19 20:38:26,966: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 20:38:28,173: INFO: [train_wsdan.py:483]: Valid: Loss 1.22066,  Accuracy: Top-1 70.77, Top-3 87.15, Top-5 91.61, Time 38.15
2019-05-19 20:42:46,679: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-05-19 20:42:49,127: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-05-19 20:42:49,160: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-05-19 20:42:49,180: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-05-19 20:42:51,132: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 64, Training size: 265213, Validation size: 3030
2019-05-19 20:42:51,132: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 0.0006
2019-05-19 20:49:34,610: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.7158, Accuracy: (83.31, 94.45, 96.97), (Crop) Loss 1.1055, Accuracy: (70.34, 86.11, 91.03), (Drop) Loss 2.0039, Accuracy: (54.05, 70.53, 76.38), Time 3.55
2019-05-19 20:55:28,478: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.7195, Accuracy: (83.19, 94.49, 97.02), (Crop) Loss 1.0863, Accuracy: (70.77, 86.50, 91.26), (Drop) Loss 2.0482, Accuracy: (53.45, 69.90, 75.49), Time 3.55
2019-05-19 20:56:21,823: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 20:56:23,001: INFO: [train_wsdan.py:483]: Valid: Loss 1.22540,  Accuracy: Top-1 67.34, Top-3 86.41, Top-5 90.95, Time 53.23
2019-05-19 21:02:09,677: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6564, Accuracy: (85.11, 95.46, 97.56), (Crop) Loss 0.9077, Accuracy: (75.01, 89.21, 93.22), (Drop) Loss 2.0818, Accuracy: (52.79, 68.89, 74.83), Time 3.47
2019-05-19 21:07:56,635: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.6341, Accuracy: (85.92, 95.79, 97.75), (Crop) Loss 0.8372, Accuracy: (76.67, 90.32, 93.98), (Drop) Loss 2.0873, Accuracy: (52.73, 68.73, 74.62), Time 3.46
2019-05-19 21:08:35,186: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 21:08:36,429: INFO: [train_wsdan.py:483]: Valid: Loss 1.29373,  Accuracy: Top-1 67.84, Top-3 84.56, Top-5 89.82, Time 38.46
2019-05-19 21:14:24,546: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.6173, Accuracy: (86.42, 96.04, 97.87), (Crop) Loss 0.7879, Accuracy: (77.87, 91.01, 94.47), (Drop) Loss 2.0540, Accuracy: (53.31, 69.38, 75.19), Time 3.48
2019-05-19 21:20:12,304: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.6055, Accuracy: (86.72, 96.21, 97.97), (Crop) Loss 0.7579, Accuracy: (78.55, 91.45, 94.79), (Drop) Loss 2.0408, Accuracy: (53.60, 69.54, 75.28), Time 3.50
2019-05-19 21:20:50,506: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 21:20:51,891: INFO: [train_wsdan.py:483]: Valid: Loss 1.33508,  Accuracy: Top-1 66.76, Top-3 85.01, Top-5 90.41, Time 38.11
2019-05-19 21:26:41,234: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5984, Accuracy: (87.00, 96.35, 98.04), (Crop) Loss 0.7349, Accuracy: (79.05, 91.86, 95.04), (Drop) Loss 2.0309, Accuracy: (53.73, 69.67, 75.43), Time 3.48
2019-05-19 21:32:30,214: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5925, Accuracy: (87.18, 96.39, 98.05), (Crop) Loss 0.7203, Accuracy: (79.42, 92.06, 95.15), (Drop) Loss 1.9868, Accuracy: (54.49, 70.38, 76.07), Time 3.46
2019-05-19 21:33:08,249: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-05-19 21:33:09,514: INFO: [train_wsdan.py:483]: Valid: Loss 1.30040,  Accuracy: Top-1 67.12, Top-3 85.04, Top-5 90.14, Time 37.94
2019-06-03 08:16:07,796: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-03 08:18:50,663: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-03 08:18:53,005: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-03 08:18:53,037: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-06-03 08:18:53,052: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-03 08:18:54,725: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-06-03 08:18:54,725: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 0.0004
2019-06-03 08:23:03,736: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.9012, Accuracy: (79.53, 91.94, 95.47), (Crop) Loss 1.3764, Accuracy: (65.53, 82.16, 87.28), (Drop) Loss 2.2874, Accuracy: (49.53, 66.72, 72.62), Time 2.09
2019-06-03 08:26:33,110: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.8849, Accuracy: (79.06, 92.48, 95.50), (Crop) Loss 1.3468, Accuracy: (65.86, 82.41, 87.53), (Drop) Loss 2.2902, Accuracy: (49.81, 66.27, 72.00), Time 2.21
2019-06-03 08:27:32,319: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 08:27:35,123: INFO: [train_wsdan.py:483]: Valid: Loss 1.34797,  Accuracy: Top-1 65.97, Top-3 83.73, Top-5 89.10, Time 59.10
2019-06-03 08:30:59,883: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.7852, Accuracy: (81.69, 93.83, 96.38), (Crop) Loss 1.1173, Accuracy: (70.59, 85.90, 90.34), (Drop) Loss 2.3917, Accuracy: (48.15, 64.45, 70.05), Time 2.06
2019-06-03 08:34:24,049: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.7408, Accuracy: (82.94, 94.50, 96.84), (Crop) Loss 0.9990, Accuracy: (73.10, 87.73, 91.85), (Drop) Loss 2.4673, Accuracy: (46.80, 62.89, 68.54), Time 2.05
2019-06-03 08:35:09,495: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 08:35:11,902: INFO: [train_wsdan.py:483]: Valid: Loss 1.40543,  Accuracy: Top-1 65.46, Top-3 84.33, Top-5 89.67, Time 45.35
2019-06-03 08:38:36,578: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.7162, Accuracy: (83.50, 94.87, 97.09), (Crop) Loss 0.9413, Accuracy: (74.36, 88.72, 92.64), (Drop) Loss 2.4218, Accuracy: (47.54, 63.28, 69.12), Time 2.07
2019-06-03 08:41:58,663: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-03 08:42:00,991: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-03 08:42:01,022: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-06-03 08:42:01,038: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-03 08:42:02,110: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-06-03 08:42:02,111: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 0.0001
2019-06-03 08:46:11,835: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.8805, Accuracy: (79.81, 92.25, 94.97), (Crop) Loss 1.3515, Accuracy: (64.91, 82.31, 87.59), (Drop) Loss 2.3026, Accuracy: (50.22, 66.34, 71.81), Time 2.09
2019-06-03 08:49:41,112: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.8716, Accuracy: (79.62, 92.47, 95.09), (Crop) Loss 1.3445, Accuracy: (65.28, 82.61, 87.83), (Drop) Loss 2.2573, Accuracy: (49.97, 67.17, 72.78), Time 2.07
2019-06-03 08:50:38,800: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 08:50:41,560: INFO: [train_wsdan.py:483]: Valid: Loss 1.24774,  Accuracy: Top-1 67.43, Top-3 85.47, Top-5 89.63, Time 57.59
2019-06-03 08:54:06,808: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.7328, Accuracy: (83.74, 94.30, 96.38), (Crop) Loss 1.0434, Accuracy: (72.55, 87.09, 91.09), (Drop) Loss 2.1571, Accuracy: (51.76, 68.28, 73.75), Time 2.04
2019-06-03 08:57:32,578: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.6576, Accuracy: (86.02, 95.33, 97.03), (Crop) Loss 0.8821, Accuracy: (76.39, 89.49, 92.80), (Drop) Loss 2.1281, Accuracy: (52.70, 68.63, 73.98), Time 2.08
2019-06-03 08:58:17,909: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 08:58:21,048: INFO: [train_wsdan.py:483]: Valid: Loss 1.19117,  Accuracy: Top-1 69.65, Top-3 86.64, Top-5 91.55, Time 45.24
2019-06-03 09:01:46,694: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.6136, Accuracy: (87.42, 95.88, 97.44), (Crop) Loss 0.7830, Accuracy: (78.72, 90.86, 93.86), (Drop) Loss 2.0969, Accuracy: (53.25, 69.01, 74.31), Time 2.05
2019-06-03 09:05:12,261: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5828, Accuracy: (88.40, 96.34, 97.76), (Crop) Loss 0.7165, Accuracy: (80.46, 91.81, 94.58), (Drop) Loss 2.0729, Accuracy: (53.85, 69.34, 74.62), Time 2.03
2019-06-03 09:05:57,687: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:06:00,960: INFO: [train_wsdan.py:483]: Valid: Loss 1.24240,  Accuracy: Top-1 69.72, Top-3 86.59, Top-5 90.89, Time 45.34
2019-06-03 09:09:27,098: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5626, Accuracy: (89.10, 96.62, 97.95), (Crop) Loss 0.6716, Accuracy: (81.56, 92.48, 95.09), (Drop) Loss 2.0610, Accuracy: (54.21, 69.33, 74.64), Time 2.15
2019-06-03 09:12:53,280: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.5479, Accuracy: (89.54, 96.86, 98.13), (Crop) Loss 0.6383, Accuracy: (82.43, 92.92, 95.39), (Drop) Loss 2.0557, Accuracy: (54.33, 69.34, 74.61), Time 2.04
2019-06-03 09:13:38,878: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:13:40,044: INFO: [train_wsdan.py:483]: Valid: Loss 1.21991,  Accuracy: Top-1 69.88, Top-3 87.21, Top-5 91.44, Time 45.50
2019-06-03 09:17:05,677: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.5369, Accuracy: (89.90, 97.01, 98.22), (Crop) Loss 0.6146, Accuracy: (83.02, 93.23, 95.64), (Drop) Loss 2.0811, Accuracy: (53.97, 68.89, 74.14), Time 2.04
2019-06-03 09:20:31,596: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.5269, Accuracy: (90.21, 97.14, 98.30), (Crop) Loss 0.5914, Accuracy: (83.56, 93.57, 95.91), (Drop) Loss 2.0909, Accuracy: (53.78, 68.64, 73.98), Time 2.05
2019-06-03 09:20:31,596: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-03 09:21:18,112: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:21:19,270: INFO: [train_wsdan.py:483]: Valid: Loss 1.22282,  Accuracy: Top-1 69.21, Top-3 86.64, Top-5 91.44, Time 45.15
2019-06-03 09:24:45,611: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.5197, Accuracy: (90.45, 97.22, 98.36), (Crop) Loss 0.5727, Accuracy: (84.06, 93.84, 96.10), (Drop) Loss 2.0843, Accuracy: (53.84, 68.72, 74.06), Time 2.04
2019-06-03 09:28:11,919: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.5135, Accuracy: (90.66, 97.30, 98.41), (Crop) Loss 0.5570, Accuracy: (84.45, 94.08, 96.26), (Drop) Loss 2.0777, Accuracy: (54.03, 68.83, 74.13), Time 2.03
2019-06-03 09:28:58,420: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:28:59,600: INFO: [train_wsdan.py:483]: Valid: Loss 1.21454,  Accuracy: Top-1 69.83, Top-3 87.13, Top-5 91.50, Time 46.40
2019-06-03 09:32:25,448: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.5080, Accuracy: (90.80, 97.35, 98.47), (Crop) Loss 0.5454, Accuracy: (84.75, 94.23, 96.39), (Drop) Loss 2.0638, Accuracy: (54.38, 69.06, 74.34), Time 2.03
2019-06-03 09:35:51,404: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.5041, Accuracy: (90.95, 97.40, 98.50), (Crop) Loss 0.5344, Accuracy: (85.05, 94.40, 96.49), (Drop) Loss 2.0566, Accuracy: (54.52, 69.20, 74.44), Time 2.07
2019-06-03 09:36:37,275: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:36:38,450: INFO: [train_wsdan.py:483]: Valid: Loss 1.20691,  Accuracy: Top-1 69.73, Top-3 86.95, Top-5 91.91, Time 45.78
2019-06-03 09:40:04,692: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.4999, Accuracy: (91.06, 97.47, 98.55), (Crop) Loss 0.5263, Accuracy: (85.27, 94.50, 96.57), (Drop) Loss 2.0513, Accuracy: (54.59, 69.25, 74.47), Time 2.04
2019-06-03 09:43:31,074: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.4956, Accuracy: (91.22, 97.55, 98.59), (Crop) Loss 0.5173, Accuracy: (85.47, 94.65, 96.67), (Drop) Loss 2.0471, Accuracy: (54.72, 69.35, 74.56), Time 2.13
2019-06-03 09:44:16,309: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:44:17,495: INFO: [train_wsdan.py:483]: Valid: Loss 1.24373,  Accuracy: Top-1 69.50, Top-3 86.80, Top-5 91.63, Time 45.14
2019-06-03 09:47:43,220: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.4924, Accuracy: (91.31, 97.58, 98.63), (Crop) Loss 0.5108, Accuracy: (85.62, 94.73, 96.74), (Drop) Loss 2.0487, Accuracy: (54.69, 69.30, 74.51), Time 2.05
2019-06-03 09:51:08,856: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.4896, Accuracy: (91.39, 97.62, 98.66), (Crop) Loss 0.5063, Accuracy: (85.70, 94.78, 96.79), (Drop) Loss 2.0438, Accuracy: (54.77, 69.40, 74.59), Time 2.04
2019-06-03 09:51:54,775: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:51:55,944: INFO: [train_wsdan.py:483]: Valid: Loss 1.23219,  Accuracy: Top-1 69.36, Top-3 86.90, Top-5 91.35, Time 45.82
2019-06-03 09:55:22,084: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.4885, Accuracy: (91.42, 97.66, 98.67), (Crop) Loss 0.5017, Accuracy: (85.81, 94.83, 96.83), (Drop) Loss 2.0346, Accuracy: (54.91, 69.56, 74.74), Time 2.09
2019-06-03 09:58:48,350: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.4860, Accuracy: (91.48, 97.69, 98.70), (Crop) Loss 0.4965, Accuracy: (85.92, 94.92, 96.89), (Drop) Loss 2.0250, Accuracy: (55.08, 69.68, 74.89), Time 2.10
2019-06-03 09:58:48,351: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-03 09:59:36,497: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 09:59:39,175: INFO: [train_wsdan.py:483]: Valid: Loss 1.24731,  Accuracy: Top-1 69.55, Top-3 86.88, Top-5 91.47, Time 45.53
2019-06-03 10:03:05,438: INFO: [train_wsdan.py:330]: 
	Batch 2100: (Raw) Loss 0.4837, Accuracy: (91.55, 97.73, 98.73), (Crop) Loss 0.4933, Accuracy: (86.03, 94.97, 96.92), (Drop) Loss 2.0225, Accuracy: (55.14, 69.72, 74.92), Time 2.04
2019-06-03 10:06:31,039: INFO: [train_wsdan.py:330]: 
	Batch 2200: (Raw) Loss 0.4819, Accuracy: (91.60, 97.77, 98.76), (Crop) Loss 0.4892, Accuracy: (86.13, 95.04, 96.98), (Drop) Loss 2.0189, Accuracy: (55.18, 69.73, 74.95), Time 2.07
2019-06-03 10:07:16,560: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:07:19,409: INFO: [train_wsdan.py:483]: Valid: Loss 1.21702,  Accuracy: Top-1 70.16, Top-3 87.15, Top-5 91.53, Time 45.42
2019-06-03 10:10:45,774: INFO: [train_wsdan.py:330]: 
	Batch 2300: (Raw) Loss 0.4806, Accuracy: (91.62, 97.79, 98.77), (Crop) Loss 0.4843, Accuracy: (86.25, 95.11, 97.02), (Drop) Loss 2.0142, Accuracy: (55.24, 69.78, 74.99), Time 2.03
2019-06-03 10:14:12,051: INFO: [train_wsdan.py:330]: 
	Batch 2400: (Raw) Loss 0.4795, Accuracy: (91.65, 97.80, 98.77), (Crop) Loss 0.4797, Accuracy: (86.35, 95.17, 97.06), (Drop) Loss 2.0140, Accuracy: (55.24, 69.82, 75.02), Time 2.02
2019-06-03 10:14:57,659: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:14:58,854: INFO: [train_wsdan.py:483]: Valid: Loss 1.22791,  Accuracy: Top-1 69.62, Top-3 87.46, Top-5 91.30, Time 45.50
2019-06-03 10:18:25,484: INFO: [train_wsdan.py:330]: 
	Batch 2500: (Raw) Loss 0.4787, Accuracy: (91.67, 97.81, 98.79), (Crop) Loss 0.4772, Accuracy: (86.39, 95.22, 97.09), (Drop) Loss 2.0152, Accuracy: (55.23, 69.82, 75.02), Time 2.05
2019-06-03 10:21:51,240: INFO: [train_wsdan.py:330]: 
	Batch 2600: (Raw) Loss 0.4770, Accuracy: (91.71, 97.84, 98.80), (Crop) Loss 0.4734, Accuracy: (86.48, 95.28, 97.13), (Drop) Loss 2.0132, Accuracy: (55.26, 69.80, 75.00), Time 2.06
2019-06-03 10:22:37,085: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:22:38,260: INFO: [train_wsdan.py:483]: Valid: Loss 1.23105,  Accuracy: Top-1 69.93, Top-3 86.75, Top-5 91.70, Time 45.75
2019-06-03 10:26:04,487: INFO: [train_wsdan.py:330]: 
	Batch 2700: (Raw) Loss 0.4769, Accuracy: (91.72, 97.84, 98.80), (Crop) Loss 0.4714, Accuracy: (86.53, 95.32, 97.16), (Drop) Loss 2.0102, Accuracy: (55.31, 69.88, 75.08), Time 2.03
2019-06-03 10:29:30,706: INFO: [train_wsdan.py:330]: 
	Batch 2800: (Raw) Loss 0.4756, Accuracy: (91.76, 97.86, 98.82), (Crop) Loss 0.4692, Accuracy: (86.57, 95.36, 97.18), (Drop) Loss 2.0067, Accuracy: (55.37, 69.94, 75.14), Time 2.14
2019-06-03 10:30:15,487: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:30:18,716: INFO: [train_wsdan.py:483]: Valid: Loss 1.21758,  Accuracy: Top-1 69.91, Top-3 86.79, Top-5 91.73, Time 44.68
2019-06-03 10:33:45,580: INFO: [train_wsdan.py:330]: 
	Batch 2900: (Raw) Loss 0.4742, Accuracy: (91.81, 97.89, 98.84), (Crop) Loss 0.4670, Accuracy: (86.61, 95.39, 97.20), (Drop) Loss 2.0120, Accuracy: (55.27, 69.82, 75.03), Time 2.08
2019-06-03 10:37:12,175: INFO: [train_wsdan.py:330]: 
	Batch 3000: (Raw) Loss 0.4731, Accuracy: (91.83, 97.90, 98.85), (Crop) Loss 0.4655, Accuracy: (86.62, 95.40, 97.20), (Drop) Loss 2.0088, Accuracy: (55.31, 69.86, 75.08), Time 2.04
2019-06-03 10:37:12,175: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-03 10:37:59,002: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:38:00,177: INFO: [train_wsdan.py:483]: Valid: Loss 1.22346,  Accuracy: Top-1 70.18, Top-3 87.49, Top-5 91.06, Time 45.44
2019-06-03 10:41:26,860: INFO: [train_wsdan.py:330]: 
	Batch 3100: (Raw) Loss 0.4721, Accuracy: (91.87, 97.92, 98.87), (Crop) Loss 0.4645, Accuracy: (86.65, 95.41, 97.20), (Drop) Loss 2.0038, Accuracy: (55.39, 69.95, 75.15), Time 2.09
2019-06-03 10:44:53,195: INFO: [train_wsdan.py:330]: 
	Batch 3200: (Raw) Loss 0.4718, Accuracy: (91.89, 97.93, 98.87), (Crop) Loss 0.4633, Accuracy: (86.68, 95.43, 97.21), (Drop) Loss 2.0001, Accuracy: (55.46, 70.01, 75.20), Time 2.04
2019-06-03 10:45:39,229: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:45:40,401: INFO: [train_wsdan.py:483]: Valid: Loss 1.20180,  Accuracy: Top-1 70.61, Top-3 87.18, Top-5 91.47, Time 45.94
2019-06-03 10:49:06,917: INFO: [train_wsdan.py:330]: 
	Batch 3300: (Raw) Loss 0.4707, Accuracy: (91.91, 97.94, 98.88), (Crop) Loss 0.4617, Accuracy: (86.72, 95.45, 97.23), (Drop) Loss 1.9956, Accuracy: (55.54, 70.09, 75.28), Time 2.04
2019-06-03 10:52:33,049: INFO: [train_wsdan.py:330]: 
	Batch 3400: (Raw) Loss 0.4698, Accuracy: (91.93, 97.95, 98.89), (Crop) Loss 0.4594, Accuracy: (86.78, 95.48, 97.25), (Drop) Loss 1.9919, Accuracy: (55.59, 70.16, 75.34), Time 2.07
2019-06-03 10:53:18,636: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 10:53:19,812: INFO: [train_wsdan.py:483]: Valid: Loss 1.21825,  Accuracy: Top-1 69.96, Top-3 86.79, Top-5 91.37, Time 45.49
2019-06-03 10:56:45,730: INFO: [train_wsdan.py:330]: 
	Batch 3500: (Raw) Loss 0.4700, Accuracy: (91.93, 97.95, 98.89), (Crop) Loss 0.4584, Accuracy: (86.83, 95.49, 97.26), (Drop) Loss 1.9866, Accuracy: (55.70, 70.25, 75.43), Time 2.03
2019-06-03 11:00:11,707: INFO: [train_wsdan.py:330]: 
	Batch 3600: (Raw) Loss 0.4692, Accuracy: (91.97, 97.96, 98.90), (Crop) Loss 0.4570, Accuracy: (86.86, 95.50, 97.26), (Drop) Loss 1.9853, Accuracy: (55.75, 70.27, 75.45), Time 2.06
2019-06-03 11:00:57,213: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:00:58,388: INFO: [train_wsdan.py:483]: Valid: Loss 1.22987,  Accuracy: Top-1 70.18, Top-3 87.00, Top-5 91.65, Time 45.41
2019-06-03 11:04:24,166: INFO: [train_wsdan.py:330]: 
	Batch 3700: (Raw) Loss 0.4682, Accuracy: (91.98, 97.98, 98.90), (Crop) Loss 0.4553, Accuracy: (86.91, 95.52, 97.28), (Drop) Loss 1.9813, Accuracy: (55.83, 70.33, 75.50), Time 2.04
2019-06-03 11:07:50,381: INFO: [train_wsdan.py:330]: 
	Batch 3800: (Raw) Loss 0.4675, Accuracy: (92.01, 98.00, 98.91), (Crop) Loss 0.4541, Accuracy: (86.94, 95.54, 97.30), (Drop) Loss 1.9782, Accuracy: (55.88, 70.37, 75.57), Time 2.05
2019-06-03 11:08:36,026: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:08:37,197: INFO: [train_wsdan.py:483]: Valid: Loss 1.22728,  Accuracy: Top-1 69.93, Top-3 86.93, Top-5 91.76, Time 45.55
2019-06-03 11:12:04,315: INFO: [train_wsdan.py:330]: 
	Batch 3900: (Raw) Loss 0.4666, Accuracy: (92.04, 98.00, 98.92), (Crop) Loss 0.4521, Accuracy: (86.98, 95.56, 97.31), (Drop) Loss 1.9722, Accuracy: (55.99, 70.48, 75.67), Time 2.03
2019-06-03 11:15:30,994: INFO: [train_wsdan.py:330]: 
	Batch 4000: (Raw) Loss 0.4658, Accuracy: (92.06, 98.01, 98.93), (Crop) Loss 0.4504, Accuracy: (87.02, 95.58, 97.33), (Drop) Loss 1.9670, Accuracy: (56.09, 70.57, 75.75), Time 2.10
2019-06-03 11:15:30,994: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-03 11:16:20,201: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:16:23,414: INFO: [train_wsdan.py:483]: Valid: Loss 1.25667,  Accuracy: Top-1 70.18, Top-3 86.67, Top-5 91.12, Time 45.95
2019-06-03 11:19:50,331: INFO: [train_wsdan.py:330]: 
	Batch 4100: (Raw) Loss 0.4652, Accuracy: (92.07, 98.02, 98.93), (Crop) Loss 0.4491, Accuracy: (87.04, 95.60, 97.34), (Drop) Loss 1.9594, Accuracy: (56.20, 70.72, 75.88), Time 2.05
2019-06-03 11:23:17,375: INFO: [train_wsdan.py:330]: 
	Batch 4200: (Raw) Loss 0.4654, Accuracy: (92.07, 98.01, 98.93), (Crop) Loss 0.4490, Accuracy: (87.05, 95.60, 97.34), (Drop) Loss 1.9513, Accuracy: (56.34, 70.86, 76.01), Time 2.10
2019-06-03 11:24:03,076: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:24:05,449: INFO: [train_wsdan.py:483]: Valid: Loss 1.22323,  Accuracy: Top-1 70.67, Top-3 87.28, Top-5 91.88, Time 45.61
2019-06-03 11:27:32,334: INFO: [train_wsdan.py:330]: 
	Batch 4300: (Raw) Loss 0.4649, Accuracy: (92.07, 98.02, 98.93), (Crop) Loss 0.4480, Accuracy: (87.08, 95.61, 97.35), (Drop) Loss 1.9433, Accuracy: (56.46, 70.99, 76.14), Time 2.20
2019-06-03 11:30:58,582: INFO: [train_wsdan.py:330]: 
	Batch 4400: (Raw) Loss 0.4646, Accuracy: (92.08, 98.03, 98.94), (Crop) Loss 0.4470, Accuracy: (87.10, 95.62, 97.36), (Drop) Loss 1.9376, Accuracy: (56.56, 71.07, 76.23), Time 2.04
2019-06-03 11:31:44,870: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:31:47,443: INFO: [train_wsdan.py:483]: Valid: Loss 1.23879,  Accuracy: Top-1 70.08, Top-3 86.57, Top-5 91.45, Time 46.19
2019-06-03 11:35:14,319: INFO: [train_wsdan.py:330]: 
	Batch 4500: (Raw) Loss 0.4644, Accuracy: (92.08, 98.04, 98.94), (Crop) Loss 0.4468, Accuracy: (87.11, 95.62, 97.36), (Drop) Loss 1.9336, Accuracy: (56.61, 71.14, 76.31), Time 2.13
2019-06-03 11:38:41,050: INFO: [train_wsdan.py:330]: 
	Batch 4600: (Raw) Loss 0.4638, Accuracy: (92.10, 98.04, 98.95), (Crop) Loss 0.4455, Accuracy: (87.16, 95.64, 97.38), (Drop) Loss 1.9297, Accuracy: (56.67, 71.18, 76.35), Time 2.06
2019-06-03 11:39:27,156: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:39:29,943: INFO: [train_wsdan.py:483]: Valid: Loss 1.21842,  Accuracy: Top-1 70.79, Top-3 87.26, Top-5 91.81, Time 46.01
2019-06-03 11:42:56,816: INFO: [train_wsdan.py:330]: 
	Batch 4700: (Raw) Loss 0.4636, Accuracy: (92.11, 98.05, 98.95), (Crop) Loss 0.4445, Accuracy: (87.17, 95.66, 97.39), (Drop) Loss 1.9274, Accuracy: (56.69, 71.22, 76.38), Time 2.09
2019-06-03 11:46:23,287: INFO: [train_wsdan.py:330]: 
	Batch 4800: (Raw) Loss 0.4631, Accuracy: (92.12, 98.06, 98.95), (Crop) Loss 0.4432, Accuracy: (87.21, 95.69, 97.41), (Drop) Loss 1.9218, Accuracy: (56.80, 71.32, 76.47), Time 2.09
2019-06-03 11:47:08,874: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:47:11,835: INFO: [train_wsdan.py:483]: Valid: Loss 1.23383,  Accuracy: Top-1 69.83, Top-3 86.73, Top-5 92.12, Time 45.49
2019-06-03 11:50:38,604: INFO: [train_wsdan.py:330]: 
	Batch 4900: (Raw) Loss 0.4627, Accuracy: (92.14, 98.06, 98.96), (Crop) Loss 0.4419, Accuracy: (87.25, 95.71, 97.42), (Drop) Loss 1.9195, Accuracy: (56.83, 71.35, 76.50), Time 2.05
2019-06-03 11:54:05,429: INFO: [train_wsdan.py:330]: 
	Batch 5000: (Raw) Loss 0.4622, Accuracy: (92.16, 98.07, 98.97), (Crop) Loss 0.4409, Accuracy: (87.27, 95.72, 97.43), (Drop) Loss 1.9156, Accuracy: (56.91, 71.41, 76.55), Time 2.05
2019-06-03 11:54:05,429: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-03 11:54:54,280: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 11:54:56,603: INFO: [train_wsdan.py:483]: Valid: Loss 1.22267,  Accuracy: Top-1 70.18, Top-3 86.87, Top-5 91.29, Time 45.50
2019-06-03 11:58:23,899: INFO: [train_wsdan.py:330]: 
	Batch 5100: (Raw) Loss 0.4621, Accuracy: (92.16, 98.07, 98.97), (Crop) Loss 0.4399, Accuracy: (87.31, 95.73, 97.43), (Drop) Loss 1.9133, Accuracy: (56.95, 71.46, 76.60), Time 2.07
2019-06-03 12:01:51,090: INFO: [train_wsdan.py:330]: 
	Batch 5200: (Raw) Loss 0.4618, Accuracy: (92.18, 98.08, 98.97), (Crop) Loss 0.4392, Accuracy: (87.33, 95.74, 97.43), (Drop) Loss 1.9094, Accuracy: (57.02, 71.52, 76.66), Time 2.07
2019-06-03 12:02:37,114: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:02:39,660: INFO: [train_wsdan.py:483]: Valid: Loss 1.20672,  Accuracy: Top-1 70.42, Top-3 87.11, Top-5 91.83, Time 45.93
2019-06-03 12:06:06,251: INFO: [train_wsdan.py:330]: 
	Batch 5300: (Raw) Loss 0.4618, Accuracy: (92.18, 98.07, 98.97), (Crop) Loss 0.4387, Accuracy: (87.34, 95.75, 97.44), (Drop) Loss 1.9071, Accuracy: (57.05, 71.55, 76.70), Time 2.05
2019-06-03 12:09:33,096: INFO: [train_wsdan.py:330]: 
	Batch 5400: (Raw) Loss 0.4616, Accuracy: (92.19, 98.08, 98.97), (Crop) Loss 0.4383, Accuracy: (87.35, 95.76, 97.45), (Drop) Loss 1.9037, Accuracy: (57.10, 71.62, 76.75), Time 2.04
2019-06-03 12:10:18,929: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:10:21,635: INFO: [train_wsdan.py:483]: Valid: Loss 1.21816,  Accuracy: Top-1 70.42, Top-3 87.29, Top-5 91.37, Time 45.74
2019-06-03 12:13:48,892: INFO: [train_wsdan.py:330]: 
	Batch 5500: (Raw) Loss 0.4616, Accuracy: (92.20, 98.08, 98.97), (Crop) Loss 0.4376, Accuracy: (87.37, 95.77, 97.45), (Drop) Loss 1.9011, Accuracy: (57.15, 71.66, 76.79), Time 2.08
2019-06-03 12:17:16,035: INFO: [train_wsdan.py:330]: 
	Batch 5600: (Raw) Loss 0.4610, Accuracy: (92.22, 98.09, 98.97), (Crop) Loss 0.4363, Accuracy: (87.40, 95.79, 97.47), (Drop) Loss 1.8984, Accuracy: (57.19, 71.69, 76.82), Time 2.05
2019-06-03 12:18:01,885: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:18:04,785: INFO: [train_wsdan.py:483]: Valid: Loss 1.22535,  Accuracy: Top-1 70.03, Top-3 86.88, Top-5 91.30, Time 45.75
2019-06-03 12:21:32,279: INFO: [train_wsdan.py:330]: 
	Batch 5700: (Raw) Loss 0.4607, Accuracy: (92.23, 98.10, 98.98), (Crop) Loss 0.4359, Accuracy: (87.40, 95.80, 97.48), (Drop) Loss 1.8947, Accuracy: (57.24, 71.76, 76.89), Time 2.12
2019-06-03 12:24:59,373: INFO: [train_wsdan.py:330]: 
	Batch 5800: (Raw) Loss 0.4605, Accuracy: (92.24, 98.10, 98.98), (Crop) Loss 0.4357, Accuracy: (87.41, 95.80, 97.49), (Drop) Loss 1.8926, Accuracy: (57.27, 71.79, 76.92), Time 2.07
2019-06-03 12:25:45,320: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:25:46,485: INFO: [train_wsdan.py:483]: Valid: Loss 1.21148,  Accuracy: Top-1 70.10, Top-3 87.25, Top-5 91.71, Time 45.85
2019-06-03 12:29:13,801: INFO: [train_wsdan.py:330]: 
	Batch 5900: (Raw) Loss 0.4602, Accuracy: (92.25, 98.11, 98.99), (Crop) Loss 0.4357, Accuracy: (87.42, 95.80, 97.48), (Drop) Loss 1.8880, Accuracy: (57.33, 71.88, 76.99), Time 2.07
2019-06-03 12:32:41,211: INFO: [train_wsdan.py:330]: 
	Batch 6000: (Raw) Loss 0.4600, Accuracy: (92.25, 98.11, 98.99), (Crop) Loss 0.4357, Accuracy: (87.42, 95.80, 97.48), (Drop) Loss 1.8837, Accuracy: (57.43, 71.95, 77.06), Time 2.09
2019-06-03 12:32:41,211: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-03 12:33:28,198: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:33:29,373: INFO: [train_wsdan.py:483]: Valid: Loss 1.18732,  Accuracy: Top-1 70.62, Top-3 86.75, Top-5 91.83, Time 45.65
2019-06-03 12:36:56,471: INFO: [train_wsdan.py:330]: 
	Batch 6100: (Raw) Loss 0.4598, Accuracy: (92.26, 98.11, 98.99), (Crop) Loss 0.4352, Accuracy: (87.43, 95.81, 97.49), (Drop) Loss 1.8823, Accuracy: (57.45, 71.97, 77.08), Time 2.04
2019-06-03 12:40:23,357: INFO: [train_wsdan.py:330]: 
	Batch 6200: (Raw) Loss 0.4593, Accuracy: (92.27, 98.11, 98.99), (Crop) Loss 0.4346, Accuracy: (87.45, 95.82, 97.49), (Drop) Loss 1.8812, Accuracy: (57.48, 71.98, 77.08), Time 2.06
2019-06-03 12:41:08,780: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:41:09,954: INFO: [train_wsdan.py:483]: Valid: Loss 1.22247,  Accuracy: Top-1 70.49, Top-3 86.91, Top-5 91.60, Time 45.32
2019-06-03 12:44:37,309: INFO: [train_wsdan.py:330]: 
	Batch 6300: (Raw) Loss 0.4588, Accuracy: (92.29, 98.12, 99.00), (Crop) Loss 0.4341, Accuracy: (87.45, 95.82, 97.50), (Drop) Loss 1.8801, Accuracy: (57.49, 72.00, 77.10), Time 2.10
2019-06-03 12:48:04,622: INFO: [train_wsdan.py:330]: 
	Batch 6400: (Raw) Loss 0.4588, Accuracy: (92.28, 98.12, 98.99), (Crop) Loss 0.4341, Accuracy: (87.45, 95.82, 97.50), (Drop) Loss 1.8785, Accuracy: (57.52, 72.04, 77.13), Time 2.05
2019-06-03 12:48:50,485: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 12:48:51,677: INFO: [train_wsdan.py:483]: Valid: Loss 1.18975,  Accuracy: Top-1 69.95, Top-3 87.00, Top-5 91.44, Time 45.77
2019-06-03 12:52:18,729: INFO: [train_wsdan.py:330]: 
	Batch 6500: (Raw) Loss 0.4588, Accuracy: (92.29, 98.12, 98.99), (Crop) Loss 0.4337, Accuracy: (87.45, 95.83, 97.50), (Drop) Loss 1.8764, Accuracy: (57.57, 72.07, 77.15), Time 2.05
2019-06-03 12:57:22,643: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-03 12:57:24,985: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-03 12:57:25,018: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-06-03 12:57:25,034: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-03 12:57:26,680: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 32, Training size: 265213, Validation size: 3030
2019-06-03 12:57:26,680: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 1e-05
2019-06-03 13:01:36,481: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.9052, Accuracy: (80.31, 92.66, 95.09), (Crop) Loss 1.4008, Accuracy: (65.59, 82.78, 87.66), (Drop) Loss 2.3437, Accuracy: (50.28, 67.16, 73.31), Time 2.09
2019-06-03 13:05:05,881: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.9218, Accuracy: (79.30, 92.36, 94.98), (Crop) Loss 1.4050, Accuracy: (64.91, 82.41, 87.38), (Drop) Loss 2.3630, Accuracy: (49.61, 66.50, 72.62), Time 2.09
2019-06-03 13:06:04,809: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 13:06:06,007: INFO: [train_wsdan.py:483]: Valid: Loss 1.23320,  Accuracy: Top-1 67.25, Top-3 85.13, Top-5 90.04, Time 58.82
2019-06-03 13:09:30,613: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.7851, Accuracy: (82.96, 93.99, 96.12), (Crop) Loss 1.1161, Accuracy: (71.80, 86.42, 90.42), (Drop) Loss 2.1417, Accuracy: (53.49, 69.84, 75.50), Time 2.03
2019-06-03 13:11:29,314: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-03 13:11:31,749: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-03 13:11:31,781: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-06-03 13:11:31,796: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-03 13:11:32,934: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 128, Training size: 265213, Validation size: 3030
2019-06-03 13:11:32,934: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 1e-05
2019-06-03 13:23:48,231: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.6720, Accuracy: (85.52, 95.46, 97.38), (Crop) Loss 1.0442, Accuracy: (72.95, 87.80, 91.26), (Drop) Loss 1.9926, Accuracy: (56.58, 72.35, 77.95), Time 6.63
2019-06-03 13:34:52,298: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.6579, Accuracy: (85.80, 95.66, 97.55), (Crop) Loss 1.0185, Accuracy: (73.42, 88.16, 91.79), (Drop) Loss 1.9644, Accuracy: (56.87, 72.62, 78.11), Time 6.61
2019-06-03 13:35:55,115: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 13:35:56,343: INFO: [train_wsdan.py:483]: Valid: Loss 1.18304,  Accuracy: Top-1 68.22, Top-3 85.98, Top-5 90.81, Time 62.70
2019-06-03 13:46:49,389: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6050, Accuracy: (87.45, 96.35, 97.98), (Crop) Loss 0.8624, Accuracy: (77.05, 90.27, 93.36), (Drop) Loss 1.8428, Accuracy: (58.91, 74.39, 79.67), Time 6.51
2019-06-03 13:57:36,490: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.5692, Accuracy: (88.53, 96.72, 98.18), (Crop) Loss 0.7624, Accuracy: (79.53, 91.65, 94.36), (Drop) Loss 1.7856, Accuracy: (59.84, 74.96, 80.13), Time 6.47
2019-06-03 23:26:33,745: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-03 23:26:41,842: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-03 23:26:41,875: INFO: [train_wsdan.py:103]: Network loaded from ./saved_models/latest.ckpt
2019-06-03 23:26:41,892: INFO: [train_wsdan.py:111]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-03 23:26:43,466: INFO: [train_wsdan.py:152]: 
Start training: Total epochs: 20, Batch size: 128, Training size: 265213, Validation size: 3030
2019-06-03 23:26:43,466: INFO: [train_wsdan.py:220]: Epoch 013, Learning Rate 1e-05
2019-06-03 23:39:06,628: INFO: [train_wsdan.py:330]: 
	Batch 100: (Raw) Loss 0.6734, Accuracy: (85.62, 95.45, 97.41), (Crop) Loss 1.0354, Accuracy: (73.32, 87.84, 91.73), (Drop) Loss 2.0159, Accuracy: (56.77, 72.26, 77.44), Time 6.64
2019-06-03 23:50:15,431: INFO: [train_wsdan.py:330]: 
	Batch 200: (Raw) Loss 0.6648, Accuracy: (85.70, 95.64, 97.49), (Crop) Loss 1.0144, Accuracy: (73.74, 88.32, 92.11), (Drop) Loss 2.0040, Accuracy: (56.35, 71.90, 77.42), Time 6.68
2019-06-03 23:51:31,837: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-03 23:51:34,728: INFO: [train_wsdan.py:483]: Valid: Loss 1.19006,  Accuracy: Top-1 67.70, Top-3 85.80, Top-5 90.69, Time 76.28
2019-06-04 00:02:36,572: INFO: [train_wsdan.py:330]: 
	Batch 300: (Raw) Loss 0.6149, Accuracy: (87.25, 96.23, 97.83), (Crop) Loss 0.8690, Accuracy: (77.12, 90.31, 93.53), (Drop) Loss 1.8583, Accuracy: (58.76, 74.01, 79.35), Time 6.52
2019-06-04 00:13:31,378: INFO: [train_wsdan.py:330]: 
	Batch 400: (Raw) Loss 0.5713, Accuracy: (88.58, 96.69, 98.12), (Crop) Loss 0.7631, Accuracy: (79.71, 91.68, 94.49), (Drop) Loss 1.7854, Accuracy: (59.99, 74.97, 80.12), Time 6.55
2019-06-04 00:14:06,437: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 00:14:07,825: INFO: [train_wsdan.py:483]: Valid: Loss 1.15270,  Accuracy: Top-1 70.86, Top-3 87.23, Top-5 91.91, Time 34.96
2019-06-04 00:25:03,313: INFO: [train_wsdan.py:330]: 
	Batch 500: (Raw) Loss 0.5431, Accuracy: (89.46, 97.03, 98.34), (Crop) Loss 0.6895, Accuracy: (81.52, 92.63, 95.14), (Drop) Loss 1.7657, Accuracy: (60.24, 75.10, 80.17), Time 6.58
2019-06-04 00:35:59,052: INFO: [train_wsdan.py:330]: 
	Batch 600: (Raw) Loss 0.5235, Accuracy: (90.06, 97.24, 98.47), (Crop) Loss 0.6370, Accuracy: (82.85, 93.29, 95.60), (Drop) Loss 1.7655, Accuracy: (60.15, 74.95, 79.93), Time 6.54
2019-06-04 00:36:34,230: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 00:36:35,406: INFO: [train_wsdan.py:483]: Valid: Loss 1.15379,  Accuracy: Top-1 71.61, Top-3 87.49, Top-5 91.96, Time 35.08
2019-06-04 00:47:29,228: INFO: [train_wsdan.py:330]: 
	Batch 700: (Raw) Loss 0.5079, Accuracy: (90.54, 97.43, 98.59), (Crop) Loss 0.5985, Accuracy: (83.80, 93.78, 95.96), (Drop) Loss 1.7743, Accuracy: (60.00, 74.66, 79.59), Time 6.51
2019-06-04 00:58:22,726: INFO: [train_wsdan.py:330]: 
	Batch 800: (Raw) Loss 0.4969, Accuracy: (90.89, 97.55, 98.67), (Crop) Loss 0.5674, Accuracy: (84.61, 94.17, 96.22), (Drop) Loss 1.7840, Accuracy: (59.80, 74.36, 79.33), Time 6.51
2019-06-04 00:58:57,711: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 00:58:58,985: INFO: [train_wsdan.py:483]: Valid: Loss 1.15814,  Accuracy: Top-1 71.98, Top-3 87.70, Top-5 91.95, Time 34.87
2019-06-04 01:09:54,201: INFO: [train_wsdan.py:330]: 
	Batch 900: (Raw) Loss 0.4882, Accuracy: (91.21, 97.66, 98.73), (Crop) Loss 0.5434, Accuracy: (85.22, 94.48, 96.44), (Drop) Loss 1.7903, Accuracy: (59.67, 74.18, 79.12), Time 6.58
2019-06-04 01:20:48,835: INFO: [train_wsdan.py:330]: 
	Batch 1000: (Raw) Loss 0.4814, Accuracy: (91.46, 97.74, 98.77), (Crop) Loss 0.5235, Accuracy: (85.71, 94.72, 96.61), (Drop) Loss 1.7983, Accuracy: (59.49, 74.01, 78.93), Time 6.69
2019-06-04 01:20:48,835: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-04 01:21:25,243: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 01:21:26,414: INFO: [train_wsdan.py:483]: Valid: Loss 1.16050,  Accuracy: Top-1 71.71, Top-3 87.34, Top-5 91.99, Time 34.66
2019-06-04 01:32:22,193: INFO: [train_wsdan.py:330]: 
	Batch 1100: (Raw) Loss 0.4746, Accuracy: (91.70, 97.81, 98.81), (Crop) Loss 0.5065, Accuracy: (86.15, 94.93, 96.77), (Drop) Loss 1.8011, Accuracy: (59.45, 73.89, 78.80), Time 6.61
2019-06-04 01:43:16,969: INFO: [train_wsdan.py:330]: 
	Batch 1200: (Raw) Loss 0.4691, Accuracy: (91.89, 97.88, 98.86), (Crop) Loss 0.4924, Accuracy: (86.53, 95.10, 96.89), (Drop) Loss 1.8024, Accuracy: (59.46, 73.82, 78.71), Time 6.59
2019-06-04 01:43:52,022: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 01:43:53,186: INFO: [train_wsdan.py:483]: Valid: Loss 1.15984,  Accuracy: Top-1 71.75, Top-3 87.73, Top-5 92.04, Time 34.96
2019-06-04 01:54:47,804: INFO: [train_wsdan.py:330]: 
	Batch 1300: (Raw) Loss 0.4643, Accuracy: (92.05, 97.95, 98.89), (Crop) Loss 0.4804, Accuracy: (86.84, 95.25, 96.99), (Drop) Loss 1.8043, Accuracy: (59.42, 73.76, 78.63), Time 6.50
2019-06-04 02:05:42,641: INFO: [train_wsdan.py:330]: 
	Batch 1400: (Raw) Loss 0.4599, Accuracy: (92.18, 98.01, 98.93), (Crop) Loss 0.4688, Accuracy: (87.14, 95.40, 97.09), (Drop) Loss 1.8050, Accuracy: (59.42, 73.71, 78.58), Time 6.53
2019-06-04 02:06:18,023: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 02:06:20,613: INFO: [train_wsdan.py:483]: Valid: Loss 1.16834,  Accuracy: Top-1 71.46, Top-3 87.46, Top-5 92.04, Time 35.28
2019-06-04 02:17:16,331: INFO: [train_wsdan.py:330]: 
	Batch 1500: (Raw) Loss 0.4553, Accuracy: (92.35, 98.07, 98.96), (Crop) Loss 0.4592, Accuracy: (87.37, 95.52, 97.18), (Drop) Loss 1.8037, Accuracy: (59.46, 73.72, 78.56), Time 6.51
2019-06-04 02:28:10,554: INFO: [train_wsdan.py:330]: 
	Batch 1600: (Raw) Loss 0.4520, Accuracy: (92.48, 98.11, 98.98), (Crop) Loss 0.4507, Accuracy: (87.61, 95.63, 97.25), (Drop) Loss 1.8040, Accuracy: (59.44, 73.69, 78.54), Time 6.60
2019-06-04 02:28:45,748: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 02:28:48,257: INFO: [train_wsdan.py:483]: Valid: Loss 1.16661,  Accuracy: Top-1 71.36, Top-3 87.72, Top-5 91.98, Time 35.10
2019-06-04 02:39:42,597: INFO: [train_wsdan.py:330]: 
	Batch 1700: (Raw) Loss 0.4493, Accuracy: (92.57, 98.14, 99.00), (Crop) Loss 0.4432, Accuracy: (87.81, 95.71, 97.31), (Drop) Loss 1.8018, Accuracy: (59.46, 73.70, 78.54), Time 6.52
2019-06-04 02:50:36,985: INFO: [train_wsdan.py:330]: 
	Batch 1800: (Raw) Loss 0.4473, Accuracy: (92.67, 98.17, 99.01), (Crop) Loss 0.4377, Accuracy: (87.96, 95.79, 97.36), (Drop) Loss 1.8015, Accuracy: (59.49, 73.69, 78.53), Time 6.53
2019-06-04 02:51:11,727: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 02:51:12,893: INFO: [train_wsdan.py:483]: Valid: Loss 1.16643,  Accuracy: Top-1 71.62, Top-3 87.62, Top-5 91.91, Time 34.59
2019-06-04 03:02:07,682: INFO: [train_wsdan.py:330]: 
	Batch 1900: (Raw) Loss 0.4449, Accuracy: (92.77, 98.20, 99.03), (Crop) Loss 0.4319, Accuracy: (88.12, 95.85, 97.41), (Drop) Loss 1.7983, Accuracy: (59.54, 73.70, 78.56), Time 6.63
2019-06-04 03:13:01,772: INFO: [train_wsdan.py:330]: 
	Batch 2000: (Raw) Loss 0.4428, Accuracy: (92.84, 98.21, 99.04), (Crop) Loss 0.4267, Accuracy: (88.26, 95.91, 97.44), (Drop) Loss 1.7960, Accuracy: (59.57, 73.71, 78.57), Time 6.52
2019-06-04 03:13:01,772: INFO: [train_wsdan.py:334]: saving the latest model from epoch 13
2019-06-04 03:13:39,809: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 03:13:42,675: INFO: [train_wsdan.py:483]: Valid: Loss 1.17403,  Accuracy: Top-1 71.58, Top-3 87.55, Top-5 92.09, Time 35.17
2019-06-04 03:22:03,840: INFO: [train_wsdan.py:376]: Train: (Raw) Loss 0.4415, Accuracy: (92.89, 98.24, 99.05), (Crop) Loss 0.4232, Accuracy: (88.36, 95.95, 97.47), (Drop) Loss 1.7943, Accuracy: (59.60, 73.72, 78.59), Time 14120.37
2019-06-04 03:22:38,370: INFO: [train_wsdan.py:471]: saving the best model from epoch 13
2019-06-04 03:22:41,429: INFO: [train_wsdan.py:483]: Valid: Loss 1.17263,  Accuracy: Top-1 71.58, Top-3 87.72, Top-5 92.11, Time 34.42
2019-06-04 03:22:41,437: INFO: [train_wsdan.py:220]: Epoch 014, Learning Rate 9e-06
2019-06-04 11:37:36,980: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-04 11:37:42,186: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-04 11:37:42,222: INFO: [train_wsdan.py:104]: Network loaded from ./saved_models/latest.ckpt
2019-06-04 11:37:42,242: INFO: [train_wsdan.py:112]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-04 11:41:26,567: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-04 11:41:28,957: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-04 11:41:28,994: INFO: [train_wsdan.py:104]: Network loaded from ./saved_models/latest.ckpt
2019-06-04 11:41:29,014: INFO: [train_wsdan.py:112]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-04 11:41:34,877: INFO: [train_wsdan.py:164]: 
Start training: Total epochs: 20, Batch size: 128, Training size: 265213, Validation size: 3030
2019-06-04 11:41:34,877: INFO: [train_wsdan.py:232]: Epoch 013, Learning Rate 1e-05
2019-06-04 11:42:44,396: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.7347, Accuracy: (86.72, 93.75, 97.66), (Crop) Loss 1.0553, Accuracy: (70.31, 84.38, 92.97), (Drop) Loss 2.3254, Accuracy: (50.78, 67.97, 75.78), Time 69.52
2019-06-04 11:43:35,069: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 11:43:38,288: INFO: [train_wsdan.py:495]: Valid: Loss 1.12758,  Accuracy: Top-1 71.41, Top-3 87.81, Top-5 92.12, Time 50.56
2019-06-04 11:43:38,295: INFO: [train_wsdan.py:232]: Epoch 014, Learning Rate 1e-05
2019-06-04 11:43:56,926: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.7854, Accuracy: (82.81, 90.62, 94.53), (Crop) Loss 1.1037, Accuracy: (74.22, 82.81, 89.06), (Drop) Loss 2.1020, Accuracy: (60.16, 71.09, 77.34), Time 18.63
2019-06-04 11:44:31,496: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 11:44:33,948: INFO: [train_wsdan.py:495]: Valid: Loss 1.12092,  Accuracy: Top-1 71.05, Top-3 87.33, Top-5 91.78, Time 34.46
2019-06-04 11:44:33,955: INFO: [train_wsdan.py:232]: Epoch 015, Learning Rate 1e-05
2019-06-04 11:44:53,865: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.8112, Accuracy: (82.03, 91.41, 95.31), (Crop) Loss 1.1328, Accuracy: (71.09, 82.81, 90.62), (Drop) Loss 2.2825, Accuracy: (53.91, 64.84, 70.31), Time 19.91
2019-06-04 11:45:27,986: INFO: [train_wsdan.py:483]: saving the best model from epoch 15
2019-06-04 11:45:31,085: INFO: [train_wsdan.py:495]: Valid: Loss 1.10669,  Accuracy: Top-1 70.37, Top-3 87.60, Top-5 91.93, Time 34.01
2019-06-04 11:45:31,094: INFO: [train_wsdan.py:232]: Epoch 016, Learning Rate 1e-05
2019-06-04 11:45:47,201: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.7778, Accuracy: (82.03, 93.75, 94.53), (Crop) Loss 0.9912, Accuracy: (76.56, 89.06, 92.97), (Drop) Loss 2.3016, Accuracy: (50.78, 66.41, 71.09), Time 16.11
2019-06-04 11:46:21,074: INFO: [train_wsdan.py:483]: saving the best model from epoch 16
2019-06-04 11:46:24,220: INFO: [train_wsdan.py:495]: Valid: Loss 1.11677,  Accuracy: Top-1 70.14, Top-3 87.49, Top-5 91.46, Time 33.76
2019-06-04 11:46:24,229: INFO: [train_wsdan.py:232]: Epoch 017, Learning Rate 1e-05
2019-06-04 11:46:40,855: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.7374, Accuracy: (83.59, 94.53, 97.66), (Crop) Loss 1.1540, Accuracy: (71.88, 84.38, 89.84), (Drop) Loss 1.9635, Accuracy: (57.81, 68.75, 77.34), Time 16.63
2019-06-04 11:47:14,902: INFO: [train_wsdan.py:483]: saving the best model from epoch 17
2019-06-04 11:47:16,443: INFO: [train_wsdan.py:495]: Valid: Loss 1.12969,  Accuracy: Top-1 69.70, Top-3 87.16, Top-5 91.16, Time 33.94
2019-06-04 11:47:16,451: INFO: [train_wsdan.py:232]: Epoch 018, Learning Rate 1e-05
2019-06-04 11:47:34,050: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.8217, Accuracy: (82.03, 91.41, 94.53), (Crop) Loss 1.2969, Accuracy: (71.88, 82.03, 88.28), (Drop) Loss 2.0577, Accuracy: (59.38, 71.09, 76.56), Time 17.60
2019-06-04 11:48:08,119: INFO: [train_wsdan.py:483]: saving the best model from epoch 18
2019-06-04 11:48:09,323: INFO: [train_wsdan.py:495]: Valid: Loss 1.14368,  Accuracy: Top-1 68.73, Top-3 86.98, Top-5 91.33, Time 33.96
2019-06-04 11:48:09,331: INFO: [train_wsdan.py:232]: Epoch 019, Learning Rate 1e-05
2019-06-04 11:48:27,444: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.7117, Accuracy: (82.81, 92.19, 97.66), (Crop) Loss 1.1295, Accuracy: (68.75, 85.16, 90.62), (Drop) Loss 2.1620, Accuracy: (60.16, 71.88, 77.34), Time 18.11
2019-06-04 11:49:01,382: INFO: [train_wsdan.py:483]: saving the best model from epoch 19
2019-06-04 11:49:04,299: INFO: [train_wsdan.py:495]: Valid: Loss 1.15020,  Accuracy: Top-1 68.79, Top-3 86.94, Top-5 91.02, Time 33.83
2019-06-04 11:49:04,306: INFO: [train_wsdan.py:232]: Epoch 020, Learning Rate 1e-05
2019-06-04 11:49:20,331: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.8007, Accuracy: (78.91, 91.41, 96.09), (Crop) Loss 1.0259, Accuracy: (76.56, 89.06, 91.41), (Drop) Loss 2.3679, Accuracy: (51.56, 66.41, 71.09), Time 16.03
2019-06-04 11:49:54,343: INFO: [train_wsdan.py:483]: saving the best model from epoch 20
2019-06-04 11:49:57,441: INFO: [train_wsdan.py:495]: Valid: Loss 1.15861,  Accuracy: Top-1 68.68, Top-3 86.63, Top-5 91.07, Time 33.90
2019-06-04 12:08:32,786: INFO: [wsdan.py:82]: WSDAN: using inception as feature extractor
2019-06-04 12:08:35,119: INFO: [wsdan.py:122]: WSDAN: All params loaded
2019-06-04 12:08:35,155: INFO: [train_wsdan.py:104]: Network loaded from ./saved_models/latest.ckpt
2019-06-04 12:08:35,174: INFO: [train_wsdan.py:112]: feature_center loaded from ./saved_models/latest.ckpt
2019-06-04 12:08:41,166: INFO: [train_wsdan.py:164]: 
Start training: Total epochs: 20, Batch size: 128, Training size: 265213, Validation size: 3030
2019-06-04 12:08:41,166: INFO: [train_wsdan.py:232]: Epoch 013, Learning Rate 1e-05
2019-06-04 12:20:45,561: INFO: [train_wsdan.py:342]: 
	Batch 100: (Raw) Loss 0.7938, Accuracy: (81.54, 93.89, 96.54), (Crop) Loss 1.1604, Accuracy: (69.99, 86.27, 90.47), (Drop) Loss 2.1977, Accuracy: (53.44, 69.48, 74.90), Time 6.58
2019-06-04 12:31:43,154: INFO: [train_wsdan.py:342]: 
	Batch 200: (Raw) Loss 0.7746, Accuracy: (82.05, 94.30, 96.71), (Crop) Loss 1.1468, Accuracy: (70.18, 86.32, 90.66), (Drop) Loss 2.1783, Accuracy: (53.36, 69.39, 74.97), Time 6.54
2019-06-04 12:32:34,375: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 12:32:35,568: INFO: [train_wsdan.py:495]: Valid: Loss 1.18412,  Accuracy: Top-1 68.42, Top-3 86.15, Top-5 90.68, Time 51.11
2019-06-04 12:43:25,599: INFO: [train_wsdan.py:342]: 
	Batch 300: (Raw) Loss 0.7043, Accuracy: (84.45, 95.28, 97.29), (Crop) Loss 0.9542, Accuracy: (74.91, 88.98, 92.63), (Drop) Loss 2.0315, Accuracy: (55.73, 71.55, 76.95), Time 6.42
2019-06-04 12:54:08,791: INFO: [train_wsdan.py:342]: 
	Batch 400: (Raw) Loss 0.6475, Accuracy: (86.41, 95.96, 97.72), (Crop) Loss 0.8212, Accuracy: (78.34, 90.73, 93.81), (Drop) Loss 1.9603, Accuracy: (57.02, 72.30, 77.45), Time 6.42
2019-06-04 12:54:43,395: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 12:54:46,509: INFO: [train_wsdan.py:495]: Valid: Loss 1.12600,  Accuracy: Top-1 72.23, Top-3 87.94, Top-5 92.14, Time 34.51
2019-06-04 13:05:29,868: INFO: [train_wsdan.py:342]: 
	Batch 500: (Raw) Loss 0.6098, Accuracy: (87.71, 96.45, 98.01), (Crop) Loss 0.7276, Accuracy: (80.69, 91.92, 94.66), (Drop) Loss 1.9420, Accuracy: (57.39, 72.36, 77.40), Time 6.46
2019-06-04 13:16:13,856: INFO: [train_wsdan.py:342]: 
	Batch 600: (Raw) Loss 0.5844, Accuracy: (88.64, 96.76, 98.18), (Crop) Loss 0.6669, Accuracy: (82.21, 92.73, 95.23), (Drop) Loss 1.9335, Accuracy: (57.61, 72.34, 77.36), Time 6.42
2019-06-04 13:16:48,062: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 13:16:51,033: INFO: [train_wsdan.py:495]: Valid: Loss 1.13318,  Accuracy: Top-1 72.34, Top-3 87.96, Top-5 92.14, Time 34.11
2019-06-04 13:27:34,100: INFO: [train_wsdan.py:342]: 
	Batch 700: (Raw) Loss 0.5657, Accuracy: (89.31, 97.02, 98.33), (Crop) Loss 0.6221, Accuracy: (83.34, 93.33, 95.66), (Drop) Loss 1.9246, Accuracy: (57.74, 72.31, 77.29), Time 6.43
2019-06-04 13:38:17,215: INFO: [train_wsdan.py:342]: 
	Batch 800: (Raw) Loss 0.5517, Accuracy: (89.83, 97.19, 98.44), (Crop) Loss 0.5888, Accuracy: (84.15, 93.77, 95.96), (Drop) Loss 1.9147, Accuracy: (57.93, 72.42, 77.31), Time 6.42
2019-06-04 13:38:51,357: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 13:38:54,440: INFO: [train_wsdan.py:495]: Valid: Loss 1.13538,  Accuracy: Top-1 71.98, Top-3 87.89, Top-5 92.38, Time 34.04
2019-06-04 13:49:37,532: INFO: [train_wsdan.py:342]: 
	Batch 900: (Raw) Loss 0.5403, Accuracy: (90.26, 97.35, 98.53), (Crop) Loss 0.5620, Accuracy: (84.83, 94.10, 96.20), (Drop) Loss 1.9022, Accuracy: (58.12, 72.53, 77.41), Time 6.41
2019-06-04 14:00:20,816: INFO: [train_wsdan.py:342]: 
	Batch 1000: (Raw) Loss 0.5306, Accuracy: (90.63, 97.48, 98.60), (Crop) Loss 0.5402, Accuracy: (85.39, 94.40, 96.42), (Drop) Loss 1.8886, Accuracy: (58.33, 72.70, 77.56), Time 6.44
2019-06-04 14:00:20,817: INFO: [train_wsdan.py:346]: saving the latest model from epoch 13
2019-06-04 14:00:58,447: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 14:00:59,607: INFO: [train_wsdan.py:495]: Valid: Loss 1.12658,  Accuracy: Top-1 72.44, Top-3 88.22, Top-5 92.48, Time 34.24
2019-06-04 14:11:42,673: INFO: [train_wsdan.py:342]: 
	Batch 1100: (Raw) Loss 0.5243, Accuracy: (90.88, 97.56, 98.65), (Crop) Loss 0.5233, Accuracy: (85.83, 94.60, 96.56), (Drop) Loss 1.8751, Accuracy: (58.62, 72.86, 77.70), Time 6.42
2019-06-04 14:22:24,920: INFO: [train_wsdan.py:342]: 
	Batch 1200: (Raw) Loss 0.5183, Accuracy: (91.11, 97.63, 98.69), (Crop) Loss 0.5089, Accuracy: (86.21, 94.79, 96.68), (Drop) Loss 1.8638, Accuracy: (58.85, 73.00, 77.81), Time 6.42
2019-06-04 14:23:04,740: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 14:23:07,858: INFO: [train_wsdan.py:495]: Valid: Loss 1.12078,  Accuracy: Top-1 72.52, Top-3 88.42, Top-5 92.61, Time 39.71
2019-06-04 14:33:50,391: INFO: [train_wsdan.py:342]: 
	Batch 1300: (Raw) Loss 0.5129, Accuracy: (91.31, 97.70, 98.73), (Crop) Loss 0.4961, Accuracy: (86.56, 94.94, 96.77), (Drop) Loss 1.8500, Accuracy: (59.11, 73.18, 77.95), Time 6.44
2019-06-04 14:44:33,201: INFO: [train_wsdan.py:342]: 
	Batch 1400: (Raw) Loss 0.5073, Accuracy: (91.54, 97.77, 98.77), (Crop) Loss 0.4837, Accuracy: (86.89, 95.10, 96.88), (Drop) Loss 1.8372, Accuracy: (59.39, 73.39, 78.11), Time 6.43
2019-06-04 14:45:07,315: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 14:45:08,473: INFO: [train_wsdan.py:495]: Valid: Loss 1.11978,  Accuracy: Top-1 72.50, Top-3 88.66, Top-5 92.65, Time 34.01
2019-06-04 14:55:51,948: INFO: [train_wsdan.py:342]: 
	Batch 1500: (Raw) Loss 0.5023, Accuracy: (91.72, 97.84, 98.81), (Crop) Loss 0.4728, Accuracy: (87.17, 95.24, 96.98), (Drop) Loss 1.8229, Accuracy: (59.64, 73.59, 78.29), Time 6.44
2019-06-04 15:06:35,639: INFO: [train_wsdan.py:342]: 
	Batch 1600: (Raw) Loss 0.4986, Accuracy: (91.87, 97.89, 98.84), (Crop) Loss 0.4639, Accuracy: (87.39, 95.35, 97.06), (Drop) Loss 1.8082, Accuracy: (59.93, 73.83, 78.48), Time 6.42
2019-06-04 15:07:09,925: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 15:07:11,073: INFO: [train_wsdan.py:495]: Valid: Loss 1.12277,  Accuracy: Top-1 72.49, Top-3 88.30, Top-5 92.69, Time 34.18
2019-06-04 15:17:54,679: INFO: [train_wsdan.py:342]: 
	Batch 1700: (Raw) Loss 0.4948, Accuracy: (92.00, 97.93, 98.87), (Crop) Loss 0.4555, Accuracy: (87.62, 95.46, 97.13), (Drop) Loss 1.7956, Accuracy: (60.18, 74.02, 78.67), Time 6.42
2019-06-04 15:28:38,457: INFO: [train_wsdan.py:342]: 
	Batch 1800: (Raw) Loss 0.4912, Accuracy: (92.15, 97.98, 98.90), (Crop) Loss 0.4485, Accuracy: (87.81, 95.55, 97.19), (Drop) Loss 1.7843, Accuracy: (60.42, 74.18, 78.81), Time 6.43
2019-06-04 15:29:12,612: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 15:29:13,765: INFO: [train_wsdan.py:495]: Valid: Loss 1.12414,  Accuracy: Top-1 72.39, Top-3 88.38, Top-5 92.52, Time 34.05
2019-06-04 15:39:57,349: INFO: [train_wsdan.py:342]: 
	Batch 1900: (Raw) Loss 0.4883, Accuracy: (92.27, 98.01, 98.91), (Crop) Loss 0.4418, Accuracy: (87.99, 95.64, 97.25), (Drop) Loss 1.7739, Accuracy: (60.61, 74.34, 78.95), Time 6.44
2019-06-04 15:50:40,604: INFO: [train_wsdan.py:342]: 
	Batch 2000: (Raw) Loss 0.4856, Accuracy: (92.38, 98.05, 98.93), (Crop) Loss 0.4363, Accuracy: (88.14, 95.71, 97.29), (Drop) Loss 1.7630, Accuracy: (60.82, 74.53, 79.10), Time 6.42
2019-06-04 15:50:40,604: INFO: [train_wsdan.py:346]: saving the latest model from epoch 13
2019-06-04 15:51:18,388: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 15:51:19,792: INFO: [train_wsdan.py:495]: Valid: Loss 1.12315,  Accuracy: Top-1 72.70, Top-3 88.45, Top-5 92.45, Time 34.35
2019-06-04 15:59:30,499: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.4840, Accuracy: (92.45, 98.07, 98.95), (Crop) Loss 0.4325, Accuracy: (88.24, 95.75, 97.32), (Drop) Loss 1.7550, Accuracy: (60.98, 74.63, 79.20), Time 13849.33
2019-06-04 16:00:04,951: INFO: [train_wsdan.py:483]: saving the best model from epoch 13
2019-06-04 16:00:06,131: INFO: [train_wsdan.py:495]: Valid: Loss 1.12437,  Accuracy: Top-1 72.91, Top-3 88.25, Top-5 92.39, Time 34.34
2019-06-04 16:00:06,140: INFO: [train_wsdan.py:232]: Epoch 014, Learning Rate 9e-06
2019-06-04 16:11:08,651: INFO: [train_wsdan.py:342]: 
	Batch 100: (Raw) Loss 0.7542, Accuracy: (83.56, 94.75, 96.88), (Crop) Loss 1.1473, Accuracy: (70.62, 86.38, 90.41), (Drop) Loss 2.1602, Accuracy: (54.48, 70.44, 76.12), Time 6.51
2019-06-04 16:22:01,406: INFO: [train_wsdan.py:342]: 
	Batch 200: (Raw) Loss 0.7432, Accuracy: (83.55, 94.76, 96.96), (Crop) Loss 1.1187, Accuracy: (71.05, 86.83, 90.85), (Drop) Loss 2.1120, Accuracy: (54.62, 70.77, 76.31), Time 6.53
2019-06-04 16:22:36,104: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 16:22:37,266: INFO: [train_wsdan.py:495]: Valid: Loss 1.16553,  Accuracy: Top-1 68.34, Top-3 86.77, Top-5 91.25, Time 34.60
2019-06-04 16:33:18,234: INFO: [train_wsdan.py:342]: 
	Batch 300: (Raw) Loss 0.6721, Accuracy: (85.94, 95.62, 97.48), (Crop) Loss 0.9322, Accuracy: (75.50, 89.31, 92.64), (Drop) Loss 1.8928, Accuracy: (58.39, 74.03, 79.22), Time 6.39
2019-06-04 16:44:00,360: INFO: [train_wsdan.py:342]: 
	Batch 400: (Raw) Loss 0.6177, Accuracy: (87.70, 96.31, 97.89), (Crop) Loss 0.8014, Accuracy: (78.84, 91.07, 93.91), (Drop) Loss 1.7857, Accuracy: (60.22, 75.38, 80.39), Time 6.41
2019-06-04 16:44:34,691: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 16:44:35,864: INFO: [train_wsdan.py:495]: Valid: Loss 1.10947,  Accuracy: Top-1 72.29, Top-3 88.27, Top-5 92.45, Time 34.23
2019-06-04 16:55:17,227: INFO: [train_wsdan.py:342]: 
	Batch 500: (Raw) Loss 0.5829, Accuracy: (88.94, 96.74, 98.16), (Crop) Loss 0.7130, Accuracy: (81.07, 92.20, 94.73), (Drop) Loss 1.7499, Accuracy: (60.82, 75.65, 80.59), Time 6.40
2019-06-04 17:05:59,103: INFO: [train_wsdan.py:342]: 
	Batch 600: (Raw) Loss 0.5593, Accuracy: (89.77, 97.04, 98.34), (Crop) Loss 0.6519, Accuracy: (82.61, 92.99, 95.31), (Drop) Loss 1.7362, Accuracy: (61.11, 75.67, 80.52), Time 6.43
2019-06-04 17:06:33,332: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 17:06:34,549: INFO: [train_wsdan.py:495]: Valid: Loss 1.11279,  Accuracy: Top-1 72.84, Top-3 88.42, Top-5 92.12, Time 34.12
2019-06-04 17:17:16,349: INFO: [train_wsdan.py:342]: 
	Batch 700: (Raw) Loss 0.5429, Accuracy: (90.37, 97.25, 98.47), (Crop) Loss 0.6094, Accuracy: (83.70, 93.50, 95.68), (Drop) Loss 1.7246, Accuracy: (61.34, 75.70, 80.50), Time 6.41
2019-06-04 17:27:57,826: INFO: [train_wsdan.py:342]: 
	Batch 800: (Raw) Loss 0.5294, Accuracy: (90.83, 97.42, 98.57), (Crop) Loss 0.5759, Accuracy: (84.55, 93.94, 95.99), (Drop) Loss 1.7125, Accuracy: (61.58, 75.75, 80.50), Time 6.40
2019-06-04 17:28:31,996: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 17:28:33,172: INFO: [train_wsdan.py:495]: Valid: Loss 1.11388,  Accuracy: Top-1 72.71, Top-3 88.25, Top-5 92.35, Time 34.07
2019-06-04 17:39:14,796: INFO: [train_wsdan.py:342]: 
	Batch 900: (Raw) Loss 0.5191, Accuracy: (91.20, 97.54, 98.66), (Crop) Loss 0.5490, Accuracy: (85.21, 94.28, 96.25), (Drop) Loss 1.7036, Accuracy: (61.72, 75.80, 80.53), Time 6.40
2019-06-04 17:49:57,325: INFO: [train_wsdan.py:342]: 
	Batch 1000: (Raw) Loss 0.5108, Accuracy: (91.47, 97.65, 98.73), (Crop) Loss 0.5275, Accuracy: (85.75, 94.54, 96.43), (Drop) Loss 1.6932, Accuracy: (61.96, 75.94, 80.63), Time 6.42
2019-06-04 17:49:57,326: INFO: [train_wsdan.py:346]: saving the latest model from epoch 14
2019-06-04 17:50:32,873: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 17:50:34,052: INFO: [train_wsdan.py:495]: Valid: Loss 1.12123,  Accuracy: Top-1 72.83, Top-3 88.09, Top-5 92.32, Time 34.22
2019-06-04 18:01:16,771: INFO: [train_wsdan.py:342]: 
	Batch 1100: (Raw) Loss 0.5045, Accuracy: (91.71, 97.74, 98.77), (Crop) Loss 0.5104, Accuracy: (86.19, 94.76, 96.60), (Drop) Loss 1.6823, Accuracy: (62.17, 76.09, 80.71), Time 6.40
2019-06-04 18:11:59,288: INFO: [train_wsdan.py:342]: 
	Batch 1200: (Raw) Loss 0.4987, Accuracy: (91.91, 97.82, 98.82), (Crop) Loss 0.4948, Accuracy: (86.58, 94.95, 96.73), (Drop) Loss 1.6742, Accuracy: (62.28, 76.17, 80.77), Time 6.43
2019-06-04 18:12:33,773: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 18:12:34,943: INFO: [train_wsdan.py:495]: Valid: Loss 1.12221,  Accuracy: Top-1 72.88, Top-3 88.35, Top-5 92.52, Time 34.39
2019-06-04 18:23:17,713: INFO: [train_wsdan.py:342]: 
	Batch 1300: (Raw) Loss 0.4937, Accuracy: (92.10, 97.88, 98.85), (Crop) Loss 0.4827, Accuracy: (86.90, 95.11, 96.84), (Drop) Loss 1.6650, Accuracy: (62.43, 76.28, 80.86), Time 6.41
2019-06-04 18:34:00,744: INFO: [train_wsdan.py:342]: 
	Batch 1400: (Raw) Loss 0.4894, Accuracy: (92.25, 97.93, 98.88), (Crop) Loss 0.4727, Accuracy: (87.16, 95.22, 96.92), (Drop) Loss 1.6576, Accuracy: (62.55, 76.38, 80.96), Time 6.46
2019-06-04 18:34:35,167: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 18:34:36,336: INFO: [train_wsdan.py:495]: Valid: Loss 1.11666,  Accuracy: Top-1 72.75, Top-3 88.58, Top-5 92.74, Time 34.32
2019-06-04 18:45:18,775: INFO: [train_wsdan.py:342]: 
	Batch 1500: (Raw) Loss 0.4862, Accuracy: (92.36, 97.97, 98.90), (Crop) Loss 0.4634, Accuracy: (87.39, 95.34, 97.00), (Drop) Loss 1.6502, Accuracy: (62.69, 76.47, 81.03), Time 6.43
2019-06-04 18:56:01,550: INFO: [train_wsdan.py:342]: 
	Batch 1600: (Raw) Loss 0.4830, Accuracy: (92.47, 98.01, 98.92), (Crop) Loss 0.4549, Accuracy: (87.61, 95.45, 97.08), (Drop) Loss 1.6464, Accuracy: (62.75, 76.52, 81.06), Time 6.41
2019-06-04 18:56:35,892: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 18:56:37,067: INFO: [train_wsdan.py:495]: Valid: Loss 1.11784,  Accuracy: Top-1 72.67, Top-3 88.30, Top-5 92.79, Time 34.24
2019-06-04 19:07:20,317: INFO: [train_wsdan.py:342]: 
	Batch 1700: (Raw) Loss 0.4802, Accuracy: (92.56, 98.04, 98.94), (Crop) Loss 0.4484, Accuracy: (87.79, 95.53, 97.14), (Drop) Loss 1.6416, Accuracy: (62.86, 76.57, 81.10), Time 6.42
2019-06-04 19:18:03,385: INFO: [train_wsdan.py:342]: 
	Batch 1800: (Raw) Loss 0.4779, Accuracy: (92.64, 98.08, 98.96), (Crop) Loss 0.4422, Accuracy: (87.96, 95.61, 97.19), (Drop) Loss 1.6358, Accuracy: (62.97, 76.64, 81.15), Time 6.44
2019-06-04 19:18:37,585: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 19:18:38,756: INFO: [train_wsdan.py:495]: Valid: Loss 1.11780,  Accuracy: Top-1 72.83, Top-3 88.48, Top-5 92.52, Time 34.10
2019-06-04 19:29:21,845: INFO: [train_wsdan.py:342]: 
	Batch 1900: (Raw) Loss 0.4752, Accuracy: (92.74, 98.11, 98.99), (Crop) Loss 0.4363, Accuracy: (88.12, 95.69, 97.24), (Drop) Loss 1.6293, Accuracy: (63.10, 76.71, 81.20), Time 6.42
2019-06-04 19:40:05,154: INFO: [train_wsdan.py:342]: 
	Batch 2000: (Raw) Loss 0.4726, Accuracy: (92.82, 98.14, 99.01), (Crop) Loss 0.4304, Accuracy: (88.27, 95.76, 97.29), (Drop) Loss 1.6222, Accuracy: (63.25, 76.82, 81.29), Time 6.43
2019-06-04 19:40:05,154: INFO: [train_wsdan.py:346]: saving the latest model from epoch 14
2019-06-04 19:40:40,985: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 19:40:42,158: INFO: [train_wsdan.py:495]: Valid: Loss 1.11928,  Accuracy: Top-1 72.65, Top-3 88.53, Top-5 92.45, Time 34.47
2019-06-04 19:48:25,152: INFO: [train_wsdan.py:388]: Train: (Raw) Loss 0.4710, Accuracy: (92.87, 98.16, 99.02), (Crop) Loss 0.4266, Accuracy: (88.37, 95.81, 97.32), (Drop) Loss 1.6184, Accuracy: (63.32, 76.88, 81.34), Time 13699.01
2019-06-04 19:48:59,696: INFO: [train_wsdan.py:483]: saving the best model from epoch 14
2019-06-04 19:49:00,892: INFO: [train_wsdan.py:495]: Valid: Loss 1.12092,  Accuracy: Top-1 72.67, Top-3 88.50, Top-5 92.69, Time 34.44
2019-06-04 19:49:00,902: INFO: [train_wsdan.py:232]: Epoch 015, Learning Rate 8.1e-06
2019-06-04 20:00:04,439: INFO: [train_wsdan.py:342]: 
	Batch 100: (Raw) Loss 0.7606, Accuracy: (82.95, 94.51, 96.80), (Crop) Loss 1.1530, Accuracy: (70.54, 86.16, 90.50), (Drop) Loss 2.1246, Accuracy: (54.78, 71.48, 76.71), Time 6.54
2019-06-04 20:11:00,660: INFO: [train_wsdan.py:342]: 
	Batch 200: (Raw) Loss 0.7494, Accuracy: (83.24, 94.57, 96.88), (Crop) Loss 1.1380, Accuracy: (70.70, 86.39, 90.65), (Drop) Loss 2.0760, Accuracy: (55.26, 71.87, 77.20), Time 6.54
